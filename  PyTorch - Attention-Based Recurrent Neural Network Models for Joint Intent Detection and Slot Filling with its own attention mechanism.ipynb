{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5YAAAFqCAYAAABhxMU1AAAMJ2lDQ1BJQ0MgUHJvZmlsZQAASImVlwdYU8kWgOeWJCQktEAEpITeROlVeg0gIFWwEZJAQokhIYjYkUUF1oKKCFZ0VcS2FkAWG/ayCPb+UARFWRcLNlTeJAF09Xvvfe9839z758yZM+ecO3dyBwDVaLZIlIWqAZAtzBXHhPgzJyUlM0mdAAEoUAGqwInNkYj8oqMjAJTh+z/l3U1oDeWarczXz/3/VdS5PAkHACQacipXwsmGfAgA3IUjEucCQOiFepOZuSLIRBgl0BTDACGbyjhdwW4yTlVwhNwmLiYAcgoASlQ2W5wOgIosLmYeJx36USmDbCfkCoSQmyF7c/hsLuTPkMdkZ8+ArGoJ2TL1Oz/p//CZOuKTzU4fYUUuclEKFEhEWexZ/2c5/rdkZ0mH5zCBjcoXh8bIcpbVLXNGuIypkM8LUyOjIGtAvi7gyu1l3M2XhsYP2X/gSAJgzQADAJTKZQeGQ9aDbCzMiowY0nunCYJZkGHt0ThBLitOMRblimfEDPlH83mSoNhhZovlc8lsSqSZ8X5DPjfyeaxhn00F/LhERZxoW54gIRKyCuT7kszY8CGb5wX8gMhhG7E0RhYzfOYYSBMHxyhsMNNsyXBemAdfwIoc4ohcflyoYiw2jcOWx6YNOYMnmRQxHCeXFxikyAsr5Anjh+LHykW5/jFD9ttEWdFD9lgzLytEpjeG3CrJix0e25cLF5siXxyIcqPjFLHhmhnssGhFDLg1iAABIBAwgRS2VDADZABBa29DL/yl6AkGbCAG6YAHbIc0wyMS5T1CeI0FBeAvSDwgGRnnL+/lgTyo/zKiVVxtQZq8N08+IhN0Q84G4SAL/pbKRwlHZksAT6BG8NPsHBhrFmyyvp90TNVhHTGIGEgMJQYTrXBd3Bv3xCPg1Rc2B9wNdx+O65s9oZvQTnhMuEHoINyZLigU/xA5E0wAHTDG4KHsUr/PDjeHXp1xf9wL+oe+cQauC2xxJziTH+4D53aG2u9jlY5k/K2WQ77IdmSUPIrsS7b8MQIVaxXnES+ySn1fC0VcqSPVChjp+TGPgO/qx4X38B8tsSXYQewcdhK7gDVjDYCJHccascvYURmPrI0n8rUxPFuMPJ5M6Efw03zsoTllVZPY1dn12H0e6gO5vPxc2csSMEM0SyxI5+cy/eBuzWOyhJyxY5gOdvbuAMj2fsXW8oYh39MRxsVvupwTALiXQGX6Nx0b7kFHugGgv/umM3kNl/0KAI62caTiPIUOl10IgAL/UTSBDjCAe5clzMgBuABP4AuCQBiIAnEgCUyDdebDdSoGM8EcsBAUg1KwAqwBVWAT2Ap2gj3gAGgAzeAkOAsugTZwA9yDa6ULvAB94B0YQBCEhNAQOqKDGCJmiA3igLgh3kgQEoHEIElICpKOCBEpMgdZhJQi5UgVsgWpRX5HjiAnkQtIO3IHeYT0IK+RTyiGUlFNVB81R8ehbqgfGo7GoVPRdDQHLUCL0GVoJVqD7kbr0ZPoJfQG2oG+QPsxgCljDMwIs8XcsAAsCkvG0jAxNg8rwSqwGmwv1gSf9DWsA+vFPuJEnI4zcVu4XkPxeJyD5+Dz8DK8Ct+J1+On8Wv4I7wP/0qgEfQINgQPAoswiZBOmEkoJlQQthMOE87Ad6eL8I5IJDKIFkRX+O4lETOIs4llxA3EfcQTxHZiJ7GfRCLpkGxIXqQoEpuUSyomrSPtJh0nXSV1kT4oKSsZKjkoBSslKwmVCpUqlHYpHVO6qvRUaYCsRjYje5CjyFzyLPJy8jZyE/kKuYs8QFGnWFC8KHGUDMpCSiVlL+UM5T7ljbKysrGyu/JEZYHyAuVK5f3K55UfKX+kalCtqQHUKVQpdRl1B/UE9Q71DY1GM6f50pJpubRltFraKdpD2gcVuspYFZYKV2W+SrVKvcpVlZeqZFUzVT/VaaoFqhWqB1WvqPaqkdXM1QLU2Grz1KrVjqjdUutXp6vbq0epZ6uXqe9Sv6D+TIOkYa4RpMHVKNLYqnFKo5OO0U3oAXQOfRF9G/0MvUuTqGmhydLM0CzV3KPZqtmnpaHlpJWgla9VrXVUq4OBMcwZLEYWYznjAOMm49Mo/VF+o3ijlo7aO+rqqPfao7V9tXnaJdr7tG9of9Jh6gTpZOqs1GnQeaCL61rrTtSdqbtR94xu72jN0Z6jOaNLRh8YfVcP1bPWi9GbrbdV77Jev76Bfoi+SH+d/in9XgOGga9BhsFqg2MGPYZ0Q29DgeFqw+OGz5laTD9mFrOSeZrZZ6RnFGokNdpi1Go0YGxhHG9caLzP+IEJxcTNJM1ktUmLSZ+poekE0zmmdaZ3zchmbmZ8s7Vm58zem1uYJ5ovNm8wf2ahbcGyKLCos7hvSbP0scyxrLG8bkW0crPKtNpg1WaNWjtb862rra/YoDYuNgKbDTbtYwhj3McIx9SMuWVLtfWzzbOts300ljE2Ymzh2IaxL8eZjkset3LcuXFf7Zztsuy22d2z17APsy+0b7J/7WDtwHGodrjuSHMMdpzv2Oj4ysnGiee00em2M915gvNi5xbnLy6uLmKXvS49rqauKa7rXW+5abpFu5W5nXcnuPu7z3dvdv/o4eKR63HA429PW89Mz12ez8ZbjOeN3za+08vYi+21xavDm+md4r3Zu8PHyIftU+Pz2NfEl+u73fepn5Vfht9uv5f+dv5i/8P+7wM8AuYGnAjEAkMCSwJbgzSC4oOqgh4GGwenB9cF94U4h8wOORFKCA0PXRl6i6XP4rBqWX1hrmFzw06HU8Njw6vCH0dYR4gjmiagE8ImrJpwP9IsUhjZEAWiWFGroh5EW0TnRP8xkTgxemL1xO4Y+5g5Medi6bHTY3fFvovzj1sedy/eMl4a35KgmjAloTbhfWJgYnlix6Rxk+ZOupSkmyRIakwmJSckb0/unxw0ec3krinOU4qn3JxqMTV/6oVputOyph2drjqdPf1gCiElMWVXymd2FLuG3Z/KSl2f2scJ4KzlvOD6cldze3hevHLe0zSvtPK0Z+le6avSe/g+/Ap+ryBAUCV4lRGasSnjfWZU5o7MwazErH3ZStkp2UeEGsJM4ekZBjPyZ7SLbETFoo4cj5w1OX3icPF2CSKZKmnM1YQf2ZelltJfpI/yvPOq8z7MTJh5MF89X5h/eZb1rKWznhYEF/w2G5/Nmd0yx2jOwjmP5vrN3TIPmZc6r2W+yfyi+V0LQhbsXEhZmLnwz0K7wvLCt4sSFzUV6RctKOr8JeSXumKVYnHxrcWeizctwZcIlrQudVy6bunXEm7JxVK70orSz2Wcsou/2v9a+evgsrRlrctdlm9cQVwhXHFzpc/KneXq5QXlnasmrKpfzVxdsvrtmulrLlQ4VWxaS1krXdtRGVHZuM503Yp1n6v4VTeq/av3rddbv3T9+w3cDVc3+m7cu0l/U+mmT5sFm29vCdlSX2NeU7GVuDVva/e2hG3nfnP7rXa77vbS7V92CHd07IzZebrWtbZ2l96u5XVonbSuZ/eU3W17Avc07rXdu2UfY1/pfrBfuv/57ym/3zwQfqDloNvBvYfMDq0/TD9cUo/Uz6rva+A3dDQmNbYfCTvS0uTZdPiPsX/saDZqrj6qdXT5McqxomODxwuO958Qneg9mX6ys2V6y71Tk05dPz3xdOuZ8DPnzwafPXXO79zx817nmy94XDhy0e1iwyWXS/WXnS8f/tP5z8OtLq31V1yvNLa5tzW1j28/dtXn6slrgdfOXmddv3Qj8kb7zfibt29NudVxm3v72Z2sO6/u5t0duLfgPuF+yQO1BxUP9R7W/MvqX/s6XDqOPgp8dPlx7ON7nZzOF08kTz53FXXTuiueGj6tfebwrLknuKft+eTnXS9ELwZ6i/9S/2v9S8uXh/72/fty36S+rlfiV4Ovy97ovNnx1ultS390/8N32e8G3pd80Pmw86Pbx3OfEj89HZj5mfS58ovVl6av4V/vD2YPDorYYrb8UwCDDU1LA+D1DgBoSfDboQ0AymTF2UwuiOI8KSfwn1hxfpOLCwA7fAGIXwBABPxG2QibGWQqvMs+weN8AeroONKGRJLm6KDwRYUnFsKHwcE3+gCQmgD4Ih4cHNgwOPhlGwz2DgAnchRnQpnIzqCbx8moresl+FH+DShCcTfEIeRfAAAACXBIWXMAABYlAAAWJQFJUiTwAAABnWlUWHRYTUw6Y29tLmFkb2JlLnhtcAAAAAAAPHg6eG1wbWV0YSB4bWxuczp4PSJhZG9iZTpuczptZXRhLyIgeDp4bXB0az0iWE1QIENvcmUgNS40LjAiPgogICA8cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPgogICAgICA8cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0iIgogICAgICAgICAgICB4bWxuczpleGlmPSJodHRwOi8vbnMuYWRvYmUuY29tL2V4aWYvMS4wLyI+CiAgICAgICAgIDxleGlmOlBpeGVsWERpbWVuc2lvbj45MTg8L2V4aWY6UGl4ZWxYRGltZW5zaW9uPgogICAgICAgICA8ZXhpZjpQaXhlbFlEaW1lbnNpb24+MzYyPC9leGlmOlBpeGVsWURpbWVuc2lvbj4KICAgICAgPC9yZGY6RGVzY3JpcHRpb24+CiAgIDwvcmRmOlJERj4KPC94OnhtcG1ldGE+CpZIPI0AAAAcaURPVAAAAAIAAAAAAAAAtQAAACgAAAC1AAAAtQAAaq2hfGU4AABAAElEQVR4AeydBXhURxeGv40QgUACBAtuBYIGLe7uUIq3uJT+SKGCFLcCxYqU0pYCRYsWK4TiTnGCl9AWd41uzn/vQmSTje9udrPffZ6QK3NnzrznbtjvnpkzGlE2cCMBEiABEiABEiABEiABEiABEiCBJBLQUFgmkRxvIwESIAESIAESIAESIAESIAES0BGgsOSDQAIkQAIkQAIkQAIkQAIkQAIkkCwCFJbJwsebSYAESIAESIAESIAESIAESIAEKCz5DJAACZAACZAACZAACZAACZAACSSLAIVlsvDxZhIgARIgARIgARIgARIgARIgAQpLPgMkQAIkQAIkQAIkQAIkQAIkQALJIkBhmSx8vJkESIAESIAESIAESIAESIAESIDCks8ACZAACZAACZAACZAACZAACZBAsghQWCYLH28mARIgARIgARIgARIgARIgARKgsOQzQAIkQAIkQAIkQAIkQAIkQAIkkCwCFJbJwsebSYAESIAESIAESIAESIAESIAEKCz5DJAACZAACZAACZAACZAACZAACSSLAIVlsvDxZhIgARIgARIgARIgARIgARIgAQpLPgMkQAIkQAIkQAIkQAIkQAIkQALJIkBhmSx8vJkESIAESIAESIAESIAESIAESIDCks8ACZAACZAACZAACZAACZAACZBAsghQWCYLH28mARIgARIgARIgARIgARIgARKgsOQzQAIkQAIkQAIkQAIkQAIkQAIkkCwCFJbJwsebSYAESIAESIAESIAESIAESIAEKCz5DJAACZAACZAACZAACZAACZAACSSLAIVlsvDxZhIgARIgARIgARIgARIgARIgAQpLPgMkQAIkQAIkQAIkQAIkQAIkQALJIkBhmSx8vJkESIAESIAEUgMBLYLfBCFEJO7OaOzh5OwMBzulmDYIb4K0sHNwhnMa3QldHaF2DnB1ThN3PbFc1Qa9QZDWDg5KG7oqYynH0yRAAiRAApZHgMLS8nxCi0iABEiABEjAvAQCfkenXG2x4nFw3O06lcSYYycwulQavFreEVm7rkXBL/bh7OTKQMAWdMndFqvTdkGw/w9x12Pw6hus6VgE7dfa4dOdlzC7lovBUnon39zAxunf4b9GkzGgvLPeJR6QAAmQAAmYlwCFpXl5szUSIAESIAESsDwC4cLyuSeqt6uH/LEFHB1yoeWor9Eit4MBYbkDfUt+jA2uHXD/7Mwk9DGxwjIIW3qWQMtfQvDpLj/MrJkAIZoEq3gLCZAACZBAwghQWCaME0uRAAmQAAmQQOol8E5YrgyoiUX+O9DTUxNvX2NELOO9I74CiRWWgVjXuQjardbgfxSW8cHldRIgARIwOQEKS5MjZgMkQAIkQAIkYOEEjCIs3+DBrft4rUmPfLkz6Xc46B5O7vwDR689gV2WoqjVpC6Kpn2F27efQps+G3JnUqON+sJyZrl7OLBjN87eDkBar5Ko3agq8qWzf1fva6Wtf7FxcF30+12Dbst3YngFD3jmzga38CL6FvCIBEiABEjAxAQoLE0MmNWTAAmQAAmQgMUTMIawjGWO5YsTC9C983Csv/oMb1MDaeCY9X0M/Lwsdn25AC97bMKNBY0VROHCEug4sjPu/DALexVRGX5PmqxVMHzleoyq5Qm71xvRIVc7rHoaEoFW41IL867vQr8cVJYRULhDAiRAAmYkQGFpRthsigRIgARIgAQskoCJhKX23iZ0q9gBy/9zQtmPvsSwDhWR8elprJw+Fb+cfgKNNgy5+2zWF5ar/oNG44wCjT7BkB4NUDTdIxz4fjwmrb8EKTYYe05NRyWNH5aP/wnrNizGJj87lPvwY1TP8x5aD++Dym7xD+O1SB/QKBIgARKwcgIUllbuQJpPAiRAAiRgeQR+/vln5MyZE/Xq1bM84wxZ9E5YrniRE037t4W3swFx5lgALT/viUrvhFuMOZYxIpahODOuFiqOOYoCfTbg4LymyKiuSqJuz/ZjcNVmmH3xNfL1jSYsV95G5kazcez3AcgXHnwMOIRBpRtizq2imHT6EL4s6qhUwjmWOpb8hwRIgAQshACFpYU4gmaQAAmQAAmkHgLVqlVDpUqVMG3aNOvoVLiwjGO5EY1Lbcy/sRN9s79Ve/EKy9CrmFilIkaeLYCJp45geDFVDIZvYfCf3RRFB+9EjhgRy8do/qOyjEi3bOGFld+vsbxNYXT93RmDfS9iRnV1aREKyyiAuEsCJEACKU6AwjLFXUADSIAESIAEUhsBaxWWK99UwHjfBWiZwUDEUpMOOd7LA493UcR4heW7COYq+7ZY578MzaNFQYP2DYN33VmQntHnWGrRZ8s1LGjgGuWxCJ9/GXWNSwrLKIC4SwIkQAIpToDCMsVdQANIgARIgARSGwGrFZbJWW4k+lDY17+hbfaO2OzeGb9f+xENnPTFatCxr1Gm6mQExRCWUcVj+JNBYRlOgr9JgARIwFIJUFhaqmdoFwmQAAmQgNUSoLD8QRmpugd932uCH57Xw1L/jejkri8s32zpjwItFsG1d7Q5lmspLK32wafhJEACNk2AwtKm3c/OkwAJkAAJmILAoEGDULRoUfTp08cU1Ru/TpNkhX2En1uWRo+tYeix3g8/NHOPYncQDgx9H7VnnEPu6Ml7KCyjcOIuCZAACVgPAQpL6/EVLSUBEiABEiAB0xAwibAEnm7qi5JtFuFpsZ5YuWUemuVWE/hocc93NJq1mYqTLwT5kyEsN3xUDG1XhKD/jquYW8fFNGxYKwmQAAmQQIIIUFgmCBMLkQAJkAAJkEAqJmAiYYmwO1jTvT66LPWDNn0+VKpSAh6vruLwkSsIdHZF0KsA5O27BdfnN1TgGppHGc7c0LVg7B9SAXVm+aHQh+MwtH5hlGrVAmXdw9coCb+Xv0mABEiABMxBgMLSHJTZBgmQAAmQAAlYMgFTCUu1z8H/Yvu3ozH552047f8E8CiAyq0H4KsSB9Dsk3XIOfAPXJpZWyloSDyGQzN87fXRKajbaBSOPgsFHPJikK8fZtZg5DKcGn+TAAmQgDkJUFiakzbbIgESIAESsAkCvr6+yJw5M0qXLm0T/U1KJx8taoWcfbaizPgTODKyVFKq0N0TdPcM9hy6hOf2mVG8am14ezJimWSYvJEESIAEkkGAwjIZ8HgrCZAACZAACRgiYHVZYQ11ItnngrC1//v49HAOfPLDb/isvHNkjWGPsKpTRXRa8xxdfvsbS1qlj7zGPRIgARIgAaskQGFplW6j0SRAAiRAApZMgMJS9U4Ybv/4IYr3Xg87nx6YMmUA6ntnAR5dxu6fxuOrOXvwomBfbD0xD7Xd9JcisWTf0jYSIAESIAHDBCgsDXPhWRIgARIgARJIMgEKy3fogq7i5x5t8b8V5/FKouLUIF2hlpi6agn6+zBaGZUM90mABEjAWglQWFqr52g3CZAACZCAxRKgsIzqmkD8c3gzNvxxAtfuvwTSZUWhsvXQulUV5HJmpDIqKe6TAAmQgDUToLC0Zu/RdhIgARIgAYsk0KZNG5QpUwYjR460SPtoFAmQAAmQAAkYmwCFpbGJsj4SIAESIAESsHECp06dgo+Pj41TYPdJgARIwLYIUFjalr/ZWxIgARIgARIwKYHAwECUKlUKFy5cgKOjo0nbYuUkQAIkQAKWQ4DC0nJ8QUtIgARIgARIwOoJrFy5Eh07dsSGDRvQsmVLq+8PO0ACJEACJJAwAhSWCePEUiRAAiRAAiSQYALXrl2Dq6srvLy8EnxPainYpEkTbNu2Da1bt8a6detSS7fi7If2wW6M/98sHH8RBtfiXfHbNx/GWZ4XDREIw73tkzB43mE8F2eU7DETk1rngZ2hojxHAiRgkQQoLC3SLTSKBEiABEjAmgnYalbYR48eIWvWrAgLC4ODgwMePnwId3d3a3Zl/LaH3sSPH9RBn03+cMjfHr/4LsWHeR3e3fcIP7WpgKF7nsWsR+OGtj/6YVHLtDGvJeFM8MO/cfmOknXXOQsKv5cdzkmow3S3BOPhjSu4o6w545y1EN7L5mK4qbAH2DawCdrOO4ngjDUwbe8ODC5uWT0xbDjPkgAJqAQoLPkckAAJkAAJkICRCdiqsJw3bx4GDhwIrVYLe3t7LFy4ED179jQyXUuqTotrC9ui8icb8SRdBYzx9cWo8m5RDHyIhY2KY8Cux8q5MIRpBaLRwN5OicMpwrL9in+w/IOo5aPcmqhdLW7MaISiQ3fBocxwHD4+AaUdLGgpF60/ptfywbADr1D268M4OrYcwqV3jG4GXcGcZnUweNcdZKg6Dnt9R6CkkwX1JYbBPEECJBBOgMIynAR/kwAJkAAJkICRCNiqsFQzwZ45cwYiAo0ioCpVqoTDhw8biarlVaO99xs6+XTG6nuOqDZpH3Z96QMng2aG4e78Fsj7yRaEurfCytvr0M7VmGIpFQlLhV/ojR/RrGI/7HiaFo2/O47N/QrB3iBXniQBErAkAhSWluQN2kICJEACJJAqCNiisLx69Sree++9GP67efMm8ubNG+O89Z8IxtHh1VB9ygnYFxmAnSdmo1ra2MQihWWCI5a6ByMUp8fXQZXR+xGavxe2nvke9dLFxtb6nyT2gARSCwEKy9TiSfaDBEiABEjAYgjYorBctmwZJkyYoBsCe/36dRQoUEDnj9GjR6N9+/YW4xtjGSJPN6Ordzssv+eEJgvPYnPvvHEkmkmAsAx7jjNbNuH0Y0HWcq3QuERa3D+9CctXbMFhv//wUuOOfD710KVPV1T1ihIX1f6HA2t9cXzLDHz56wVo8rbE1yObwysi640dspRrgSYlos11fXUDu1atwub9p3Hz3nNoXTMjT/HKaNbpIzQpmj4GprBn57Fl00k8hifKt26C4q6PcGrDr1i59SD8br+Axj0PfBp0Rt8uNZAjTeTtof8exm++x/D71JFYcSUI+VqPwoimuSNZ2WVG+ZZNUTyDvnCUxxvQ0bs9Vj10RcsfzmFd91yR90RWzz0SIAFLIqAMV+FGAiRAAiRAAiRgRAJv3ryRoKAgI9ZoPVVdvHhRlO85omTGtR6jk2Dpo187S0Y7iEOO9rLuSVg8NWjlzrymougtsXNvJatfGygffEFGl82gsHOUyl8tkxmdyoqHg0bHUuX59kcjjtnryszTLyPbe7NVumZ1ilYuvLz621GqTrkQWV60cnfneKmXO60oUi7GfRrnXNJi+mF5GuUOdTf47ETxcdSIxqmCfLX8W+lYylOUaZz692scxKvBNDkdpX+vN/aWLAqnyD7o76v1Tb0UHK019TBAfAcUFwclHYhH/bnyr9ZAEZ4iARKwKAKMWCp/6biRAAmQAAmQAAkYh4Cfnx+8vb2hLrlSsGBB41RqcbW8wfquxfHBslvI1nEF/H79EBnitDEBEcuQixjzfhWM/euFEvW1Q5hdJlRs3wfdW9VAMUWZPTi/DXPGz8W+O8FIX30yjv75BYqoEw+V+5aMmIfdR7Zi5cF/AM9yaNOqLDwiAoAOKNBqBIY1yK6z8Mnu4ajdYirOvkmDfHV6YEC3RiiXzwNhj65h/2/zMefXE3iiyY7Ovx7HknZeEVHCkHOTUKncSJwKtVOSD4XBXmnnw9490KpGcWTRPMK5LfMwYY4v7mhdUHPaMez5rLiuvZBzyzFiwS4c/n0VDt0ORZYKbdCyTEZEmOeYF61HDkP9rDFnUQbuHoyiDWbjn7SN8dP13/GRZ8RdcdLmRRIggRQiYFEyl8aQAAmQAAmQAAlYNQGbiFgGHpfPi7kpGYrcpPUv9xPgr8RELO3Eo/RHsuDIPSW2qL89WtNdsinRP41TeZmiF+ULlevT64mjEoF0KTNcTocYiIiqVb05LJ8VdVMS0zpJ8b4b5G70BuSl7P+8ojhpNOJSdoRePeERS9hlEJ9uc+XIg1B945QY5+pO+UUZgSuulcbrXwu9KdOqeeiip2W/PiEh+ldjP3q5RbpmU6KxDjmk7/bXsZfjFRIgAYsgoGZu40YCJEACJEACJGBEAoGBgRIcbGh4nxEbsdCqbEJYPl8lLd0cBE5lZNy5hAx5ToywdJRqUy9KdNmmujvs4RJp6KK0a5dJum18FeUJSJiwfPZbD92wVMfcXWTzU8PiM/S/RVLH1V7pWzmZfDHyGQ4XlhqnivLN5cjzUYyQB4taibMyPNYha6eop0WSKiy1t2V2rUyKIE0j9efe1K+TRyRAAhZHgMLS4lxCg0iABEiABKydQNWqVWXo0KHW3o0k2W8LwjLk0nSp6Ggndm7NZfkLwwJNH55xhKWEz6fUuMgHK15EaSIhwjJQfD/xFnvYSfZOq+SpMgdYnQcc4+flHumfz1URrxnl4w2R4jUhwjJ8PqWdW4sotim7SRWWyjzLjd0KKFFQBynx+QH9OnlEAiRgcQQoLC3OJTSIBEiABEjA2glQWKbu5D3Bf42TEkoiG4dsXeT3ADMKy4Cd0tPLRRmC6yxtf02ssHwqPzTOYjBhjzIbK2ZyHaWN1sueRXwUEyIs32wbIF72SoKidM0j7tPtJFlYBsm+waWVBD72UrD/Dv06eUQCJGBxBCgsLc4lNIgESIAESMDaCVBYpnJheWy0eKvCMsdHstVahKX2jsyprQ4rVTLLpsss2bNnj+cnj3RfnfLC8sDQMjphma/PFmv/s0D7SSDVE6CwTPUuZgdJgARIgATMTYDCMnULy5ALU6SsIiztPNrI2ihLa8T+nBlpKGyyIpbP5afmWZWIpb3k77tVAmM31uCVlIlYBsqOPkWU4bsOUnTIHoN28SQJkIDlEKCwtBxf0BISIAESIIFUQoDCMnULy/AkOhrnqjLzb8OJbPQfZVMLS63cmFFft06mS6kv5ITBrLBBclAX/dNIumpT5Iah7ED6RusdJUtYav1levWMuqywZUYcSXhWWHkmPzbPpohhNaGRn549PCABErA8AhSWlucTWkQCJEACJGDlBC5fviz//vuvlfciaebbQvIeCdgr/fIocx3tPKXH5qhzHWNjZmphKXJvQQtxUuZKOubtJb6Bhud9BuweIvntNaJJU0g+3fU4NmPfndfqLXeSLGEpD2VBA09FWNpLgX7bEx4tDTwigwunU+aUukvntc/jsZeXSYAEUpoAhWVKe4DtkwAJkAAJkEAqImATwlKeKJG07EokzUGKDNot8S84YnphGbB7sORVRCMcCyii8YnhJyrkmsypl0PJsqrOD60tY//wjynytM/l8va50rduB1ngH7niZPKEZXhGWohT4T7i+8yw8I1udHibdi5VZVaCIsPRa+AxCZCAOQlo1MaUbGDcSIAESIAESIAESCDZBPz8/ODt7Y1r166hYMGCya7PMivQ4sbMpij+2Q4oyhJ/nv4WlZ00Bkx9giXtKuDzvS8gQc/x+EUwYOeE9JnSI40mHVovOo+FLdK+vS/kIsa8XwVj/3qDalPPYM/nxWAfvcbAXehVsAUW3xG0Xf4Aazu6RZYIOIzBZRpi9pVXsPcognrNqqOAazAe+F9HmuaLsaxfYV3ZUP/16NO4O36+9ByicUHOMtVQuXR+eDqF4Nm9mzh75Cj87r+BOFfDLL8/8b+8Drr7Qs5NQqVyI3HargKmnj2AYe85Rrb9bi9g+6co1Ow73HVpDu3LTXrXA/Z/idJ1p+FqqAYexeqiWbVCcA16CP/rGrT8eSn6FIhenxYXJtZB2VH7YF9mBI4cG49SDoYY6zXDAxIggZQkYE4Vy7ZIgARIgARIgARSNwHbiFgqSzP+vUBqp7UXOOSQ3r8/NexU7QOZXz+z+gI/5o/GTTqsiTKMNviCjC6bQSmnzie8KAanQMaavOdt80+PzJLm+dNHW1LEUapOuaBnn/bhCfn+kwZSKINjtLKKnRpHyVSkpnQduVzOvYqMLIZHDzVOFeWby4bnlca63Iiu9edyZHpbye9qp8dC41RBpl4yUF/gURlaRB0G6yiVxp1KxLxMva7ygARIwIwEGLFMSVXPtkmABEiABFIlgTZt2sDHxwcjRoxIlf2Lq1O2EbFUCTzF6k7l0HHFTWSsNxPHtg9E/hghxrhImeha8EOcP3AAp/0fI8TRHdnyF1GeRW9kd7WL2WDgfZw/dgIX/e/hRYgD0npkQ8HiPij9XhYo8zVNsgU/uIgDB07B/0kwHN2zoUDRMihTLAf0zQvD3RUfo0yXZXjo3hCLzvyOHrneRk5NYhQrJQESMAoBCkujYGQlJEACJEACJBBJoFq1aqhUqRKmTZsWedJG9mxHWAJBZ6agauWROBmSDd1Wn8Ti1tlgQL7ZiOeN2M2XBzG4YmPMvhwI78E7cHRGbbwbMGzERlgVCZCAsQlQWBqbKOsjARIgARKweQIUlql9jmX4I/4KvgOrofHcs9Dk7YRVh5egVTZLCFuG22eNv1/gzyG10XjWKYTl6oDVx5eiVVYytUZP0mbbI0BhaXs+Z49JgARIgARMTIDC0laEpfIgPduLgZVbYO6lV8jWcAZ2bRwIb4OJfEz80KWK6rW4uawbavb4Ff/CCx+vPIrFbXIwCpwqfMtO2AIBCktb8DL7SAIkQAIkYFYCFJY2JCyVJ+v1yRlo2mwcjr+0Q6GOC3Fm0Ydmfd5SR2NhuL9zJJp3/g4X3jii5KdrsX1ybbinjs6xFyRgEwQoLG3CzewkCZAACZCAOQn4+voiU6ZMKFOmjDmbtYi2bGmOpUUApxEkQAIkYCEEKCwtxBE0gwRIgARIgARSAwEKy9TgRfaBBEiABBJPgMIy8cx4BwmQAAmQAAmQQCwEKCxjAcPTJEACJJDKCVBYpnIHs3skQAIkQAIkYE4CFJbmpM22SIAESMByCFBYWo4vaAkJkAAJkEAqITBkyBAULVoUvXr1SiU9Sng3KCwTzoolSYAESCA1EaCwTE3eZF9IgARIgAQsggCzwtpWVliLeOhoBAmQAAmkMAEKyxR2AJsnARIgARJIfQQoLCksU99TzR6RAAmQQNwEKCzj5sOrJEACJEACJJBoAhSWFJaJfmh4AwmQAAlYOQEKSyt3IM0nARIgARKwPALmFpahoaHo3Lkzbt++DTs7uxQF8ubNG5w7dw6lSpWCi4tLitoSFhaGPHnyYMmSJXBwcEhRW9g4CZAACaR2AhSWqd3D7B8JkAAJkIDZCfz444/ImTMnGjRoYJa2Hz16BE9PT2TJkgVZs2Y1S5vW0Mjdu3ehsnn+/DnSp09vDSbTRhIgARKwWgIUllbrOhpOAiRAAiRAAm8JhAvL5s2bI1u2bMTyjsCdO3ewZcsWCks+ESRAAiRgBgIUlmaAzCZIgARIgARIwJQEKCwN06WwNMyFZ0mABEjAFAQoLE1BlXWSAAmQAAmQgBkJUFgahk1haZgLz5IACZCAKQhQWJqCKuskARIgARKwaQKzZs1C3rx50bJlS7NwoLA0jJnC0jAXniUBEiABUxCgsDQFVdZJAiRAAiRg0wTMnRWWwtLw40ZhaZgLz5IACZCAKQhQWJqCKuskARIgARKwaQIUlpbhfgpLy/ADrSABErANAhSWtuFn9pIESIAESMCMBCgszQg7jqYoLOOAw0skQAIkYGQCFJZGBsrqSIAESIAESIDC0jKeAQpLy/ADrSABErANAhSWtuFn9pIESIAESMCMBMaMGYOCBQuic+fOZmmVcywNY6awNMyFZ0mABEjAFAQoLE1BlXWSAAmQAAmQgBkJ+Pv7I1++fGjevDmyZctmxpYtuykKS8v2D60jARJIXQQoLC3Bn2FahIYKNA4OsLezBINogz6BMGhDQyEaBzjQQfpozHnEz4k5abMtKyKwZs0aDBw4EPfu3aOwjOY3CstoQHhIAiRAAiYkQGFpQrgJq1oLv8l1UXr4IZQafQRHxpSFQ8JuZCkzEQi9NB1VSn2B8yW+wpFj41HKQWOmltlMJAF+TiJZcI8E3hJ4/PixTlD++uuvEUgYsYxAoduhsNTnwSMSIAESMCUBCktT0k1Q3fzCnCBMKViIwjIF4Uc0zc9JBAruWAWBdevW6YakVqlSxej2igjWrl2Lvn374tWrVwgJCUH79u2xatUqRiyj0aawjAaEhyRAAiRgQgIUliaEm7Cq+YU5YZxSrhSFZcqxj2yZn5NIFpa9F6YNRaho4OBgD1se2W+qrLCqUOrWrRt27typ9yAsXboUXbt2pbDUowJQWEYDwkMSIAESMCEBCksTwk1Y1fzCnDBOKVeKwjLl2Ee2zM9JJAsL3gu9iklVK2LEmdwYc+wERpdKY8HGmtY0UwhLNVLZvXt3LFmyRM94R0dHXL9+HXny5KGw1CNDYRkNBw9JgARIwKQEKCxNijchlet/YT40zAN/LlmM1btO4ubTMHjkr4iW/QaiS4UsNv32PyEkTVVGT1ge+Qpp9yzFD6t24tTNJxD3fHi/VV8M7FIJmW05PGMq+BH18nMSgcKSdygsI7xjCmGpVq6Ky6lTp2L48OHQaN7O927QoAHUiKWnpyeFZYQH3u4wYhkNCA9JgARIwIQEKCxNCDdhVYd/YT6IPE27oLDfb9juHwQ35QuCS8BDPHgRDE26Evhs0158UztjwqpkKaMSCBeWZ3I3QqciV7Fq2w1o3Tzh6RKIBw+eIwRp4fPZBuyeVg/uRm2ZlUUS4OckkoUF71FYRjjHlMLy448/xubNm5Xhxg5Q169cvHgxWrRoQWEZQT9yh8IykgX3SIAESMDUBCgsTU043vrDvzDvRaidG4q2HopJYwegabGMsA+9j92j2qHV1AOwqzEVf/kOQwH7eCtkASMTCBeWx0OBDEVa4vPJY9GvaXF42Ifi7u5xaNlqEk5KZcw4vRuDCjoauXVW95YAPydW8SRQWEa4SZ0HWbJkSQwePDjinDF2fvrpJ/Ts2RN//PEHfHx8oIpMVVja29tTWBoATGFpAApPkQAJkICJCFBYmghswqsN/8J8EIUH7sDRWXWQLsrN8mQlWufris12TbDMfwM6ZuBSF1HwmGU3XFieLdAPO0/MRfV0UX3wDL+09ka3jS/QZtktrO3EqLJpnMLPiWm4GrlWPWF5DJ+lO4AlP6yC71838FTcUeD9Fuj3v64o78k3ZEkhf+7cOVSsWBGff/45xo4dq6tCHRqrDolVI5ccChuTKoVlTCY8QwIkQAKmIkBhaSqyCa43/AtzLOtYBh3CwOINMPe2D2b5/Yn/5eUqlwlGa6SC4cLS8DqWwdg7qDzqzb6MGrP8sHNgAc6FNRJ3/Wr4OdHnYaFH4cLylAeadfHGxZXb4K9NpwgeFwQ8eIAXIUD60gOxcc+3qOUe9QWNhfbHgsx6+fIlypUrh5w5c+oywqoRyqhbuLBUz2fMyBdc4WzUtT7DwsLw4sULuLm5hZ/mbxIgARIgARMQoLA0AdTEVRnfF+aT+MKnNqbdKIkZfnswOD+HWiaOb/JLxycsj35ZBdWmnkW1GRexa0gh6H/dS377rEElwM+JVTwH4cLy2HPYpS+MNp9Pwtj+zVHUwwEhd/diVKsP8M3x16g14zR2Dn6Pn5UEOlWNSnbs2BF79+7F6dOndetjRr9VFU/ff/89bt++Hf2S1R2HR2GNZbgqxtU1P7mRAAmQAAmYmIDyB5xbihIIlYuTaoojHKXc6JMSEt2WwBPyhbebaJyqyLc3gqNf5bEZCIT4TZMKjnbi4jNCzoSERWsxSI58WU4cFP/VmnFVQqNd5aGxCPBzYiySJq0n5IpMrOgucCwkg/c+j9HUo1/ai5tGI5laL5FnMa6mrhMnTpyQq1evGqVTCxYsEDs7O9mzZ49R6rP0SpQhv7Jw4UJLN5P2kQAJkAAJRCOgpi7nlqIE+IU5RfEnoHEKywRAMnkRfk5MjtgYDYQLS6eSMuZMUIwaA/cOkwIOGklXc7r4a2NcTlUnqlatKkOHDk12n06dOiVOTk4yYcKEZNdlLRUEBgaK8k5d3n//fQkKivkcWUs/aCcJkAAJ2BoBCssU9zi/MKe4C+IxgMIyHkBmuczPiVkwJ7eR+ITl0VFSVBGWaatPlb9TeXjfGMLy2bNnUqBAAVHWqRStNpUr8WjPnios1Z/y5cuLkoAn2lUekgAJkAAJWCIBCssU90oyvzC/vilHfE/JXdv6zmFWryVNWAbK3XO7Ze3P82XapEny7eKNcvo+hzIn3XFJ/JyEPpNrh7bIr9/PkskTpsp3y33l6ovow5mTbhXvjEYgXmH5tRSjsIwGzfChMmdS2rRpI15eXvLgwQPDhVLxWWVJFVGy3Yqjo6Mo2W7l2LFjqbi37BoJkAAJpA4CFJYp7sckfmFW7NYG3JY9YxtIRo/Wsvo1vyybypVJEZYvV3cVd4f0kq98XWnVpoXUeC+TOHlWlQmHUvvMMlN5ISmfk0DZ2b+YOLpmF+/K9aVlqwZS1iutuBZoK0uuUOSbxFMUlhFYkxuxnDNnjigZXuXgwYMRddrSzvz588XBwUEXtVQ5qD/KGp62hIB9JQESIAGrI0BhmeIuS8oX5lC5OrulZHfPIOldHcXOvRWFpQn9mBRhGXxhp2w4/TAymU/ARZlQOZN41J8r/zK6nARvJe1zcu3PjXL0TmBEe6H310mHHK7i/dle4cytCCzG26GwjGBZu3Zt+fLLLyOOE7OjRufUSN3UqVMTc1uqKqsyCB8OG/X3jz/+mKr6yc6QAAmQQGoiwOVGlP+xrHl7tbQ9sgwMxpLb69DOlevCWa4vg7B7QFk029sQe05NQ8U09FWK+CroGIaWqo/tTTbh9IyaSJMiRqTiRsOXGzmTG2OOncDoUvqEg46Nhk/V8bhVeQrO//k58hlamyf0Lk7vvQApWhM+Xra3vNLTp09RpkwZlChRAps2bYKSDTYVPzCxd01J4ANXV1f15TfUtTmdnZ0xb948dO3aFcoQ2dhv5BUSIAESIIEUI0BhmWLojdMwhaVxOJq8ltDr+KZmJUz1mAi/TX2Q1Ta/K5occ2wNBD35F/7/XMX+H8dinG8uTNm6BJ24JmxsuJJ+PrnCMuwJdg1rjJYzz6Duj7exqVumpNtihXeqIqply5Y4c+aMbr3KjBkzWmEvjGdy5syZ8fjxY5QtWxbXrl2DsnwLsmbNarwGWBMJkAAJkIBRCVBYGhWn+SujsDQ/88S3qMX1xR1RfcAJtNxwAvMb2daX5cTzMvYdwTj0RWXUmnYK8KyE/839AWPaeSOdsZthfUCyhGUw/BZ0QP3JZ2D/8A5Kz//P5oTljBkz8NVXX+HAgQOoWLGizT9RyjxTVKlSBcWKFYO3tzeqVauGX375xea5EAAJkAAJWCoBCktL9UwC7aKwTCCoFCsWhnvbPkfD9j8h3aAN2DKuBtxTzBbbblj75iEu75qLPj0WwG3MXmwZ4A1DIzFtm1JK9T4MD7YPQ90eR9FuRT9caN0PATP8rVpY3r9/H8r6k3B3T9gn/vDhw6hevTqmT5+OQYMGpZQjLLbdLVu2oFmzZti/f79OYFqsoTSMBEiABGyYAIWllTufwtKSHaiIyh0j0LTDIjj1XYENExsgC4fAprDDXmNNh2Locbs/zu75AvmpLFPYH2+bD7ywEC0bTkf2mbvxY+PT6JSrC95YubBUo2uVKlXCtGnT4mX86NEj3bxKZc1GrFu3jnMIYyHWokUL/P333zh16hSU5EaxlOJpEiABEiCBlCJAYZlS5I3ULoWlkUAavZpgXF81CK36bkSOL1Zj1RfV4EFRaXTKia/wOZa2LoZPngzC+d3DkJfCMvEIjXyH9t4ODKjbE1c6rsPvwysi7euN6GBDwlJZrxJNmzbF5cuXdYIpoRFOI7vBKqrz9/dH0aJFMXHiRAwZMsQqbKaRJEACJGBLBCgsrdTb2pcPcOdpIF5v/BRlRmkx6695aOTkikxenkhLAZPCXtXi2o+dUWfgAZQctQSzOhSOzD6qsUc6Ty9kdE5hE22h+RA/LJm4BW6NP0T9snngZv8GNzaOwgddFsNj7CHsHFKcQ2FT+jkIu4tfPqiGqRkmwXdxO+RQ/3bZmLCcPHkyxowZA3UorJqkhlvcBCZMmABlGRadEPfy8oq7MK+SAAmQAAmYlQCFpVlxG6sxLfwm10Xp4XsREqVKjUs9fO+/Hb2yMAwTBUsK7AZhW++SaP7DVWijt27nga5r/8UvrdNGv8JjYxMIvYL5H7bGiN8v4aV9Brg7vcGzwMyo2m8Wfp72AfI5GLtB1pdoAiEXMLpSdUy7AThHvBALxevnrwBXd3h498e9oxMSXa0l3JCQobD79u2Dst4l5s6di/79+1uC2RZvQ1BQkG4pFh8fH6xatcri7aWBJEACJGBLBCgsbcnb7CsJ2CAB7esHuHXzH9x/5Yjs7xVDXg/OzbKcxyAQdy/54fbrsEiTgg9iVOPhCBqyDdPaFERZ75yR16xoLz5hqSb3UderVBP2rFy5kvMqE+HbnTt3okGDBvD19UWdOnUScSeLkgAJkAAJmJIAhaUp6Rqx7nv37iFbtmxGrJFVJZfAkydPkC5dOqRJo78IfHLr5f1JJ6CuA/jgwQOudZd0hCa5M1F/v1LJUFhVOKp/Gzw8PGIw1Wq1aNiwIW7duoWTJ08iffr0McrwRNwEPvjgA5w/fx5nz57VZd+NuzSvkgAJkAAJmIMAhaU5KBuhjR49emD06NHInTu3EWpjFcYgoA5fy5MnD5o3b26M6liHEQgcOnQIu3bt0s1ZM0J1rMIIBJ4+fYo+ffpgzZo1CastlQjLuDo7duxYTJkyBUePHkWpUqXiKsprsRD477//UKRIEYwcORJffvllLKV4mgRIgARIwJwEKCzNSTuJbb158wZp06bFJ598gu+++y6JtfA2YxPQaDQoVKgQrl69auyqWV8SCdSqVQt79+6FmmlT9Q+3lCcwadIkjBgxQhdJ9vT0THmDUtiC3bt3o169eli0aBF69uyZwtZYd/PqUi5q4qNLly7xpat1u5LWkwAJpBICFJZW4Eh1/k3Hjh2RKVMmPHz4kF+YLcBnV65c0b0tV01RIzJcIiDlnaIm9XB2fptuV41cVq5cOeWNogUoXbq0briiGuEfMGCATRO5e/eujkf9+vWxdOlS/i1P5tMQEhKi4/nee+9h/fr1yayNt5MACZAACSSXAIVlcgma4X71S4iapECdP6bOx2FKejNAj6cJdfiVOpRN9cnChQvRq1eveO7gZVMTUL9Ytm3bFnZ2drpIkOoXbilL4ObNm8ifP7/OCFVgnj59OmUNMmPralSyfPnyUCO26hYaGoq6devqIrfHjx/Xzc82ozmptil1hII6UmHbtm1o1KhRqu0nO5YIAmGPsHP8QMw59hTiWgzdp09Bm7yxpQEPxtMbylzdq7fx+I0WadKmR8YcBeBdJC/cY0mfoL29AcP6LcZlTX50mT0THWKtOxE2W3JRZVmotcP64+dLWhTuPAszOuaPWKrLuliE4d72SRg87zCeizNK9piJSa3zICIhuSX7wJpsU74Yc7NgAsobblGG9InyTImjo6MMHDjQgq21DdOUxBuSPXt2nU9U31SsWNE2Om7hvVQWmRd7e3udX5SkShIYGGjhFqd+88aNG6f7u6X+/VJ/Ll++nPo7/a6HVatWlaFDh0b0VxkOLK6urnLhwoWIc9wxDoFOnTpJgQIFJCAgwDgVshYrJhAq1xd/KNntNaJJk1e6rrwhoYZ6E/Sv7JrRW2oW9BAHzdu/T+F/pwCN2DlnlveqtpJPp66U43f0/y8JuTpDKjnaCZzKyLhzQYZqT9K5oAc35OyZM3L28h1JzpP8emN/yZfRQ5TEYfH+ZMzRUn6+pxIKlB2flpZMyj2ZC/eWbQFhkX0IuS6T33dX/oY7SsWxpyQk8orEziKO+qLcb/Zd7X3ZOqCcuCg+t89UQ749nxzSZrfeKhpUIy7cLJjAt99+Kw4ODrovZeofPWXIpSjDfyzY4tRvmvKGPMIf4f8RKZGZ1N9xC+7ho0ePIkRluE/WrVtnwRanftOUea6iJBuL+KyoL8ZUcWUrW1RhuX37dh2HJUuW2Er3zdpP9QWskllXlPmWZm2XjVkegZBri6VhZkeBJp1UGXtYXhkwMfThXhlZNYfYq4JSYy8Z8vhI3VbtpVPHttKsblUp4ZXu7TXdCzF7KdB/hyK7IrfYxVRkmcTvKYJ4ej1RFsMSlzLD5XRIFGGXyMpervlY3HV90+j+X1RfuMb245Curnx/VxWWAbK5e0FRonfikKWTbEq2sIyjvkT2x+jFAy/L7HpeSl814lF1vJwNTDpro9uWCiqksLRwJ2bJkiXii1n4F+atW7dauNWp27z27dvH8ImS5TF1d9rCezdv3rwYPlHWB7Rwq1O3eUeOHInhE/VvmBrxt4UtXFj+888/osyPl+7du9tCt1Osj7NmzRInJye5fv16itnAhlOYgBKNWtG+gNgrgsG9SiyCQXtXln+YXykDsXPzlh4/npQnMf4kvRL/I6tlXOeKksXReoWlxqWmzP0noYGIULm1b4X8sGiR/LDsT7kVNcybpIhlHPWl8GOiNh9yXXkBkUl5AWHnLo3nXzUc1bYAO63RBApLC/aaOmQqXExG/a0KG24pQ0DJ0Ctubm4x/KJkhxU1QsMtZQhUqlQphk/UN7RqJJNbyhDo379/DJ+of8f27duXMgaZuVVVWA4ePFiUJFJSvHhxef36tZktsK3m1JE8ytIt0rhxY/4tti3XR/Q28OhoKa4MUdWkKSRD9r2IOB91J+TqTKnipEyZ0DhLtSnn9IZ1Ri33dj9U7u6dIQO+2SdRB7xaS8QyccIyZu8jziRJWEbcbaE7IXJqXHXdkFjHAr1k50t+fzOWo5i8R/mmY6mb4uQI07JmzYrx48ejd+/eunNcSiECjVl3ovpETRShrmMZNUkM/WJWd0Q0Fu4XNanSzp07oSZHCd/ok3AS5v0d7hM1qVK7du10yWvCLbAFn6jPoLqkyOrVq3VJ19TMpdxMS+Dw4cO6DOrHjh2D+n8mN1si8BzrupZFu2V/w6PRdzizpT9yGsjK8mZjb+Rt8wMe2hfGF/vOYsr7bzOJJ4ZU6LVvUc17GI7alcK4E0cxqoSBLD9B/+HA6l+x/s+TuH73ObSumZG3RFU069AZjYqm129Oq5Rd64vjW2bgy18vQJO3Jb4e2RxeEfbbIUu5FmhSwl3/vliOXq3thlwfLsFz55qYc2UXBuSKLXGRfgUvLmzHhhP3oMlcBs2alIZHePuhNzClejl8deQ1Ko49hoNfl0F4jXGxiLW+sOeKfzbh9GNB1nKt0LhEWtw/vQnLV2zBYb//8FLjjnw+9dClT1dU9XLSN1LvKBR3j6/H0lXbcOzSf3gelhbZCpZBnbad0cDjMnxPP4RdnmroUrug3l3hB/J4Azp6t8eqh65o+cM5rOuei4l8wuEk57fynz83KyCgDon9/vvvrcBS2zGxYcOGoiz8bjsdtoKeqnP4lEycVmCp7ZioznVVo8e2tm3evFkXsV2xYoWtdT1F+xscHJyi7bPxlCEQ9niNtM2URhnamEW6/vYwViPebP1EvOyVuZV2meWj9U9jLRfXhfgilq/O/SSdimUUuxhJgSAaZy9pOM5XHkYdfvtmq3TN6mRwhIfy/V457yhVpyQ86Vf4HMvERSxD5cqU2ro5nq7lRsm5qHM8kxSxjKO+4AsyumwGXb8qf7VMZnQqKx4Ob5NUvu2v2meNOGavKzNPvzTsioDL8kuP8uKuJGmKvEe9T/nRpJG0aR1FWcla3FvFNa89QHwHFBcHda5l/bnyb1SfGG6VZxNAgENhEwDJEopQWFqCF/RtoLDU52EJRxSWluAFfRtsUVj6+/vrsjH27dtXHwaPSIAETELg5fqe4mmnJJ7J2k5+exb7sMbQ/xZLAzc1IaJG0pftJxtvvEm0PXEJy5CbK6SNl7MiajSSrlBjGfrdGtl18JDs3bxExnauIBlVIWSXQapNOCoRg+MVofXzsH7SuWpu3dxPe89y0q53H92La/XldZ8+n8g3O+4k2E7rEZZvkwtpHLNIpS6jZNF6Xzl48E9Zv2Co1MzhpGOYofoUuRR1vqdKQXtHVnUuIo6KcNc45ZCafafK8q175eC+7bLulzkyskcDec89IcJSSVnkO0jyKj6xS99EljyI/blJMHwWFApLK3kIKCwtz1EUlpbnEwpLy/OJrQnLoKAgqVChgpQpU4bLX5j6cQzwF9/vR0uvto2ldvVqUrNBG+n5+TRZecg/Wcs1mNps1m9sAkFy+ItyushT5pY/yuM4q38mW/uV1IkSNbqlcc4mZRp0lkFjZsnSTXvl/D9P45l3qSR+iXW5kaey7qNCuuRBzoU/lk13oiuiV3J0bC1xUwSRnVt1mXU5anTdBFlh7TNLqfrNpFkzwz+tP1sZJUoXR4TRZBFLO/Eo/ZEsOHJPogcLH63pLtmUFwUap/Iy5VJUTiJPf+8nuRUxqHHIKR2WXTfgr0DZ1vs9nUiPO2KpPCgvt0jXbEq02CGH9N0eIfXjfIJ4MW4CFJZx87GYqxSWFuOKCEMoLCNQWMwOhaXFuCLCEFsTlupaw2qCr7Zt28rMmTMjOHDHuATeXFwmXYp66Ia7aRzdJItXdsno6qA7hia9dFxjOHmLca1gbZZB4KUsbZVd8X3MdRYN2vfqoiz+yEcy2BkaRmkv6bIVkeptPpUZG84ayBgbu7AMu79cWrgr0VCNmzT74Z8YYklny6s90i+fqxIxdZRyo09GEUUmEJa6YbTvhoca2HetOFb8IrRvSghLR6k29aLBjKxhD5dIQxeFpV0m6bYxyqIx2ofyU4scumhmxvpz5FZ0RaqDnAhhqb0ts2tlUvyRRurPvWnwceHJxBGgsEwcrxQrTWGZYuhjbZjCMlY0KXaBwjLF0MfasC0JS7WvahRk7dq1Er7cSKxgeCHJBMKe7JZP3nMTjTKksHzfn+SvR+8iGkEP5dyWudK3ZhHp9CuFZZIBW9uNIVdlUiV3RdC5SJtlCZ03GST/HflVxvVtI1WLeomboyGR6Sg564wQX906j5FQYotYhs/f1DhXlZl/60fZIu9+Leu75tOtoZi+3hy5EyGMTCAsncrIoNV/yK5duwz+7D72d5R1Pi1LWEr4vFPFpx+siPJZDtgh3XM464R5rRmxLROSCGGpjG3Y2K2A4g8HKfH5gUg3cS/JBCgsk4zOvDdSWJqXd0Jao7BMCCXzlqGwNC/vhLRmK8JSXT8xffr08umnn+qwUFgm5OlISplQ8fumrrJMgJ1kbTJfbkZEXKLUpX0pL15GfGOPcoG7qZJA8BkZUTK9LiFPj81RoluJ6Kz21X25fGyXrFk0RYZ0qSfveaR5G/2GnWRv8b3euo6xCcsH37cUJYep2Hu2lw0Bsc3XC5G/vn5flyTHufhQORYUXs74wtIakvfEFrGUgJ3S08tFtyxM2ygvicIeK5FMZ3W5GHfp/FsUwann68QIyyDZN7i0MozaXgr236FXCw+SRoDCMmnczH4XhaXZkcfbIIVlvIjMXoDC0uzI423QFoRlQECA+Pj46DISBwYG6phQWMb7aCStgPYfmaUMXdMoQ+S6/pbQ6FTSmuJdVkIg+KR8WVwVllmk15akCcvoPQ25t19GVMmqRLKU+ZDOlWTalcgIpGFhqZV/5zQWZeERccjxkWyNVViGyoWJNXTC0qnwADlAYWlwKGyswvLeYqnnZKf4OqN8vCE2XydOWB4YWkYnLPP12RL9MeBxEghQWCYBWkrcQmGZEtTjbpPCMm4+KXGVwjIlqMfdpi0Iy379+om7u7vcvHkzAgaFZQQK4+4E7JNPlDlquqQefpFf9o3bCGuzKgIhl2RcOWX5CmVuYwcjzq19sa6HLtMs7LNJn62RIsawsBR5suRDcVUT87i3lFUvwyOR0UkGyaFhZRUhA3HxGSFnIpb1YMRSj1QsEUt5tV7aeTjqIplNF9/VuyXyIDHCMlB29CmiJPpxkKJD9kRWwb0kE6CwTDI6895IYWle3glpjcIyIZTMW4bC0ry8E9JaaheWK1eu1M2r3LRpkx4OdZ7lgQOcs6MHxRgHAX9ID2WInMalmsy+GWKMGlmH1RN4LIsaZdEl76n97TXDEbAk9FFdiiKPujyIQy4Z4Bu5LElswjLw8Agpoq7H6FhUhh8LMNyi9oEsapxVl3wmS9tl8iyilFZuzKivi3i6lPpCTkQIzogCCd6xnuVGYk/eE1vEUsJfIihDV/P12hy5ZIsencQIy2fyY/Nsumen2lQ/vVp4kDQCFJZJ42b2uygszY483gYpLONFZPYCFJZmRx5vg6lZWF6+fFnSpUsnn332WbwcWMBIBAKPydCi6QRpisnIE0FGqpTVWDeBQNnVv5gSdbKTnN3WxyI21B5q5c6acTJq3aU4yoSTCJDDX1bQLUti79laVj6OjEDGJizljZLxNa+a8dVBvAfvjpIYJ7xOkZBr86WWmzpHMGbm2HsLWujmaDrm7SW+gZHtRd6dsL1ULSyVPLqnRleRNEpk2D5TXZl3OaaAf3lpnfQp8zZjdLzLjQQekcGFlb8n6pzNtc8TBpil4iRAYRknHsu5SGFpOb4It4TCMpyE5fymsLQcX4RbklqF5Zs3b6RkyZLy/vvvS3Awh2SG+9v0v5/JsjY5RaNxllozLhstOmV6u9mCKQk8/KmdpFPEhjpvcX/EvMXoLWrl5swGiihJKwXrfyKzN5+RB4beTYQ+lKPfdZHCLspcPuU5Kzt8v54QjVVYKqLn3JS6Ojs0rkWlz9rr8nbG9Vs7Qh8elDE1c+gywjoV6iM7X+iLx4DdgyWvGiF1LCCf7noS3fgEH6duYSkSem+TdM2jjFqARpxyVpWe4+bJslWrZOmCyTKoXWXxclb8pgw1Vn/iE5bBZyeKj5IR2M6lqsyKNZNvgtGzoEKAwtJKHgMKS8tzFIWl5fmEwtLyfJJahWXPnj0lU6ZM8s8//1ge9FRu0eN1PSWH8gXcMU87WRFjOGyo3D+2TNaeUCMZL+XqwT/E9/Qdw2sKpnJOttS9kBvfSQ0XJRLoWEiGHYwctqrP4J2wfCc6oAgTh/Q5pWztFtL+4z7yySd9pNsHDaVs7vRir4hUVVQWbrdALkRLxBO7sFRaC7gk85sX0EU6NXbppUC1VtKtb3/p1bGhFPd8m2nW3qO8jNr7KOYz+eaQDFKX0VHt8igqjbr2kQF9u0m7htWk8/wr+l2J4yi1C0u16y/+WiCtCqisoq3Tqbw0KNxipIxslVeJYGvEo80vcZAKlfMTauiin/rzXeO4hZfiJUBhGS8iyyhAYWkZfohqBYVlVBqWsU9haRl+iGpFahSWS5cu1b0N37ZtW9Su6u2PHj1ali9frneOB0YiEOovSz8srHx5VyIWXu/Lx6NmyuIlP8q8b0ZKryYlJZOji+iWKAg+KyNLpRfPD1foRZzisiL0/lrpXq6uTDgSc4hdXPfFf00r91b0k3L1R8vRWCNq8dfCErEQ0PrL7DrqPEtl7l3PjRLbQhTaF9dl56JR0qVeacnh6hBTmKhCReMoGYs1ls9+OiaPDaxaE6ewVM0LvC6/fdVcCrlFq1/jJDmr9JQfThgQle+69fTILGmeP300uxyl6pQLsXQ85mlbEJa6Xr9UfLl4onzWp5t06dJd+n0+WZbu91eixIHye49CSmRYWSqmy9qYgMLPBB6VoUXUYbCOUmncKSXezM0YBDRqJUq4mJuFE8iaNSvGjx+P3r17W7iltmNeo0aNkCdPHixcuNB2Om3hPR05ciR27tyJ48ePW7iltmPe+vXr0a5dO4SGhqaKTvv5+aF8+fIYOHAgJk2aFGufqlWrhkqVKmHatGmxluGFZBAI9sfGsYPwxXdbce1FqC5sodamsXdD3sqtMPy7H9CzpD3ePHuGQOVcRjdlIYgEbNo7i1C/0AQU23wFc+u4JOCOhBYJw+3vmuO9GV7YUbn3aQAAKm1JREFUfHkhajspsRZuRiXwaE13lOjwMx5kqI25J3agfwHHuOsPfIgr5y7g6q3bePTsNYKVXK0uHtlRwNsH5Yplg7ImZbK2sNf/4q8DJ3Dl7jNoXTKjQOkqqFQkE5SMsHFvwQ9x/sABnPZ/jBBHd2TLXwQ+Pt7I7qosfsItAQQeYlHj4ui7/SnKjj6CE2PKGrgnDHdXfIwyXZbhoXtDLDrzO3rkitczBurhqegEKCyjE7HQYwpLy3MMhaXl+YTC0vJ8kpqE5evXr1GhQgVkzpwZu3fvhoND7F9EKCzN9Cy+uYdzJ07h2r2XkLRZUdinHErmSPe28bCn2D7xM+zMPQTTPioOzeNdmDhkC3L1+gCBa2Zg+b5rCMhYEu1GTsPndbxgF3Iei/r1w9hfzsCtRmOU8bRXVppogOUzP1bqe4Gzv07D5J924OL9ELgXqoaPho9G9/KZYYcwPN4+FZ/94YmebcKwevoy7L/xChlLt8HIaV+hTnZ7hJz5CX37jsHSi86o2bgsMtvZIXvj4fi2i7eZQNlAM0HnMa5aTYw58Rx5P1qJYz99AE9qMRtwvH4XQ68vQINyn+LP1zkxcOclzKpl4AXRy4MYXLExZl8OhPfgHTg6ozbS6lfDo6QSMEbYk3WYngCHwpqecWJb4FDYxBIzfXkOhTU948S2kFqGwoaFhSnDrbqIp6en3L59O14MXMcyXkSmL6D9V2bWyizv/W+XLolK6K15UtPJSdxylpPOYxbJ2g2/yuQPvMUlWxtZcT9UJOS6bBjbRgo6ukulj0fK119/LWNnb1XsDJS/ptSXTJ7lpff0ZbJh4wr5tk8VyZylgXx/XU3cpBX/WY0kjWM6yVmho4z9YY1s+HWqtC3sJjnaLZUHynDKkKubZUyLIpJGmV/XbdTXSt1jZPb2v03PwMZaeO47VAo72onGMbd0X3c75jxGG+OROrsbKHtnDJDh3y6THceuyv2At+OVtQH35ezmadKuaAZlKLFG3KtOlAsGl215LrsHlxUnZSi9Y+6Osv6e8tnnZjQCnGNpNJSmrYjC0rR8k1I7hWVSqJn2HgpL0/JNSu2pRVguXrxYyUSqkV27diUIA4VlgjCZtpAhYemSS/rteBnRbujfc6Sqi5f03f5ady709vdS21V/3cKwR2ukjWcO6bQqShKgkCsyoWImZW7WaWVu1lth6Zq3h/zxOjzT59t1CV1zd5cduqUjtPLf3CaSNm9v2Z2MpSQiDOdOLASey86BPopoUJajyFpP5p6PLZFPLLfztBUQeC3L2+SImIeq0diLo7OzOKoZdXXJfDSSrkgnWXbF0DzpUPl7aRfJrXv5kEu6/caXD8Z2OIWlsYmaqD4KSxOBTUa1FJbJgGeiWyksTQQ2GdWmBmF59uxZcVa+uKgRrIRu3377rSjDgBNanOVMQcCQsHTNJ4P2RBEbL1dIi7QZpctvr3QWGBKWAb7KMhBpckr1zt2lR48e7366Sd2CacXr43US8E5Ypi3YX/ZGEY0vfmkvaTN/KOt1WUUpLE3hYoN1vjolk2vllnSuaSVjyW7ymz/TshjkZLUnQ+T8ipHSo3VdKe9dUHJlzyQZ3DJIxuz5pXSNVvLptPXiF20pl7ddVRJo/fGVVPB0E1flM1/py93y1GoZWK7hnGOZ1DHEZr6PcyzNDDwBzXGOZQIgmbkI51iaGXgCmrP2OZYvX77UJevx8vLSJYayt7dPQK9ZxCIIhP2HWXXLYGGJlTg7uy4c/pmPukWno/TWi5hZ8928q9er0Spbf7gt8cfSNm4wlLznze/9UKDtHyjTuxWK6SXd0SCtT2eM6lgCt2c3hfd3+bD1wneo8a7Mq+UdkX1wGJbeWolWrsLkPRbxUNAIEiABUxKgsDQlXSPWTWFpRJhGqorC0kggjVgNhaURYRqpKmsWlso7YXTq1Al79uzBmTNnoP4d5mZFBJIiLO8tRsMCY1Bo/VXMb+Cq62zohSmoVGEJ6u4+gynvOxsAEIZbCRCWd+e3RKGpWbD+6g+orydQDVTJUyRAAiRgjQQsN5hKy6IS4FDYqDQsY59DYS3DD1Gt4FDYqDQsY9+ah8IqSwmJnZ2dKMLSMmDSisQRSMhQ2FerpGU6dSjsu5UPX22WTp7ppMqE07qEPxIUpGTeuS5z6uWQTBU/lXWXX7xNCBPyVC5umyezNlyX0FiGwr5c1kHSqUNh3827fLmuh2R2rSATz70dihsUxCGaiXMoS5MACVg6Ac6xtHQPvbOPwtLyHEVhaXk+obC0PJ9Yq7A8deqUOCkZRCdMmJAkqD/99JMoa6om6V7eZCQCSRGW8koOjqklmRydxD2rp2T0/p/OmNDbO+XrpkUlvaOzcj6bZErrKE6ZvaXn8r8TLCzl5REZXTm7ODq5S1ZPdyk55E8jdZTVkAAJkIBlEOBQWCsJM3MorOU5ikNhLc8nHApreT6xxqGwz58/R9myZVGwYEFs27YNStQy0WC5jmWikVnQDVo8978AvztByJCnKIp5uUXY9ubeFfjdfAr7jLlQsIAX3GJfyjTiHr0d7Qv4n/fDnWA35ClWBF7pOGdXjw8PSIAErJpACgrLMDzYORn/m3MIL8QFJbpNw9S2+ZMMU3tvF8YNnoMTz8PgWuJjzJr8AXIm/rtAkts39Y0UlqYmnPj6KSwTz8zUd1BYmppw4uu3NmGpvPPFBx98gKNHj+L06dNQ1q1MfKeVOygsk4SNN5EACZAACVgxgRQTlqE3lqJttd7YfC8MBTv/jF0/d0KeZL24C8O9bUNRr+1sXAjKgLrf/Imtn5VGGit2TlTTKSyj0rCMfQpLy/BDVCsoLKPSsIx9axOWc+fOxeDBg7Fv3z5UqVIlyRApLJOMjjeSAAmQAAlYKYGUEZahf2Nh85r4ZPt/SP/+SOzcNRbl02qMgDAYfnPaoPrgLXjq9j4m7d+NL0q+SymehNq3bt2KQ4cOJeFO498ye/ZsVK9eHWXKlDF+5Yms0cXFBf/73/+QIUOGRN6Z/OJqBGHt2rXJr8gINaxevRrp06eHKjBTelMWboeyvhry50961D+pfbh37x7UL+NqpCelN1UM3Lx5Ex9//HFKm6Jrv2nTpqhcubLZbQkJCcHkyZMRGBho9rajN3jlyhVs2LABX375ZfRLKXLs4+ODtm3bGmz7xIkTOjE5ceJEDBs2zGCZhJ6ksEwoKZYjARIgARJILQRSQFgqkcVV3eHT+RfcT1sJkw78mSzxF8MRoTcV0VpdEa13kKnhbBzbMgD5khgJ9fb2hp+fHypUqBCjGXOfCAoKgoODAyxhDbXjx4/rvii2bNnS3BjQrVs3LFmyxCJ8EhwcDFXQOTo6mp1D9AZVn4waNQrjxo2Lfsnkx6qoVF80WMLnJDQ0FGFhYUiTJuXHKqg+adKkCbZs2WJyH0RvQH0hVrVqVRQuXBju7u7RL5v1WKvVQvWLkgjHrO0aakz1iYeHB548eRLj8tOnT3Uv7kqUKIFNmzYlaV5l1EoHDRqEokWLok+fPlFPc58ESIAESIAEUi0B8wvLoJP4qnwdTL0QgGKDduDYt7WR1sh4Q85MUaIEI3EyJCc+2XoO39VPn6QWSpYsqZtro35h5xZJQBVTagTCFMJSjXqp9ce2qZEoNbGG2j63SAJqohFVxKSEsJwzZw5mzJiBW7duRRrEPfTq1Qt3795NEWF58OBB3Ry/R48eIVOmTPTGOwILFizA+PHjcefOHT0m6t8d9e+ZulalOioiY8aMetd5QAIkQAIkQAIkED8BswvLJ+t7ofgHi3E/Q30sPLsVvXLFl1LtNa7sWo3Vv+/HuZt38SzIEe5eBVH6/Tpo3rI+SmYx9Bb8KVZ3LIuOK28hc/OFOLOhF7InIZEPhaXhB8iUwnL69Onw9fVF9+7d0axZM6jDbqNuFJZRaUTum1JY3r9/XxcFzJ49e2SDUfYoLKPAiLJrSmGpjmBQh/wWKVIkSouRuxSWkSyi7sUmLNUXI1999RUOHDiAihUrRr2F+yRAAiRAAiRAAgkloLypNeP2VJZ/kEvsYCe5Oq+WJ/G0HPLvDvmyVl5x0kCdvBXjR+OaW3qvf2Swlje7h0h+B43Ypa8jC/9J2iLEypAoUSJABuu35ZOqL5SIoUkQTJo0SednRbyKq6urKENfRZk3J8pwOl17H330kSiRBZO0bc2VKvPGRImsm6QLf/zxh84nNWrUkOXLl8urV6/02lHm/0ru3Ln1zvFApGfPnqJEkU2C4uHDhzqfeHl5iSLs5cGDB3rtKAJJd12JWOqdt/WD+fPni/KCRA+DMmxYlGkGMnPmTL3zPCABEiABEiABEkgcAfNGLF9vQZf8bbH8UTp0Xn0Vy9rGPtxIe387PqnZHosuv4RDFh906N8PrasXQWbNc/ifPYjt61Zhw6HbqDH/Jrb1yRFTRwfuQ/+ijbHglgYtf7qODR9ni1kmnjOMWBoGpEYs69Spgzx58hgukIyzZ8+exfnz56HOX1Q3df6imohE3UaMGIGLFy/q9jkUVoch4h9TRiyVRd7RoEGDiDln6vxFNfmJIvJRq1YtzJs3j0NhIzwRuWPKiKU6xDV8GQx17rU6r7R+/fq6OcjNmzfHyZMnORQ20hURe9EjlipHNSFa+fLlsW7dujiH4UdUksAddeRF5syZUbp06QTewWIkQAIkQAIkYN0EzCosg45+jTLVJuBKuqZYcn0TumSKbS7dK2zvVwnNv78IydoIc3f/hn7FXKORDsatnfOx1a4r+tc1JFBfK2KyJNr+cgt5em/Epe+bwtCg2WiV6h1SWOrhiDhQhWW5cuUQ29DIiIJJ2Ll27Rr+/vvvCGGpJitSk3+om/pF/d9//9UlAdm4cWMSak+9t6iJplRuSpTX6J1Uhf3Lly8N1quKzLp16+peBvzzzz8Gy9jqSfV5VSK8JvGJKiSfPXsWK1p1vqD6GeEcS31EUYWlylDN2nv58mWcOnXK6EmOmBVWnz2PSIAESIAEUj8BswrL58s7ImfXlQgrOwpHj4xFCQfDwlIer0KbQl2x4Zk9an7zF3yHFkPiE7uG4d85TVFw4HY41ZkJv52DkDOR8ywpLA1/AEw5x1JdImH48OG67LdK8B0NGzbURWHUL4DOzs7gHEvDPlGjIrly5UKrVq0MF0jG2QsXLkAZJhhRgxohU8V+3rx5dVFkNcPmd999x+Q9EYTe7qjCUl2+Qs2Ya+xNFfpq1tHwLTyynzNnTt1nRM3Qq0YuKSzDCb39HVVYTpkyBaNHj8bhw4ehRvyNvVFYGpso6yMBEiABErB4AokbOZuc0qHiN7mWOEIjHq1+lhdxVPVma3/JYQ/ROFWQqZeD4ygZ96XXm/pKVjuIk/cQORoUFndhA1c5x9IAFOWU8lCbbI6lIixFib6JIlREnUcWfeMcy+hE3h6bY46l6ndl+QRREiyJklUzwhDOsYxAobdjjjmWqk+yZcsmyssYuXTpUkT7nGMZgUJvJ3yOpTpv287OTpRh3HrXjXmgLPciQ4cONWaVrIsESIAESIAELJqAuqi5mbYQOTmyoiIs7SRnt/USEGurWrk7v5koq9CJXeZ2sv514gVheNWB+7+QQkoCH8d8vWV3YOLrobAMJ6n/25TCUlnQXb+xaEcUltGAvDs0pbA8evSo7guyMv/VYOMUlgaxmDR5jxIlFiVzsuzZsycisVVUKygso9KI3FeFZZYsWXQJfD788ENRhsNGXjTyHoWlkYGyOhIgARIgAYsnYMahsKE4Nrwyqk3+C9l6rMfVxS3grCiUmFsYbs5qjCKD/0BYjo+w6cbPaOxseMhszHv1zwQdGoGSNSfjZo7u2HL1B9RX0ssmZuNQWMO0TDkU1nCLkWc5FDaSRdQ9UybvidqOoX0uN2KIyts5wVzH0jCblDqrJpoaMmSILvGYmuAoffqkrXGcEPvbtGmjSww0cuTIhBRnGRIggQQQUL5VY+nSpVCyk6N///5GTbiVgOZZhARIID4C5pO+oXJ+fDXdUFjPD1fI6zgafvRDa1G0pNi5t5AVL5L+Rjngj/9JLnuNOL33PznIobBxEE/cJeWZMtlQ2PgsYcTSMCFTRiwNtxh5lhHLSBZR90w5FDZqO4b2GbE0REVk4sSJuiGwf/75p+ECPEsCJGDRBNRlgdTvIOrP119/bdG20jgSsEUCZoxYAg9/aI3cfTbAvvo3uLB7GPLGkpEnaP/n8K4zHTc0BTFszzl8U8VwbDM+0fzk5w+Rq8ca4P2JOLN/OArF0l5s9TBiaZhMfBFLNWGIi4sL0qZNa7iCZJxlxNIwPEYsDXNJybOmXG4kvn4dPHiQy40YgPTtt9/i888/R+3atbF9+3ZdkjADxXiKBEjAAgmoUUplTjm++uorqEnk1ARcyhq+umXJLNBcmkQCtknAnGo6wHeQ5FEiiA7Zu8jvcc2dfPmH9MjporyRspeCvTbJk1iN1Crzi2K7GCT7h5QWByVZUNaOq0R/SffY7tE/zzmW+jzCj5RPSoyIZUBAgKxdu1Zq1Kihe5OopPAPL27U34xYGsYZV8RSWRNUtmzZIqdPnzZ8czLPMmJpGGBcEUt1bp+SjVT++OMPwzcn8ywjloYBqnMslbUlxcnJScaNG2e4EM+SAAlYJIGff/5ZlOzw8vTpU1GWHtN911DWWbZIW2kUCdgqATMm7xEJe7RMmrk5CBzzy5B9safvEQmRUxNqiKsyHFaTJpe0nXdSnkbzUMB/B2Renzry0eLb0a68Owy+IKPLZhBo0kjtmdck1HCpOM9SWBrGEy4s1S/H6hdYJTIjSnRSlEim7ke9TmFpmJ2pzkYXlqpvlKUuRFnqQtzd3XX/Aa9YscIkzVNYGsZqSFjeuHFDxowZI7lz59b5RJnvZ/jmZJ6lsDQMMDwr7Pfff68bErt7927DBY1w9urVq/Lff/8ZoSZWERuBW7duyeDBg0WJQOt+1JcFamIrbqmTQPXq1aVDhw4RnVOWVZK+fftGHHMnbgKHDh2STp06SaVKlaRbt26yf//+uG/gVRJIAgGzDoWF1h8z65bHZ3ufodhQX/w1rQacYgsUB1zEnDZN8dkOf4QqpbKVqI6a5QvCHc9w98Z5HDlyEQ+CHNFo4U1s65MjRi2hF79BZZ+vcEJTHGOOncDoUkqe2URuHAprGJg6FFbJqIjVq1cbLqCcVdc4TJMm8cxjrfDdhXv37qFmzZrYtGlTfEVt6nr4UFhFzGDJkiW65AaKiNENEQoJCdGxmDZtGpo0aWJ0LsuWLYP6o7xBNnrd1lxh+FBYlc2vv/6qY3T8+PEIn6ifI3Vo97Bhw4zezb/++gtdunThOpbRyIavY3n79m0dH19fX5w5c0Y3vC5a0WQfch3LZCOMtQJlFIbuc7Nw4ULd+r3169dHUFAQtm7dqhsiuXz5ct3/E7FWwAtWR0D9/6xgwYLYtWsX6tatq7NfHQo7d+5cKC9wmMQnDo8+f/4cvXv3xpo1a6CIcygvonVrLKtr+CovY3TrUav/H3EjAWMQMK+wRBj+ntMcJQdtRXCuj7Hhwk9o4hbHwxz4NzZO+gIj522G35Ng3Wztt53WwM4lG3wadcCQcePRwds1GotgHPr8fdScdhppyo/C0cNjUMIhjnai3R1+SGEZTkL/t/oHSHnjDyUqCWUive5i+ALt4SWV9dvg6ekZfmi03+ofRi8vLwrLaETV/yiUyCSU5SeiXXl7qKzZByWKafCaMU5mzZoVqujnFklAFZanTp2C+oVI/Y89+hb9MxP9ujGO1fnO/2fvOsCiurLwmaEjgqixYtSogKirUdRYgz26aoxBNKtx3bVFsUVddI3EXrCDxoIl0Y3YsKFiL6trwV6wxIIaYyHEEqkyg2fPecwgwzymMgWZ+306zO3v3Hnv3f+ec/5TqlSpgujqvehDCSwpDqvAKtmwYUMBVDLAtLPT0wlfi0RswFKLgAwslsvl0KtXL+A1Y5/Zvn37CmCSu3v16pWwgY6NjQXeNPM73LwpCzLT3oBMCPesYWSJHTg5O4O9VEMdCxW9lWdAxpu3IHVwBmdH65lgWFgYkHWMACL5fcaJNHBAYX2A7+fy5ctbSGIGDpvxDK6cuQB3Hj+HdKk7ePnWh4Z1PwS3AhY5Hyx36tQJbty4AWvWrIEOHToIEyZFFKxcuRJI4yt89u/f38ALsTWzSUBVAmYGlmQj+Xw79K79FWxIdIYOEWdhzzBv0Po6z3wBt86dgasJz+C1zBE8K3mDf6P6UNnDXvVqFN+ynm2Br+r1gS2/u0CXFZdhx8AqYMi9agOWouIVTga3b98O3bp1Y1NqYO3I2rVrBY2McgPNoNPHx0e8AyNybeQ94sJTaiz5VJKp2Hk9yBQvRzvGrebPnw+dO3cW78CIXOV4No2lqhCVGkvWnmzcuFFYl9OnT+esiVJjOX78eNWGBfCNQ2mQyZNNY5lHlrmBJRfFx8cDmdPBmDFjYNq0aXlqG/e16ALLDHhyJQ4u3vkNXqRLwb2iD72v64KXm9Y3vVaB8+EY+dkDv38YWJJJn1obBp4dO3YUnn8Ue1c4cFOrZKqM9F3Qu1IgRD3P1DyC018MtqTS3LGxpXK4PDkAGk2JA5+QI3AhrAUUvN2RYXNkwq0qZAnF4EiZeL/BB6r79u3LAUzKMmv9lCeegZVTQmHuz8fgQbL8ncKEDhvcq7aA3mOnwZRBzeED428XYX9G8Y5h27ZtwIRu5N6lJhZyzQAG7byP8/PzUyu3VMbbTDrgkGW9k4/GiUjA3tkVnPSV2Vs5ZGS8gbdSB3B2djQIJ2icVlEtNMB81sgmb/Di1JboQv6TDh/2xm2Jhng/appCCh75tj46kL+fs98IPJ5ieLgSm4+luJzpXlEj7+GaTBKza9cuDAoKQvYlM0WykfeIS1XMx5LJetj/qGTJkjYfS3GxmTRXzMfy/v37OH36dKQNks3H0qTSF+9c6WOZu5QJQQjkFziREmlSkCw3cg/1fv8tT8T/LRuGAVU90I7e7/yeyP4nQTv3Ktjmm8V4KpF0eQYm9hungzOBvIUsMzT2wn6WZEVhfvmnxeDfSjki2FfEln/rh3QQKv5vQCjueGi4LDRevFGFMrw0qRmFhbPH2iHH8Y1RfRVc4+TkZCQLD6QDOrVO+Vk6Z84ctXxrzEiL/wl71ihOzxspevi0x8GTI3Dtpi0YtXIRTuzfBqsUs6MyJ6weuBTjNRFc6nhx7M9P7LlI5sP5tqCDGCTLDSRFQb51zF/wBk+M/ZjIN5XPEG2fTthldZLe08y8PB0/dqCQhH6j8bQBIQn1HrCINDAreU+OTP88hsN93OgGssfq/Tbjs3yZXXNa6PzHyyPj0M9JihJ6sPfb+gSN6doGLMXFnh+wFK9dsLk2YCkuz7zAMnctMoVBCq2A5EuWO7vA/raR94iLUgxYKmvyJjkuLg5NxWhoI+9RSlr1UwxYcg0GAMwWW5BkO0UKWKbdxFW9alH8aQlKPWrgZ4Mm4eK1m3BL1CpcGDoAA6q4o5TKXD76AiOvJasuio7fmOiKwQU/y3RJTNBEfv4mO+QUnYMCWEpc2+PK3w0/1Bbt2yyZ1gks+cCaD3/ItF9NCsQbgLwvsPb09vlhDPYlUCktgY1GbMGEDPXfR/rtaBxQx5Ou1RHrjNynRlqpzzWS1ZJwsEOcC1qbkcZXqEuWLlrrmqeCHO9snIj9VQ5m+mJ7X3eUULQIr6ZBeQ5sBuCi46/1npoNWOotMp0aWAZY0tReHvwX+hIABGlp7BRxBTN0mq7mSrKEKAz60EUArNX+vslowGoDluLytgFLcblYMlcTsDT1vGzAUlzCmoCleIuCy7UBS3FZ5gcsU1NTsXbt2shgkA9iCiKlpaUhEcoURFdW3sdL3DesHjqSFqZUw2Dcfk+E8T3jLm4c2ACLMbj0C8bDL9U31ZoucsOGDcLGNzo6WlM1lTJex1q1apkXdBgALFMSH2BCwlNMzkrG2wfXYcTilbg97jdVbWHqIzwTsw5/WLgAw1esx0PxiarlwpWnYOKDBEx4+poO1LPwxc3DuH7ZIlyw+EeMvZr0jhk/9SGe2LISwxdE4I87zuFTlZ+o4cAy5dezGLN2KS5cEI4rog7g9d817epkmHhlP2nqFuOCRctxw8F4fK7BeG3YsGHIDLBiadSoUdisWTOxIivKk+EF0gQ70T3i9eWP+EiDxiPzegQGeNijxKU+Truisjg6Xw9bjFEscfzuu+90asMHnSzD7t2761TfMpUycPcAb7QDR2wbnmCU0kg5fxuwVEqiYD/N7mNJoESR0uD87C+hy4zjkOxQFXpH7oIVgVWVhXp/ZiUehnGf94Xl1/4E19pDIHr/HGhZQn/CntwDs705E28MHTo0d3aR/3vRokWCjwv7WJo7sY8l+w/Sy8TcQ1v1eLwmoaGhAsObuScaEREBI0eOtK1JHsHzmjBpAjNVmjuxPw37+DEzrI285530maGXNlFAppLvMhV/sV+4v78/0CZWCLyuVsGWISoB2aUZ0LjJ93C1ZFf4KS4a+lTKx9FJ9gvM7xAAIcdekg/fKTgRWh/EWRJUh/n1118FEh72FWOyHn0S+3+zrzP7f5cpU0afpobVVfhYbkgPgMgH+2DAB9r2IGmwIcgb+uzxod+dHNbNOw6viGNN6twU5l47BqOrIyRs+x7+OWIxHH+cJtgD8sQk0uLg2z0UVq8YDU1KKuSdugO+qhQEsc2mQmTNfTB84XFIkjMep/oOZeGz2bvgpxbnYHCvcbAzISW7L4kUSjUaC9F7Z0KAJ/djgI9l5gPYNmEQjFhyGB4T6U92IoJF9xoQOGk1LBvVHErmIrmQP4yFiQNHwpLD94CsPRXV7aDkx/1g6aYfoGd11VgBtOUFb29voDAjou83OiwS8q2aPO7NKRhVpz2EP/CCcccvw+xPnBVyEvtIpUgH/tA18i74jD4I1+cHiFXKN4/lxay5FOsTyCpG8OnPt3KuAmb579Onj0COxGR81peI9XngX+DzVQ+gVfgt2D+iqkafyNRH5+DI0fNw77kMXMvVhOZtW4LfB6q/LdkVenYRweeNGt/CsUvz4BNHbferQippv0Hc4aNw4d4fIHctC7WatYUWtcrk648sT7oGhw+dhdvPUsCxnB+07NAKapbU5elnfaugy4wsCCx1mZ5l6zCVNZndgJKBzJKzef78OZCvnFVQarM8+IXN7KzmTlu3bgUGMtawJuT3IYRUoWDr5haD2nj8MmHyEQYT5k7MfMohM3jDbunExB28Lp6enpaeiiAPMtEC3hCbOyUmJgrsmMySaQ33CrPTkqmpucWgNh7/Rps2bQqzZs1SK+MMivUqkB6R6Z1JiK5EBy3UmZnw328bQdtF16FmyFE4H9Y8380VX2bK3uFQq8sPkFhjOBy+sgiaadnIZWVlAZO28O+YN8nOxKSqT+IQJBUqVICJEycC+Zvr09SwugYCy97Rz8DOtSp0C50OA/xewYETDhA8qx947B8DTbtHwB27yvDXEeNgQHtfcE26BNHh82DN6adQImAmHNkbAnWcaEOsAJabZS7gZu8Ffx0dAl+3qAQpZyJhwqQtcM+xMtTwfAnShsNgQv/WUDH9CqyeNAU23EiDpjPOwf/+zQy6egLLty9hz/BW8OWyq2D/0WcwPGQQtPcpBr9f3A7hYavhTJIrtA47AnvGfpwdWi79HIS26AgzLiZD5fbBMH5wJ/B2ToQTa2bD3K3XaW6hcPTEZKif63fBhGfM/MphgcTIZ8idQCDuYSIfd3d3w9bNxK3kNyj8Xb3xcLn8P2DX7VXQgddLQ0rZORiqd4+EZP/JkBo3SUNN9aJVq1YJTK9M4FavXj31Cvnk8L1Srlw5IA4ACA4OzqeWJbN1BJZ6HHToDywzdT/oYVFlPYKYiYNh5OID8DBVSUREREOedWHA0k0Q3stb4/PSktI2auyCVYDaejOVBGgzhKYM5m2qeb/P/bJ5DsWGfJ8vsdBdGzEGqgTQLnQX8B5OmH17iSEa2dyqMCQmiGHCq4cPHxo13YyMDIHQzKhOrL2x7BZOa1SCyGoq4Dd7U7XPNmU39i3nhODUAGdcz9Raf+bMmQJZD7H3aq2bXwUKp4DsKmCWpCTvcfgIO48MwXHjxqn/mxiJp18r74VUjOpRUfAb+2hQDKp4n2bG4xR/8rezK4s9frr3zpSVLyT5PE7+pDT563li4Nrfss0CU7ZjL08Hci8qgV0j7+UyFUzCNZ9XoDEkWCIgDG/lsvRO2ROMXnYS9Oy6SiEe/UxhM6/Mwgbk0mRfoRuuva+6nslxM7Gxmx3alf4c1z1lO9csfPJjEJaQSrF0u/l4MzdZiuwOzg8oQ9wYFXDIvhTFXN593L17992XPH9xGW2CTcYhkGc4g76m7hqC5aSArk1n4C8aTH6VnctuzMVGDiTXcn2UWTp9so84gWucMGGCTvXzVqLQPRgQEJA320q+62AKm/UCdw+tSybHEixWrSOOX7Edjxw7gBsXDMEmZR0F/9Y2cy/muN7pZwqbhX/sGYXezOHiWhU7j1+OO44cwwObFuKgphXRnsycS7eajVdzfGfT8VRoM8H836lyOxy7bCseOhKL66b2RF83KUrdGuC0CyJuA1YibWOmYTEfS2MmXdTaKh+cZKZV1C7daq+XGXD5Zcb/bMl6JKBck9ev9Xfkt56reL9m0rNnT+E+OXv2bKG4MPaNrFu3LlIoC6N8JIsEeU/aXvxHeSeUODXGObdUgYXoYst+wRmNCYgSt8I/d6oDiNxt2E+YGS2XLFmSO1vvv8ksXPj9URw/vdvq3UAJLDWwWUpcWuOyJ0p0oQCWEjcM/FmVmEZ2cx42JnCRH2PlHxu+xlJSCX7w5dpskhcFsJS6EXHQM2X/fAXEsDmmHjFsOmDrhXdzAU5E5RhureYrLlUfYCnHG7NaaWCQfYlRQR8SaZM79hCuLRnX9/CizX1p/Pu2l3lEm4VJJ6Nw6X9i8MITTb6ZeZrRV/aP5uc+E9BYa0qmtaKQ7Vi8XQQ+1eBfqZy//NEyDCAAI/X4Qpml9ZO0+0hhdtDX1xfT0w0DLDExMUgWLkhmxVrHM38F7cBSv4MOimSgDyusngc98qc/Y1c66LEr2RojbuReDznenP8ZuknssOrg3eYXoxlGtO2KzSBkY4dgymh+cJLJpfAQNbY/W3vjJcAPYCWIoVhpxndo68FoCZAvVs6acAgJW7K8BJjKnnw8hXVhDX9hSRQDFosXLy6E6zF0zkUCWKZEY6C7AxGN5AZLGiSW9RjDW9HvQVIMe27M//Dnzp07wu+GDyWM1XRzew5JoSuRiYbZay9Skve4NMfpJ68ha1rV/l1/gC9ycJ8CWNp74bBDaSr9p+4cjGUZOAatRzEILruzAJsQ8HSpPwEvyUgDqgCW9hX7YWy6UiPKXb7BUyENSKPiQuD1T5UxZPfCsbmjFN0C5iny9QGW6bijXzUBOPbapNpvdmdyvB3WhoCnA/p/f4528fE4qYEHHUI0wXl3dTiEUJmp5i+spdOF/VRzL6YrTd0xCMuQxrJYyzl4P2ft8x9PCfjty32df6U8JVOnThVYkM+dI1kbmBiQurm54fLlyw3swZTNtAFLfQ869AOWyjXR9aDnVVQfLEFazIpfb8G8Tzp50mn8eel/cPf5x6YUmMX6tgFLi4let4H5pVipUiVhY8Z02+QDpFtDWy2TSoDZ0/g0nenvi1SsOpNK1bjOyW9OWBO+T8jX1LjObK0LRAL79+/PAfseHh6FyjR08+bNwtwpuLhBsigSwDJtD/YtyxrLZrgwQQewILuNMz/J1lj2jxGDS4jkKye885o0aWKw5iXvgpEPODLLu8mTEljqHG5EASzJdHb08dxaDbJ2JS2XO21MP+y/A1VLsq9C/nQltiWtllOt0XiGzUoVwNKx2jd4NMccj+sqgaUr9ohS3eIaBywVc5eWxYG7xdaSTF9/6IKOFBOzTsgJxIw4/FdNCjPn0gaXC6axBbcabGrPz39rTbLrYdiQ4iU6VBmIh1TWRnzGyTu/yTadbTxFvEKe3NjYWCEcS2RkZJ4S/b8GBgbiF1/orinVfwRDW2gDlnoedNA09NFY6nfQI8PLk5sLhyqfzv1F1Yzd0MsvRO1swNLKF+vkyZM5GzM2UWjXrp2Vz/j9nx6xrQkARqmx5Ph3rJmxJctJgA9gqlWrlnOv8NqwBtOWLCsBYnJUuVdY01+YEmtZGRAzfb++qUgAyxwfSy8MPqiqcROVV8oe7Eems+xjOVODjyWbvyYlJYl2YUimcuNNJHiGNNe9TQECy9RdQ7E8aSxLkamrKhzMno4sfjb6E1hxbTQZr/Prx+zAMh1j+lcnjaUb9lif17SV5yjHa9NaCpvrJtPJqkd2E6f6s8ZSR7Pp7MvU6f9PP/0UiZlcp7oWqZRxVgDV4FADx57Q5oucivuH+FFYDXusNeaYTtPlPQnHbTVWu8+DEfMyEolPgfSl0+R1rqQNWOp50EHj6gMs9TvoeYMn2UqAQqN0XKbwgdb5Ogt/xf8DAAD///VKmbAAAEAASURBVOxdBXxURxOfixEhJAFC8OLu7l4oxd2lwAcUijuUAoXiXloKFC/uUApFEtzdCVrcPUYS5tvZcMcluSQn7717d7f7+4W72/d2dvY/9473fzM7AyiaqhHo1q0burq6IgDwP41Gg0+ePFG1zvau3Pz589HZ2VlnE7LNrl277H3Zql7fqVOnYtnDxcUFJ0yYoGqd7V259+/fo5ubm84uZJPGjRvb1LLDw8OxRIkSWLx4caT3prQKFSrgwIEDTRlig+dG4JHBxdEFXDB//yAMS2IFH3b1wSzOGkyWtw8ejviUxNnSHX779i06OTnhli1bpBNqSFLoVmydyg01njVxwTNj1heCK5tlQI1rNux/IDZ6kbdmY8VkzuiWvTsGhsWVFY0PFzTFFBonTNt6Nb4nXT5swpZ+rvz8oHD98z/bSOOJzVa+i6V15K1ZWMHNCZNXmfq5PxLPjiqPrsyeBQYfwIhYZ8f9EIU3p9VEN40z5vrh3/i2j36CC+qmQ41TSmy77g0b/AHXtv6K2SEVtlnzIq4wfLO+FxYrVgW7Lr4c71hSHS1atMDmzZsndZoVj0fhpUk10IvZy7/mDLwWmbAq4ZdmYRUfF3TyLI6/XEjcAglLMf/I0aNH+W/2nTt3zBciy8hw/LtLLnQGN6wx6zZGx5sjDLd2zoFOmuTYbMXreEcRo/Di2Ersu+2KZced58c/nhuHRV3Z71G+/ng0id+jkG09MJ2TBlM1WYqxr6KYqSIvTcQSTJZnqdF4OYrmqsjnqjjpMpvZsRo41nJta7V0I6MllERktGRmxowZtrUQO9O2SJEi3C76NmnVqpWdrdK2ltOnT594NkmTJg1++qR/g2Vba7J1bZcuXcptQjf02t8u+j17/drQf/rqXe3t27fRx8cHf/jhB5OUvHbtGt6/f9+kMbZ4cuTlGVjei/3/lKo6zrmayI1w+FWcWjUtu/FzZzd2ZzCRe2tZYKCHA/3795dFtk6ohMQSI2/i1Mr+jJj54tdTz2KIbhJ2i/xkF36f15sd88e2a5/FHFGcWCJGBs/GSmT7lFVw+nlObz9rGY1P/umLeRhpdUnXHNe9jPkdfr66I6ZhN+d+lcbheX2y/PEm/lorPSOd/thu3XO9lRr3tm/fvlipUiXjTrbWWe8O49CiKVHDCH7+jovwyof4/ze9v7QM2+ZOwc5JhoX770Ki40o3uu+kB4IrV65Ueuok5kuKWJr6oAPRFGJp6oOed+u+w1Ts/750rVZivP/x3m7BrsWKY/X//ZnEmm3zsCCWKrZbcHAwkseyc+fO6O7ujhUrVuTvZ86cqWKt7Vu10NBQ7N69O7dDpkyZMG/evPz9gAEDBImxoulHjhzJ7VC0aFH09/fn7+naefEi/pNxK6rpUFMvWLCA2+Hrr79mN0oanU3OnDljczhs2rSJk+Q1a9bYnO7yK/wB9w8ri57MxsnztcVllw08z/9wBRe1K4ge7BzPAr0x6E38m2q59ezXrx/3Pss6j5TEkin67tDPWNzbGTUuqbFkmxE4a9ESnD+5H36by4ddU86Ysf7vGKx1h0hKLJ3QN291bNK0KTY18Neixzy8GEk2/IAHR1ZAb2ZXV/9i2ObHmbhoyXyc1Lce5kruhBrnAGw47+oXj83Hazjr6wzs4YILpi3dHkf9ugiXzp+EPWtkR3fmzUtVcRyei+VtNc5aEydOxFy5chl3shXPCg9ehe3z+KIGNOiVtRJ2GDIJ5y5aiovmTsHB7atiFk8nBPbgJXfL+XjFDBykWlrZsmWxV69eUomTSE5SxNL0Bx2mEEtTH/R8erEBW6ZxQyef8jjpvP5joUi8/mt99GOkM2Ob1RJhoy4xgliqyx4JakPel3nz5iV4XBxQHoFvvvmGE3/lZxYzJoTAiBEjsGTJkgkdFv1WQGDDhg3cY2mFqSWdkoiJt7c30gM/0eIgEHETl3coxEL9ADVeX2GV9oNx8lxGGhbNxUlDOmClLMy7xm6mPXM2w0WXQ+MMVubj5s2beTjsu3cGiK9UKkhMLJEF/D3dNw2b5k+FzgzbmAgmDTp5f4XVey3Gi+/1CLqkxFI7l+FX16zdMFBLfKKf477JrTC/rwuz8efzGUn0zloFey87FxOmq4/vqxM4q3Ux9HPRfF4P+844Jcec9Ubh3sdalqw/IOn3FB1B16YttOhX53Bxv3qYx4+FTGvxolfmpUxfojEOXXIMX8aP81R0aeTZpy0A6mpJE0tTH3RoiaWzb26s0cTwQ5SmzbvjwosxkRgmPehhMRmXZ9VlXkv20CWgJHb8aTYuXjofJ/xQC79yZ1E8fuVw0jnr/BbKbVdBLOVGWCL5glhKBKSEYgSxlBBMiUQJYikRkBKKsRdiGRERgWXKlMHChQsjRS6IFgeB6Nd4eslArJ0nFbrqSBARDQ26py+GTYcsxJMvzSMOcWYy6yNFLxAx27Fjh1njrTvoA94/sxc3r12Lm3cfwZuvlA4kNmL1Hx7imT1bcO3azbj7aDC+SsLUIQ/O4p7Na3H1ur/x8PWXFoVG//vvv9y2Hz58MEJRlZwS/gyvHN6JG1kUxMYdB/DsrRdJ7GlVTu9169Yh7YlX1++cMcSSYWTCgw4tsdRuOTP46pIJe+3V/t6b8KCHm+sNHp3dHguyvc+6hwj00CVHHRy796GBfaLK2VjOmTQknIEpmsoRCAgIgLFjx0LXrl1VrqnjqFe7dm346quv4I8//nCcRat8pT/++COwREpw4sQJlWvqOOpt3LgRWGINiIqKsvlF37t3D1i4NbDwQGARJImup0mTJlCsWDFgDzsSPc/+DkbAs6tn4My1+/AOUkD6rDkhX77skNLN+istVKgQ1K1bF8aPH299ZYQGkiFw4cIFYA984ObNm5A9e3bJ5DqqoIcPH0LGjBnhwIEDwLZg2SYMIY/g7LFTcPMVgl+mfFC8ZE7wc5ZqKSHw4OxxOH3zJYBfRihQvCRk93NJWHgo0+Uo0+XFR/DKWBDKls4NiZ2esCDbOCKIpW3YCQSxVJ+hBLFUn00EsVSfTeyJWBK627dv5+Tkr7/+gjZt2iQION2QMQ8nTJkyJcFzxAFlEWAJmODs2bNw+PBhZScWs8mKwPPnz4FFdcGhQ4egfPnyss7lKMIzZ84MdL0MHjzYUZYs1ikRAoJYSgSk3GIEsZQbYdPlC2JpOmZyjxDEUm6ETZdvb8SSEBg6dCjMmTMHWJkbyJMnj0FQBLE0CItVO1mIH38Y8ObNG/D09LSqLmJy6RBg2b+BZTIFllwLKFJANMsRYCVc4OPHj8ASl1kuTEhwKAQEsbQRcwtiqT5DCWKpPpsIYqk+m9gjsaSw3mrVqsGrV6942LUhkiKIpfq+i6wGNKRLlw727t3L7ac+DYVG5iKQIUMGGD58OPTs2dNcEWKcHgKzZs0CVgsaHj9+DCyrt94R8VYgkDgCglgmjo9qjgpiqRpT6BQRxFIHhWreCGKpGlPoFLFHYkmLo31IrKYtD4tdvHixbr3aN4JYapFQ12vu3LmB1R2G0aNHq0sxoY1FCNAeS/JW/vTTTxbJEYNjEKA8BaVLlwZWxxeyZs0qYBEIGI2AIJZGQ2XdEwWxtC7+hmYXxNIQKtbtE8TSuvgbmt1eiSWtlWWjBPodWLRoEXTs2DHW8vfs2QOpUqXiyX5iHXCQDyyLLiRLlkx1q6UEeJTkJTAwUHW6ya2QWm0ixbqrVq0KlJyJPG221NRqEwqDTZEiBdBDM3oQ40iNcprS+tX4+2ULdhDE0hasxHQUxFJ9hhLEUn02EcRSfTaxZ2JJaI8cORKmTZvGQ2ILFCigPgNYSSNWCw+mT59updkTnnbBggU8IQmFMTtaiB/tDSZPrbu7e8IA2egRytRM66KkWrbUKLt05cqVE9yrbc21FC9eHGrWrMlDYq2ph9Jznzx5Em7cuAGtW7dWemq7mE8QSxsxoyCW6jOUIJbqs4kgluqzib0Ty+joaKhRowbQ/j26IUmePLn6jKCwRpcuXYKCBQtCcHAw5MyZU+HZE5+OEi6VLFnS4UL8wsPDwcPDA5YtWwbt2rVLHCQbPNqtWzegckCsTqlNaU9hpt9++y389ttvqtObojBY/Vf4+++/VaebnApRtu/Lly/DuXPn5JzGbmULYmkjphXEUn2GEsRSfTYRxFJ9NrF3YkmIU4ILqm9ZvXp17jFxNE9Y3G8decYmTZoEo0aNUt1eRiJYRP7Xrl0LjRs3jqu63X5ev349NGvWDEqVKgXHjx+3u3VS4h4KP7elGsa3bt2CHDlycFvQAyonJydV2YUiMWbPng3//fefqvSSU5nIyEieYZjmePToEU/2Jed8dimbxRKLZgMIsBpNyEImbEBTx1Hxm2++QfaU1HEWbAMrZcXokXkjbEBTx1Fxw4YN6OzsbPcLZplGkd0Y6n6n+/Xrh/Pnz7f7dcddILtBxrRp0yK7YcJMmTIhKwUR9xSrf2beVKTfCkdqzCvGbULfUVb30e6WPnXqVMyWLZtNrYuFJXOb0LUSFBSkOt3ZHnKuHyvPozrd5FJo69atOpswYi3XNHYtF+x6dXa0OEEs1WdMQSzVZxNBLNVnE0chloT8zz//jCzhA549exYrVKiAAwcOVJ9BZNaIbpDpRln7d+TIEZlnNF18+/btkYiWozQikkQoySb0kIfVYLW7pbMkM+jj42Mz66IHLvTghWzi6uqKLOxUdbozjx3X79ChQ6rTTS6FWBQDuri48HXny5dPrmnsWq4IhWVXtS00EQqrPiuJUFj12USEwqrPJo4QCqtFncLZ6Hfhzp07kDp1amDkEqZMmaI97BCv3333HaxYsQIopIzdMEPnzp1h7ty5qlr7zJkzYfLkyTzUTVWKyaQM7d/r06cP0PeTwrSpTM6ZM2dkms06Yrdt2wb169fn3ztGDKyjhAmzHj16FMqVK6cbQbVwaT8j7YNVS2Psh/+OjR8/HmgPq7035pkFf39/oDrF2nbx4kUQSdm0aBj3KoilcThZ/SxBLK1ugngKCGIZDxKrdwhiaXUTxFPAkYglLf7Zs2d8vyWlq+/QoQOwEL14mNhrR1hYGNANsn6jm/yQkBDdviX9Y9Z6v3//fqhSpQpPuET/t9p7Y54XuHr1aqxlXr9+HXLlyhWrz5Y/MM84lC9fHp4+fQoswkv1S+nSpQssWbKEk32tsqtXr4YWLVpoP6rila4TIlbMy60KfeRUgjJGUzkibaM9r3379uVZv7V94jVpBASxTBojVZwhiKUqzBBLCUEsY8Ghig+CWKrCDLGUcDRiSYs/ePAgVKpUCapVqwZs72UsPOz5w5o1a6Bly5bxlrhp0yZo2LBhvH5rdbx9+xZ8fX15BlG2pcFaaigyL2XmzZ07d7y5qEwOC92O12+rHUSU8+TJA1euXIG8efOqehlUu5KF7QK96rc6deqoLgNrr1694MKFC0APY+y9VaxYEVjYb6xlUi1ieljBQshj9YsPCSMgiGXC2KjqiCCWqjIHV0YQS/XZRBBL9dnEEYklWYHq6m3evBko5I3KWzhCu337Ng8vpVBgto8RVq1aBRkzZoQMGTIAlVVQU8uePTuQ12jYsGFqUktyXeimmGryUaMHHfQbSa9EbKgkjL00CiOlMEZ6qEMh6Gpu5MFn+7C5it27d+ehyfRK3v0yZcqoSnWWgAwoy/PLly/tuu4rhf2S15teqf7u/fv3YcaMGdwWJUqUsMvar3J90QSxlAtZieUKYikxoBKIE8RSAhAlFiGIpcSASiDOUYklS84B9erV4x4U2s/m5+cnAZq2IYK8Rvnz5+eERltOQW2aE/GnUDcqO+Iozd3dndexbN68ud0tmfaP0p5e8o43aNDAZtZH+ywpumHixImq1Fm7F/TBgwf8AZEqlZRYqR9++AHIA757926JJTuGOEEsbcTOgliqz1CCWKrPJoJYqs8mjkosyRL0lJ/qWxYrVozf8DpKfUtbIJaUkIRlEtV589R35UivkT0TS0IrZcqUfE9zp06dpAdPJolqJ5bv3r3j3u2dO3dCrVq1ZEJBXWIFsbTMHoJYWoafYqMFsVQMaqMnEsTSaKgUO1EQS8WgNnoiRyaWBNKxY8eA9u5MmjQJ+vfvbzRutnyiLRDLHTt2ACs5ArTfMkWKFLYMt9G62zuxzJkzJ0++MmjQIKMxsfaJaieWhE+WLFmAyBYrn2RtuBSZXxBLy2AWxNIy/BQbLYilYlAbPZEglkZDpdiJglgqBrXREzkqsaSSFnRDRklraM/OkCFD+P4vte2hMtqQJpxoC8TyyZMnkC5dOjhw4AAn/iYsz2ZPtXdiSdcWZTFVa1ipoS+OLRBLCuknb/DSpUsNLcHu+gSxtMykglhahp9iowWxVAxqoycSxNJoqBQ7URBLxaA2eiJHJZbkpaQbXapjSQkhGjVqxGsHUtIOyjRoz80WiCXhT8SSkvf07t3bns2hW5u9E0vKqpo+fXqgshG20myBWA4fPhwoFNbeap8m9B0RxDIhZIzrF8TSOJysfpYgllY3QTwFBLGMB4nVOwSxtLoJ4ikgiOUUjsnr16/5XkuqKUjF3ClxjL02WyGWFApLNQ+pnqAjNHsnlpSJ+MOHD0C/ObbSbIFYUnbn7777jtejdYSyG4JYWnb1CGJpGX6KjRbEUjGojZ5IEEujoVLsREEsFYPa6IkEsYwhlgTYqVOneBF3qh9IobH22myFWI4YMYLXDTx//ry9miLWuuydWPbr14971Wyp5qItEMuLFy9CoUKF4Nq1awZrosb6ktnBB0EsLTOiIJaW4afYaEEsFYPa6IkEsTQaKsVOFMRSMaiNnkgQyy/EkkCbM2cO9O3bF4KCgux2b5+tEMv169dDq1atuJcrWbJkRn+nbfVEeyeW48aNg9WrV8OlS5dsxkS2QCw/fvwIXl5evC4tlemx9yaIpWUWFsTSMvwUGy2IpWJQGz2RIJZGQ6XYiYJYKga10RM5KrEcPXo0UA3Htm3bxsKK9lu2aNECDh8+zIukUyimvTVbIZa3bt3iNiJPcvHixe3NDPHWY+/Ecu7cuUDRAI8fP463drV22AKxJOwKFiwIjRs3hjFjxqgVSsn0EsTSMigFsbQMP8VG041Ihw4deHp0xSYVEyWKAIVREeF3lMQPiYKhkoO0V4oSDMyePVslGgk1Dh06BL/88gtQeQfRYhCg2nBEZLJmzcpxsbd9S7ZCLD99+gR+fn4wbdo06NKli91/Pe2dWK5du5Y/yImIiABbqRlrK8SydevWEB4eblP7V829oAWxNBe5mHGCWFqGnxgtEBAICAQEAgIBkxE4d+4czxpLD6hGjhxp8ng1D7AVYkkYVq5cGQoUKAC//fabmiGVRDd7J5Z79+6FGjVqAD248fb2lgQzuYXYCrGcMGECLF68GIKDg+WGxOryBbG0zASCWFqGnxgtEBAICAQEAgIBsxCYP38+dO/eHfbs2QPVqlUzS4YaB9kSsaT9ridOnIAjR46oEUpJdbJ3YkkPa4oWLQp37tzhNWQlBU8mYbZCLCmTdYMGDfh+ZE9PT5nQUIdYQSwts4MglpbhJ0YLBAQCAgGBgEAgHgIbNmyAtGnT8iyw8Q5+7qD9lu3atePEkupbUl1Fe2i2RCyp6HuPHj24l8veQpLjfpfsnVjev38fMmfOzLMv28qeWVshlnfv3uWh+ydPnoQSJUrE/WrZ1WdBLC0zpyCWluEnRgsEBAICAYGAQCAeAhUrVuShrlOmxM4KG/dEqrtXsmRJTkJ3794NLi4ucU+xuc+2RCwvXLgAhQsXhqtXr0KePHlsDmtTFLZ3YhkaGsqzl/77779Qs2ZNU6Cx2rm2QizpIZiPjw/MmjWL17S0GmAKTCyIpWUgC2JpGX5Jj/74DM4F7YcLj8PA1TcLlKpeEbJ7a5IeJ86wPgKfothm9Qj45OQK7u5uYHI58+iPEBoRCWDueOsjIDSwdwRCH8HZY6fhxqNXEOaUAjLmKgqlimUBb5O/7EoCFQ0RoREQ7eQCnuy6VGszlliS/lQeoVSpUjBgwAAYO3asWpdktF62RCwjIyP5fjzaP0alR+y52TuxJNt5eHjAokWLbMaWtkIsCVvStUyZMjB9+nT6aLdNEEsLTcueQogmEwJRLwJxUPE06KQBZGZCjUdFnHknUqbZhFipEfh4bhwWddVgsnz98WjEJxPFR+KJH0ujK7O9U/JKOOvmRxPHi9MTQ+BD8FYc02cmnjDZLolJdaBjby/gwh41MIu3C7LHXPz3iX6jQOOEybNUwh5/nsDX0UriEYLBm8Zhn9lHMSLWtAb6P6zGhl4u6F5gYKwz1fahQoUKOHCg8ToyYoMskyXu3LlTbUsxWZ/Lly/z79SNGzdMHmuNASy0zyRbWUNHKeZktTpxzZo1UohSrYwMGTIgqxWrWv3iKla2bFkcMmRI3G5Vfu7atSuy5Eiq1E1KpXr27OkQ65QSM31ZoP9BvJcSgWi8P6cuerAbtZQlu+CcVRtw3dr9eDdKyjmELDkRsIhYhh3GPjm90MnTCz2cXLHET8dRPFKQyFphO7FTend0y9ED94WbSvgl0sGWxUTexLl1MqOzxgXTFG+OQ6f9ias2bMINqxbi5AFNsYAfI5tOflh98ikMU2idoX/3wPTOzpi7924M15vTYL+dEktadseOHTF16tTI9orpoWB7b22NWHbu3BlZ6KTtAW2ixo5ALFm9RWS1LE1Exnqn2xKxnDlzJqZPn956YCk0syCWlgEtiKVl+CUyOgKPDCmBLhoPbLT0RSLniUNqRcASYvme3ShndHbBfN0GY8OUrowEdcfAEEGCJLF16FZsncpNEEszwQzd0QszOWvQp9woPGvgO/n+xEQs6+2MTqm+xUUPlHkSFrKhE6Z0ik8sDfbbCLEkkshCxkyyUkhICLLSF0jezo8fbTfKwdaIJds3hixxkkm2ssWTHYFYsvIx2KdPH5sxjy0Ry127dvFIhDdv3tgMvuYoKoilOah9GSP2WFoYSmxw+Mc38PDhUzg2oQm0/PM/qDvnGEz7xhPcU2WE9C5v4O6zD+Du/xV4PdkHG3dcgaiMJeHbOqUhnW67UCjcOxEI+07dhJdRnpAuXzmoXqkA+OuOx8wa8uwePAtxA/+v0oLnu+uw9599cPlpJKTMXQnq1CoEqZzpvFC4e3gH7D59D8K9s0L5b2pDsXTJDKotOmMjEHn+FyhdciRcydkP9p2dCmXcjN0b+wZWtyoKbdZ/gp47j0G5P8tBm7Uh0Hr1ZVjezD/2JOKTaQiEPIf/7m2DvuW7w/YUreCvf3+Ckj5pIHNab+Bfd5IW+gCO7w2C07deQJRnAOQvXwMq5k8DcS4f0+a1m7Oj4dK4qlBs5DEoOf40HBhW8AtuujW+hVUtCkHbdW+g2cr/YHVLX90R/ibiKZwL3AvHgp9AhHsA5C1XA6oUDDCMLzv3/MEDcOrqfXgVrgHP1JmgUMXqUD6Hn27PMv2O3ds8GMp9vx5SdlwG/4woCz7+mcE77KHB/rRO66FRQFvYmbUvhF2MmxgnAh6fD4LAo9fhaYQ7pMtTFqpXLQRpbMj4165d41kX2c0NTJo0KTb2NvLJlvZYEqRBQUG83Mvz58+BeYxtBGXT1XSEPZZNmjThCXyWLVtmOkBWGGFLeywfPHgAmTJlgqNHj/K9llaAS5EpxR5LC2H+wjHFO6kQ+HhmLBZie/OYafT+XLHS5Gv4ZlVb9NYkw697D8ayvi4xxzVuWGXqNT59+K0t2L/KV5js875MLoOF0/rkaYzTjzzHL9ueQnBNq0zo5FUbJ68egmX93b7sldK4YoZak/H001M4q1EedNfJ0qCzXwkcEfhCT45Uq7Y/OeZ6LKMeLcW6zLZu2bthYNgnfLO5Gwvz02Cq2r/h/S8GtD/AFFjR+7Ud0Vf3fY65vrxrzMJHHNcIvLVhCFbO4PnlWqC9zU7emLfpZDzyUhnvmwIwWDBFNN6eXgvd2G9KusYL8WEC38e3t07ivqD9eP6hfmBqND4NnIR1s6eIj2+zqXjslT6+kXhr/SCsGMcW9HumcfbDEt+vxv/46TG/Y7H2eYIb1pxzHVex37e4/bV+u4fRCXgso57ux3H18qCX/veD/3Y2wZnHbOs3b8WKFfz/BlY7zgJbW2+orXksGaHkeAcGBloPNAVmdgSPZZcuXbBOnToKoCnNFLbksfz06RN6e3sjS44kzeJVKkV4LC0zjAiFtQw/g6OjHuzCqYP7Y5tSASxxjxvma9gHBwwYjL/te4ZvObFkBM/FE3M3+QXX7tyKv/cfiEtYcpeoF//i97nZTRsLn81RZxDO37wX9+1ai9O6VcIAFzYmZSWcdiH085yfb8ickmOKFD5YsOVoXPZPIO5ZNxkb5/BiMrwwW65M6Ju7IY5a+jcG7d2AU9sUYTddGvQq8zNe1r8HNLgK0WkesYzCmzNroyfbv1Zg0IGYRCShQfh9Vk908iiJEy7bbnibGr4RH8+vwpH9mmB+Dyf2kKQYtu43AIfOO4Dv2KOSF9v7Yq5kTqjxzIp1h/6BmwP34a41M7BruQwsJN0JU1ediBfEnkyMvDYHq6RwZol6PDFHze9xyqoDePtN0juAw05PxnI+bP+lZzasx/Hdj4Gb5uOQOrn5XvK0tWfj9c9iIi/PxkpsDo1HTmwyehFuDTyIBwO34aIxrTE/ze2SAbvveM++UpF4/q/R2LdR4Zj96CVaYr8BQ3D+4RcJ9LMQLEPEMuwcjitPv7cemLNuzG/n/sDN+MfQ+pidvitpauLv12KnBVLD9zkxHShRhp+fH7L6cYmdpspjtkYsCUQKhaWQWHtujkAsBw8ejCxzqc2Y0ZaIJYHKslfbfaIrQSwtu3wEsbQMv0RGR+CB/kXYDa03tlr7Tnfe+1XtmMcS0DVLJ9zxXn/PXSSe+7ki81Q6Y8YmC+Mk+fmAx8ZUweTs5jig8SJ8wr0M2if9Tuhfdy7+p+d5eLK4OaZgczh5V8TpV/Vupj78i10yerD+Orj0lf7cOvXEGz0EzCKWkVdxXGk/1CQrjGPOabGPwMODi6MLENncHys5id504q2xCBjaY/nxEo4pwXB3DsBmS25hrOcm70/h6DKpeUKapksfCG89I3M3V36PBYn4fY6q0Lj6YrbitbB9/4n4V9ANfKf3e8LNEv0Y/6yXAZ1c0mLzZbdj4xt1F+fXY9ETLumwy9bX7PQovDK1NqZwZkmrRh6L833/nC0ZXLH8+Is6OQb3UjJJBvvjEctofPBnU/RlezQzNV382ROq/TJF4a35TTE1O5al00b2AEK5xgqJY3BwsNkThoWFYZEiRbB06dIYEaH9LTFbnKIDbZFYUvIe8nbZc3MEYsnCxzFXrlw2Y0ZbI5YdOnSwKY+wOV8EQSzNQe3LGEEsv2Ah8bvEiCULi2y8BOkWTNcig3F8GV8E11w45Ej8XIyfXq7HZqnd0MmvIa58TaTwM7FkT+jrzH8Y62Y5/NAwzMk8nF6Vp+Bd/RvEz3NoPCrh7LtJeyh0ujnoG3OI5cfjozC/KyvZUGE8XtdjNx/P/4LFWL9r5o749ztB6i36ShkglpFXp2Jphm9CpWFesAc6qZw06N9kaezrziJFbHtw6N19+Mew9lg1X1p0Z9joQveZtz11kdY46/Az3e/KpxfLsV4KFt6d43uDmXjfruvE8HXGrF236Yhk1Ltn+OJDXIwi8OY0ForLiGWJn07qMiUbJJBsqMH+eMTyFS6snw41LlmwT5A2okNv3nebsTX77XTN3Al3KuixNrXciJ7GurdUroNCz/r27avrs4U3tkgsWQ1R7o2xBXzN1dERiOWCBQswVapU5kKk+DhbI5ZE3LNly6Y4TkpOKIilZWgLYmkZfomMToxYOmP2Hjt1N2BcSOg/2CFtMnRK2RjXfjBAPCJv4cRyfgjJCuGos/T0WhsKG4Bdt8e+ews/+iPmcXFCP0ZeYx2JuoNTKjKvDqunOeuOIJaJGI8fMp1YhuHeXgWZl9oVi/RcgYFBQciSQsT87V2OXfJ4IbAyDk2Xxn4QkJQe4ngcBAwQy5At3TCAiGPzFbG/85+HRt6YjmUZ8fQoNhzPRhq4vuJM4Vgfo/HDvVO4bdFE7NOyCmZnBJI8mc5+ZXHCqRAORfgR+k3RoMY9JWbMkgWzxP3L4Mdrtn7Z70rDovD5pV24/NcJOKJPF2xZpxIWyuTLzwNGLFkCIWmIZfhxHJQ3OQvtdceUGQ3oliUD+rI97xqPqvj7Q72nPTIbWQpiSSquXbuWk/6NGzfKrLF04m2RWC5ZsgS9vLwwOlr/aax0mKhBkiMQyw0bNqCTk5PN2NHWiOXWrVt5vd3QUAMP8dTwJZdAB0EsLQNREEvL8EtkdGLE0gXz9A2MXQj8w3ps6uOKLhk64HaW8CVei36Kv32dmnk0c+OQo+TR/EwsXb7C3oGxL3AtsUzZZBk7S68JYqkHRtJvTSaWb7djxwzuXzw/n8MMdZ4g/pmVeag6FW8pd3+b9EJt7QwDxJJCzFOwUPHMnTcbrL0Y9XgB1mD7L5Pl74/HIgxcX7aGgYz6Rj4+iD9Xz4hO4IRpW67AV2yusF29MTNLQOXslx1LsD02tM/G0F/F/y2NSQj0/gLObV0YU+g8oYzYufliVhZu26J6LhYWLiGxDAvEbpk9+EObnCUM68V1rdAZVyhUPoXMIxWxJFksSyH6+PjgrVu36KPqmy0SyzNnzvDf7ps3b6oeX3MVdARiSQ9z6f/c169jxYSZC5ns42yNWFIUBeF79uxZ2bGx1gSCWFqGvCg3wq4QedpHODigNFSbcQuarXkIK5t582k+rG4P6Vuvggx9dsH5GVW/pOgP2wmdczSEJaHfwF/3NkErthEzVou6BmPLlYWfLmSHX84cheH5ImFt6zzQcp0T9Np1FWZV9dCdHnFsJBSpOB6eNVgC99e3A0/tkei7MLVqMRh8qgDMvBIIvbO4aI+IVwMImFpu5MXKdpCn3QqIKv4dDGmWB+KhG30HNk1aAMfC8sFPR07C6GI2VAPBAD5W6wrbBm0yNYX1fl1g16U5UJmlUA79uyfkaDAXPjZaAnfWt4eYq+2LhlGXJ0HZosPgStFRcPLIKMinq03y5RxHeIdv1kKbgn1gf7p2sPbQJCifQAmdyHO/QKlSI+FanoFw4NQkKHTqRyhUeQI8LDsBLgQNgWyJ4hcOBwZVgK+nnYFkuRtA337toHqpIlAwbzZImewT3J9dF3L02QMFfjwIx8eW5tdJ6MbOkKnZUvD/YSecn1UDtAWRDPaHrIldbiTiOAwsXAOm3y0EUy/vg/7ZXVVhyooVK/KU/FOmxC2JYrp6bI8lMKJKD4Lh8OHDwAiCQSHHjx+HFy9eGDymZOe9e/egR48eMH/+fGAF1ZWc2uBcGTNmhMKFCxs8pu0MDw+H5MmTw7p166BRo0babotfqXwMeyBgsRwpBDRs2BBYyC/Qd9PajYV4cz00mjj3OhYqdvHiRShUqBCwBwSQPXt2g9IePXoEjBgZPKZ058CBA4HVrgVW91bpqePN5+zsDNWrVwdX14R/Q5lHn5dzWbx4MbRq1SqeDHM7Pnz4APv37zd3uKTj5s6dy0oGPoRx48ZJKtdcYVSShiVyM3e48uMs46VidMIImOixZN7EqZVSsn1CzAO5N5afkU8R9WgJ1mEZGZ39m+N6nvRHeCwTxl6aIyZ5LKMf4bxv2T4vJ19suuyRbm9abE3e4ob2OZgnyBlz/fBvbG9y7BPFp8QQMOCxjLw1Gysmc2YlXrrzEi+xh0fjwwVNuUczbevVSLlIHbZ9PIlD8nuzyId8OPx47EgHfUwiL0/CEix81LPsWLzGvOufni/Dut4u6JSqHi59Et/dHvX0Kp68/ADf06HwI9g3FwtNdcuPP56Mu188nIWLF0BnlsiqyPAj0oTC4ktcWC8tC8/yxcaLDYSZRz/DKycv40OunP4q5X1frVo1HDp0qGST3L59G319fZGephtqVLSc3UGIvwQwYDeuhmCL1ZcnTx4cM2ZMrD5LP2TNmlXYJAGbHDp0yFJ4441ntRY53idOnIh3TNvBCJGwSQI2mT17thamBF8Zcccff/wxwePmHGAP4IRNErAJe+hgDqRWGyM8lrJxeRM9lhANwdPrQLGBu8Gj2gQI3DoICnp+fpL36Tn806sWNJp7HtK0WgEXVrQEPwgVHkvZbBcj2BSPZdStOVC9YF847N0IVl5dC81TGn4KG7K7D+Sv/Ss8TNMMVl1aDU0TOE/mpdm2+LDt0D5LE1jt2QF2XvsDqjGPJUTdgmk1ysKgg5FQY3IQbB5QROepj366G3pVbQJ/XHeHNqsvw/Jm/ra9fou0j4KLE2tBmeH7wK1Eb1i9eTLUSh/n6XT0I1jfpRa0XnoDSvx8FA78WBRcPj2BRY1KwP+2PYf8PTfC3ll1wN/psyLR92Bpi6rQecM9yDNwL5wZ5wwD89eCX+99BSMOn4ZxJd11Godd/B0aVu8Lu1jZwPwD9sCZqZV51Ebo5q6QpckiSNF9O1z+rdYXj6Wh/rgeS/gEDxe1hAL/Ww8RebvBpsA5UCuN1qUaDXeXtofynVfCy1x9IejcdCibgJdWp6SK32zZsgXI67R69Wpo0aJFLE3JU+nv7w/z5s1L0jsXa6Cdfzh16hRQwfO3b99CihQpEl0tYcpq9XGvZaInmnCQCso3a9Ysnr1MEGF3p5J3qkaNGsDCVqFKlSqSro9lUwZPT0/YuXMn1KpVy6DsBg0aQGRkJIwaNcrgcUftpN+WQYMGQf/+/ROFoGXLlhAVFQXr169P9DxTDv7888/A9jnDqlWrTBlm9+eyh5OQIUMG+Ouvv2xmrYJYymYqU4klU+T9MRhZrR78cvoN+BdvBt3a1YDsHq/g7JZFsPCfaxCe7lv4PWgT/C8X3QgKYimb6T4L1hLLC165oGr1guBriCs6pYbaI6dBiY21oOToIxDQbg1cXNoUfBJSLuIYC9v7GqYFa6DOHxdga9csoL0/T2iI6I+DQMRR6FewJsz6Lx20HDsEauYsBA0blATno2Ohau0xcCbMD0q06AZtq+cEjxfnYfOfi2DHjQ+Qod6vELjxe8ip5RxxxDrMx7CLML1BHRi85wHLJZUbqjdqCNWK5YQAr2h4ffcC7NuyAbafewrJSw6GLbvGQ0WfmC9++PlZULvaQNj3Ohnkrt0JOjUoDv6R9+DohsWwfN9diM7YGJYcWgOtM4fB311KQMOFweCRuy707N4A8vlEwL2ze2D1X3/DTfQC57fvwK/DOri5uDEQ7Yw4OBQKVJsC97M3hbGDv4GchRtC/eJ+EGmoP88uaBLQFnZm7QthFz+HmYZfgqnf1oIhQY/BK1ct6NS5IRT1j4K7xzbBomVBcD8qLbRYchhWtLH9641CGVnmSyDCRKF+LEsj9O7dGyiUk4jln3/+CaxMicN8nZNaKOHUvXt3o4glhb4tX74crl+/npRYo49nzpyZk0q6GRctBgEilkQo5SCWNAMRS7oOWrdubRByIlAU0jl69GiDxx21kwg3kcqkiCWRwDVr1gDbSy0ZVCSTrj16aCbaFwSGDBkCadOmFcTyCySO/M4MYsngin52CKaxp6sTNl6AN9EUGQCgcUoOWat0gDEzx0PbgtonroJYcnBk/EdLLM9GxtjB4FQumeCHbX+B54C6MDnYG7puvgLz6iRIK5mIKDg7qjKUHnsUkpUeA8cPjXTY/X4G8TSqMxSOja0DtUfvgzefANxy9IDdbK9lpWQIz/bPhJ49x8OmKy8h5vLRgJN3ZqjacTTMHN8BCiQ39HTAqEnt66TQYNgwYQT8PG8bXHweweMnYxaoARefrFC51UCY8EtXKJkyNgt/c2I+9OkxCladeQK6y0LjBulLt4fx86ZBh0Ixv0/Rz/bBmFbfweSguxDx+fLRuPpDidbDYPogH5hQrhvsTd8ddp+dDRXdmU1CTsLPX9eDMUefMv+jM+Tu/S/ba1kdkhnqH/8CWsYllqT8m9Pwe9+eMHrlCXj+RTlIlq4kdBw/D6Z2LALJ7cCK5GmpXLkyJ0opU6YEFk4ILGMs368miGV8A5tCLMkj3LhxYyDi4+HxJW9BfKnG9whiGR8ruYkl7aklTw95qg01QSwNoQJgLLGkfchE2llm2ET3YxqexXCvIJaGcRHE0jAuotcMBEIenoNjp27AKxb0mjl/MSiRIyW73RJNICAQiEEgAh6d3QdHrr0BZ/98ULFaQUitc/2GwIOzx+H0zZcAfhmhQPGSkN3PRQBnCIGot3Dn/Fm4fPcpfIhOBr7pskKh4oUgvTYM39AYiICnl0/AqWuP4ANLk5QxX3EokTdAF776ZUg4PDp/BE5cfw5RngGQt2QZyB/wJSz2y3mf30U8gTNBh+H6WydIk788VC2QJsabn1B/PAExHRHPrsDxk1fh8QcA7wx5oUTJfJAmWQIny9j99OlTnmSH7YuUfBYKQaMbO7aJhnte2rZtC9OnTxceSwNIm0Is79y5A6xGH/cGFy9e3IA007sEsYyPmdzEkpL3NGnSJMFQV0Es49uEeowlluSppIRDV69eBbYv2bAwE3sFsTQMmCCWhnERvQIBgYBAQCAgEHAoBKTMCqsFjojk5MmTuTeG1erj+wHpGO0dDA4O5iFTIhRWi1bMqynEkvZXsrIuwBKYwHfffRdbkJmfBLGMD5zcxLJq1ao8M+ysWbPiT856BLE0CIvRxPLjx4883JjV2OUefsPSTOsVxNIwXoJYGsZF9AoEBAICAYGAQMChEJCDWBKAe/bsgdq1a3MsKYGGtrHC5VC/fn2xx1ILyOdXU4glDaHU/mXKlOEe4DiizPooiGV82OQmluStpFDmhBKeCGIZ3ybUY6zHks4lT2W7du1gxIgR9NHiJoilYQgFsTSMi+gVCAgEBAICAYGAQyEgF7EkEENCQvgNHXlkqPYceTIpQc3vv/8uiGWcb5mpxLJbt27ASrvA7t2740gy/PHZs2eQJk0awwdZryCW8aGRm1gS4aEsyTt27Ig/OesRxNIgLCYRS6r1SkmSVqxYYVhYnN7Xr1/z+pdubobrdwtiGQewzx8FsTSMi+gVCAgEBAICAYGAQyEgJ7HUAnns2DHuNaBi8NomQmG1SMS8mkos58yZwwujP3nyJLagBD5R2Yxr164BZeulgvGUwVG/CWKpj0bMe7mJZdmyZYHVsYRhw4bx6yN37tyxlBDEMhYcug+meCyHDx/OS7qcOXNGNz6xN5Twp3nz5vwBWPv27XlUgEbzJZmeIJaG0RPE0jAuolcgIBAQCAgEBAIOhYASxJIAjYiIgK5du8KyZcs4voJYxv6amUos9+/fz0thUPKlxDyR2llKlizJk/24uLjwRErVq1fn+zOJvJBHRxBLLVJfXuUmllTKhOzo6urK61VS+Z3OnTsDlXxJnTq18Fh+MUWsd6YQSyoNQt59siXt906qaYml1iZ0XZBNKPEYJcwSxNIwgoJYGsZF9AoEBAICAYGAQMChECBiQmFffn5+iqz74MGDUKlSJREKGwdtLbGkLJYUNpxUo32rlPWSbna9vb2TOh3u3r3LS79oT9RPqtSxY0cejkmhmaKOpRYh4GSEyB/VYU2eXPoiQBTK/P79e92E5BmjcHFq9erVAwpfptI8oo6lDiL+5ttvv+XXiDEPVKjUyI0bNyBv3rz8dy62pPif3rx5A/fu3dPZQf+MEiVKQPr06fl1R/UxRfuCgCCWX7AQ7wQCAgGBgEBAICAQUAgB2lMm6ljGB1tLLKmuobt7IuVu9IZOmzaNJ/GhkMqkGnmKichQIwJDxDI6OhoyZMgAv/32G6+lSKRSEMsvSGo9lh06dICsWbN+OSDRu9WrV/PwZK048iZrE10tWrQIqFwP2UkQSy1CMa9169bl2XQpgVVSjTLDjh8/npc9ypUrV1Knc9JIuGsJvtZzSQMnTpwIz58/B6ojS7YT7QsCglh+wUK8EwgIBAQCAgGBgEBAIQQEsTQMtJZYvn37lpdlMXxW7F7y3NBeSSIhSbVSpUrByZMn+WkUFkvhfbSXTOupFqGw8RHUEsugoCAgz6XUjfa6agkKeUXJJm3atOFhyTSX2GNpGHFTQmFJQpYsWaBXr158f7FhiV96taGw1JMqVSoeLk6efKo5Sk2EwnIY4v0jiGU8SESHQEAgIBAQCAgEBAJyIyCIpWGEzSGWdDMXGBioI4yGJcf09ujRg5NQ7V6xuOcKYhkXkS+hsHIRy0GDBsHUqVNh06ZNPNOpfpIY0kYQy/g2oR5TiSWVPaIQ1oULFxoWqNe7fft2TvYpcU+1atXihaULYqkHlt5bQSz1wBBvBQICAYGAQEAg4KgIfP3110AeLAoXU6IJYmkYZXOIJdU/pIRItE/PmH2ZhmeO6RXEMj46cnssHz16xEORjx8/DuRRjtsEsYyLSMxnU4klZUI+evQoHDlyxLBAE3oFsTQMliCWhnERvQIBgYBAQCAgEHAoBJTKCqsFVRBLLRKxX80hlufPnwfKJHr9+nUwZv9Y7BljfxLEMjYe9EluYhkWFsYz8lIdy2+++SaeAoJYxoOEd5hKLCkD9cCBA4FqVMb1ChueIeFeQSwNYyOIpWFcRK9AQCAgEBAICAQcCgFBLNVhbnOIJZVwoWyltE+vSZMmFi1EEMv48MlNLGlGKvWyYMECvrcyrgaCWMZFJOazqcSSPJXly5cH8hCnS5fOsFAjewWxNAyUIJaGcRG9iSAQ/XA/LPrrCLyAFFCseVeoldU1ztkRcHnzPNh2NRS8izSBbrVzgkucM8RHORH4BA+DFsNfx54B+BSBFl1rQ5a4Bgi/Bpv+2ALXwr2gSLNuUDt7XBvKqZ+DyP70GAIXLofjLxB8ijWFrrWyx7sOwq9shT+2XoZw70LQvFsdyBbXTg4ClTWWKX7H4qMuiGV8TKzRYw6xJD2pPAmRyjFjxliktiCW8eFTglhmypQJBg8ezJPLxNVAEMu4iMR8NpVYkqcyZcqUsGfPHqD6rZY0QSwNoyeIpWFcRG9iCHx6BKvbV4N2K2+AT4UxsGvXCCjmrtGNeLNvOFT6dhJcTVkH5u1bD51yuOmOiTfKIBD9YD20r9AeVt13g0rjdsPOYSXhS9L6dxA06GuoM+00pG7wOwSt6wrZBaGRwTCf4MHqLlCh3VJ44F0GftmzG4YU8/wyz5uDMLByfZh+2R0azdsPazrnikc8v5ws3kmOgPgdiwepIJbxILFKh7nEsnXr1hAeHg4bN260SG9BLOPDpwSxLFy4MDRq1MhgSRFBLOPbhHpMJZY0hrIn//jjj7ysDn02twliaRg5QSwN4yJ6k0AAX++HgVUawoyL4VBkwDYInFIDfNmY6MfboEuFVrD0USbotWkfzPgmAJySkCUOy4PA68BhULnuZLgE+WDgP/thcpWUbKJP8HhTD6jQYgE8ydUNNgb9CrX8ky7ALY+GjiD1LewdWBPqTT8JzoX6wN/7pkNlX/YQ5tNT2NilGrRccgvy/LABAmfWgdTiQlH8CyF+x2JDfuLECfDx8YHcuXPHPiDTJ7HH0jCw5hLLCRMm8HIjVATekiaIZXz0lCCWlHmUvM6zZ8+Op4AglvEg4R3mEMuqVatC3rx54ffffzcs1MheQSwNAyWIpWFcRK8RCISfnwHfVB0MB0IyQqfVh2F+vQhY3LQadNv2FqpO3APbBhXT85IZIVCcIjECEXBucgOoNmwXhGZtB6sPLYK6ISugSYWusD2yDEza+w8MKKznQZN4diHuMwLhl2By7ZowbP8LyP7dSji4oBF8WNwaKnRbD9GVf4Hd24dAYT2Pv8BNWQTE75iyeOvPpiWWVMOPvDWixSBAxJIKs5tSx5JG/v3331C/fn2eGdbLy8tsOAMCAiBjxoy8tqXZQuxsIBHLcePGgVzlRgiupk2bgru7O1CG37iNCNShQ4d4qGzcY478eejQoTBt2jTo37+/0TBQuZ2rV69yWxo9yMCJRCxHjRoFEydONHDUcbvGjh3Ly+MY+h6rFRUNsqZW5RxLr2i4u6wDVOi0Ep4G1IYBzUJh3q+HIVXrJbBvaWvIKDww1v86RN+DZS2rQacNdyFtnf7Q9O1S+PW4O7RddgAWt/hKeJMVslDU3VXQssJ3sPGJL9Qd2Apez5sDJ/2awrL9f0HzTMJjrJAZEphG/I4lAIzs3aGhodxzcO/ePXBxsX48Pt1aWJopUgrQoqKieCF3yvDq5mb8VhLC8auvvgLyPFPZGHNbrVq12BaXXRbZRHubZimearKJk5MT3Lx5E7JmzWoutImOo3Ix9+/fB8oMG7cRgZo0aZLZNpHKHqSXlLLirtPUz3StbNu2DerWrWv00Dlz5vCHBE+ePDF6jKETV61aBRR+bupvlxzfabXZhMglhRvbTGMAiqYWBKJf4vaeRTGZBhjZ16BPycF48M0ntWgn9GAIRD3fhT3ypkAWgMnumryw9PB9+EYgozAC0fj8n36YJ5kTPRRDJ+9iOOLgK4V1ENMliID4HUsQGkc5wLKqIgtDxMjISEmW/ObNG2Q1CSWRZayQT58+IQtlRlZSwdghspwXHR2NLVu2xHPnzlksn4Ut4t27dy2WQwJOnz6NzEsuiSw5hDDyiKyGpRyikdVvRBYiLYls5h3ELVu2WCTr8uXL+ODBA4tkmDuYJe7h/w+/fPnSXBFmj3v16hVWqlTJ7PEJDWTeQWTe04QOG9XPHiYZdZ49nkRPS0RTEQKhR3/Cgq7shlnjigV6/4uvVaSbUIUQCMMjw0qjKyP/Grdc2Gev8j+mwg4MgdATOLQQEXwNuuftgYGvxQMYNX0vxO8YYqdOnXDGjBlqMotiuqxbt47fbDLvhyRz/vfff8j2KipOZFgpBezTp48kazBXSPv27TmWly5dMlcEH0eEkh7EsdBFi+RoBzMPE7IakUjEV41t8uTJmCNHDslV27x5M8eRldqwWDY9eCGbsFBpi2QxryzSd/Xjx48WyTFnMCs1wtfAQovNGW72GMKOhTrzuc0WksBArVx6uGRuY0mNkAi/IzZBLFVk9agXe7FXfh9GWAIwfWoX1Lhmxg5r7qI6f7ZVBJxiqkTji38HYD53J0yWNj2mdtagW9ZWuPZelGIaiIkYAtGvcGfv4uiuccO06VOjs8YFs7dbiffFhaKKr4f4HYsxQ4UKFZAVD1eFTZRWgiVH4Td85GmTol25coXLy549u6JE5vvvv0fy8lmrzZs3j6+byAcL5bVIjV9++YXLYuG9aMkNs1aJWbNmcXlsb5y2S1Wv5Gn28/OTVKdnz55hihQp+Lq3b99usWwihGRb+iPvm7ltxYoVXEa/fv3MFWH2OK1nf/78+WbLMGdg3759ddiZMz6hMVqiTDYxlywTJlq7vnv3LqGp7LZfEEu1mDbqLi5pkh2dnVJgpXHH8L9tvTAn81w6+1fHXy+FJajlh9vHcO/Zh4J8JoiQdAcib6/AxhmSobNvWRx/4j/c2q0Q81w6YUDN6Xg5Is6TrfCneH7Pelz821QcP346LtxyGp9JExUm3YJsUlIU3l7SGjM4O2HKCmPw5H//YNdcyVHjlAq/mXUBI+KsKer1LTy8bSXOmzEBx036FVfsvYaO9zMfBxQ5P5r5O0YqfXx4FnfvOokP7eQ6cVRiSTfIzs7O/MaK7WlEKW6sTp48qbtRY/uN5PwGx5LNMl1i6tSpJSFisQQb8eGff/5BtqdSt+7bt28bMcrwKXSjmy1bNp0swtPSpiWWdAOtxrC/TZs2cfzYvkFLl8rHE4bkoXV1deU4Llu2zGK59OCFrhX6o4cI5rYlS5bobLthwwZzxZg9rmzZsqgkqV28eLFuvZ6enmbrbWjg1KlTke3z5H9sn66hU5LsY/vddfo1a9bMKr8fSSop4wmCWMoIrvGiw/DU+Bro6+SE6er8ac3eAAAxJElEQVTMwWB+Y/Ue9w8ti57sP5YUJQzttYzG0PsHcHTVdJi62V8YYvxk4kxzEAg9h79UTItOTqmx3tyryE309jAOKZqS/efliaVi7bUMwdUtMqFLiq+w1NcNsUmDqpjbLxkGVB6Fh9/FIaDm6OLAY0JPT8EKvi7oHPAN/nE9hka+PTASi3g6oVPyorH3WoYF4fdZvNArXV4sV6shNqpVAjN4uGOOFn9isDT3Gg5sCUNLN+d3LEZO1PNA7FfYD528auNiOwlrdlRiSTfIWmLJErQg3fRa2vbt26e7USMis3v3bktFGjX+4MGDfN7Hjx8bdb5UJ509e5aH+ekTS5ZMyGzx+sSciFHv3r3NlqUdOH78eEyWLBknb7QXlSXK0R5Sxev+/fu57aTa+8eS1OiIPj0wmT59ukXrpAcuJIe+z2Tn0qVLmy3vt99+0xFeIlrBwcFmyzJnIIX9E+lWolEIsvb3hbCjsFUpGyudovutSZ48ObJatiaLf/78uU4G6UjfHUdqglha3dpfEpG4ZWmJax/o3fGGXcAJlRiZYfstc323Fh9rQ/0ib+Gs2lnQ1ycFerpqBLGU24aUjOQHSqrkgtnarsSHWjuwecPOTsOKjOho3LJipw0PPnuOI/Hizk147gWnn1y7sAuTsaxXcvxm7h3hXTbTXpQ4qSclTnLNhO3X3NPDMRzPTPiaPZjRYLIc7XDjo8/XELtOAjcfwcc6N2Y0Pl3zHaZ3y4mDDiUcBWCmeg4+zIzfMS1i4dfw9zrZMFO2zOiRXBBLLSy2+ko3yFpCRMRSiuQaFHZIN2j0RzJ9fX0VSVZCSYNozp07dypmDiKQ2rXqv1pCbolIaj1tJJPws3Q/3ogRIzixJHkku0SJEkhJm9TSLl68yHGUgmSRLPJiae1BhJrWb0mjBy70XdbKpNdbt26ZJZL2k5JOJIP0zJMnD4aEKOduIC9fpkyZzNLdlEH08ILWqI8bkXOp2vnz52PZg37HzPEAa/cza21LRPjYsWNSqal6OYJYWtlEkbeWY8P07Kmfex7s8+9zvZvlGMUigxdinTQs9IJ5yur+fjnGU6bTOQSXNAgQxFKHhxxvovDWopaYnu2n9MzfA3e91CP+fLooDP6jCaZxAuZFq4VzrybwH2vYfuyRNTkWHHIwXrimHFrbncyoO7ioUTa2nzIZFuz9D77UI/d8rZE38Y+6mdEJmNf/21/x2hdOHwuK8MPDMXeyHDjwoCCWsYCx8IPZv2PRz3F7rxKYvuIoDFraDn3tiFhSAhvyeDlSoxtj7c2U/qul3qy1a9fqyKpWLmWdtZQcGWMbSgDDai4ac6ok51CGUH9/fx1J0K7X3AyshJFWhv6rpYmVaI+bPlkl2dZOdKRvAO1euaNHj+p3m/w+LCwM8+fPHwtDIgrdu3c3WZb+gCJFisSSSfiNGTNG/xSj31MGUy2x1NqYkj5R+K4SjUKhaV6pvMMJ6UwEVrs+fa9lQueb2k/ZfrXyta/VqlUzVQxP2qMdr/9q7jVssgJWHiCIpZUNYNn0glhahp9yoyOvzcByHt5Y/0+tV1O5ucVM4fjyv+t4ZvdC7Fn2K8zbbgnejvt8QIBkBQTC8eLsBpgxZxtcxxJgvV/b0a6IpRUAtfqUixYtwjRp0nDvBXkSKNslZUdcvny5RbqRXLpB0/caNW7cWJGQP1ZbD+vXr2+R/qYOJkLQsWNHXaIYWjt5T81pRKxy5szJySrZJH369JgyZUocPny4OeJ0Y0g/0kufXHbr1g0/fPigO8eab7SE2tJSHmQL8mSxupfc06v1ltWrV8/s5dE+ZHowQnagcEvax0vvGzVqZJZMKlkS1xYUnmpJQiBTFNGGflLpEbkbeWIp7Ja87rRm+pOikZ1r1qzJ7UC2oCRN9EoPAEz1/lJpJNKLviva6A3aGuEoDxqlsYgUVhUyzEBAEEszQFN+CAvJXNAgK7rn6Iw7XinzBFH5Rap4xvBjOCifN/uBd8GA8n1w7RWRvsf61orGx9v6YP50FXDCyRh7CGJpfatIpQGl2acbK6lq/f36669cHiXCILn//vuvVKomKWfmzJkYEBCgmPeHFKKbXMqAS+SPEoFQXT1z9nrFXRx5tdasWRO326zPrVq14qSoTp06nPCbS3zNmtzIQUTY/vjjDyPPTvy0169fc6JA+BFZtSTZjv5MlPhmyJAh+l0mv6fsxbTXsEGDBvz6sEZNSyoHNGXKFJN1N3UAXRuU2Zi8u0Sc5agz27NnT6xRo4apqunODwwM5Hb49ttv0cPDA8nT6khNEEubtrYglqo3X/RT3N67NHr7lcJRB0XNS+vZKwpDnl7BzcOqYiqWafm3q8rX+7Le2tU3c9SDFdgoYy7stP7LXllBLNVnJ3M1kppYUoidNrsneRCUDLkkjx+RWaqlqVQ7c+YMn5OS+EjZpCSWVHqDbvKJUJLXUirCKuV6CxYsiKNHj5ZEJIUOk/eJCKaUTQpiqbUFPXwgD6hUpNeUdVKJIXrYIHfT7oOka0SuZimxpMRMFEJNrU2bNhaRVLnWKKdcQSzlRFd22YJYyg6xJRMwUrljQHn0TVkKh+9+FG//rCWixVgzEXi/CVuk9MQqU6+bKUAMkwKBj+fGYVF3T/Rhdeao1hz/83ZjicrcMLmfP5YddViKaawqg/Y9kafJEZvUxFIfQyIK5B0hUqNEoxtEIk60z1OpNmzYMKS9nVKvUUpiqY8FhRBKVbNUX66l70kvCs+VotH+u2LFikkhKpYMKYilvsDmzZsrlqFVf17yIObOnVu/S5b3tN+ZQuylvjb0lbWUWOrLor32FMKvVFiy/tzWei+IpbWQl2ReQSwlgVEOIRG3cFWXYuibvhpOOPxCkEo5MDZD5qdXq7ChjwdWm37DjNFiiGQIhD3GK6dOIpVB0P4dntIAU3hUxJ/3n8TLD95LNpW1BDlquRHCW05iqYTHIu53hjKeDhw4MG63LJ/phplI5dChQyWXLxexnDt3Lnp7e0sSrivloimBjVT7Y+k7IEetRqmJ5apVq/iDkLdv30oJZZKytB7d9+/l/e2mrNOWJk5KajFSEkvCg647S/eZJ6Wzmo4LYqkmaxitSxS+e3KPheZcx1m12Kbv+nPwBgvTuffsgyAwRmMo44ksQ+mfjXOgV8ZaOGlvMA+hojAq+rv34CWKfKQyYq8n+uOF5Thq8lo88d9b5Ll6Qm7jpl5lMLlPRZx+RYTC6kGlirf2FgoriKV0eyz1v6BEvLJly4YjR47U75b1fY8ePbBixYqyzqEVriXOp0+f1nZJ9ioXsdRmYN2xY4dkukohiPYulipVymJRRNIoEcvmzZstlhVXgNTEknQlDzsRTCXbw4cPefj2oUOHZJv2yZMnPByZyg/J2aQklqQnJXqiZGOO0gSxtEVLR17HX0p/yYhF+z/oz/ub3/BZ3DIMtrg+W9c5bBd2yeDBbaK1jfbV2b8lbgpTJoTL1mG0VP/Iy/OxUc5U6KpxRnffVOjjxl4zVsB+G27EKdtj6UxivBQICGIpBYrqkCGnx5JWSFkwKaumUm3p0qVIhecjIxOoYyShIkSYs2bNKkuon1zEkpZfpkwZ7Nq1q4RIWC5qxowZktRX/OeffzihkaOchtTEklCjrKkUEqtkowc+lORq9uzZsk27cOFCfh1q9y/KNZHUxFKrNyXicoSmoUWym17RBAICAYGAHSIQDSFP78Gde0/gg1tayJ0/K/i52OEyxZJUhwDzcAG72QaWKVF1usmt0JUrV4DV/gOWFRZYWKfk0zGvCBC+csmPq/C1a9cgb968cO7cOShcuHDcw5J+zpcvH9StWxdY0XtJ5ZIwljkUli1bBox0SC6b9J0+fTowzxWwGoOSyzdHIEsoBO3atYOIiAhgiXfMEcHHsLBkYN5YYN5ks2UkNLBcuXJQqVIlmDhxYkKnmNw/f/58YHtCgZUB4TY3WYCZA1gWVGDkEhYvXmymhMSHsXIs5AwD5jlO/EQLj/7www9w/fp12L17t4WSYoaTHVjZJdi4cSOwzL2SyFS1EEdgz2KNAgGBgEBAICAQUBKBadOmIbuRUHJK1cwlt8eSMsRSvUwlyhsQqNHR0ejj44Pshl1WjC9dusQjXagOnhxNTo9lcHAw1/3wYfUk3tq/fz/XydLC9OSN7dWrlxwmQTk8lo8fP1YkZDQuIFQep1ChQnG7JflMXkovLy9csGCBJPISEyK1x5Lmqly5Mq9Nm9i89nJMeCxVTfuFcgIBgYBAQCAgELAtBOT2WBIa//vf/4DmYURGEXC+/vprYPXzgNXNk20+llkTFi1aBHfv3rXIw5aQgnJ6LGlO8lKT10otXnpGdoFlKoWLFy8CC51OCJZE+0NCQsDX1xdWr14NTZo0SfRccw7K4bEkPcqXLw/k/WZEzBy1zBqzYcMGYNmBgSWskdxTunPnTqhduzaw/byQLl06s/QzdpDUHkual9XDBZbRFtg+UWBZYo1VxSbPE8TSJs0mlBYICAQEAgIBgYA6EVCCWLJ9bzxklG40KcxM7vbjjz/C1q1b4cKFC7JNxeouAiuRAczbLcscchNLwogIGIUoWxJ6KtXiieCkSJECdu3aBfRgwJxG4ZBkE1YrEvz9/c0RkegYuYjl1KlTeTg1814qFpp8584dYIm1gGX6BpZFN9F1m3qQeRG53BMnTpg61OTz5SCW9LCI7Z2GwMBAqFq1qsk62dQAe3G9inUIBAQCAgGBgEBAIGB9BOQOhaUVUjF4KnHxxx9/KLLgLVu28MygcpVTuHr1Kg/bPHLkiGzrkTMUlpQ+deoUXwMj37KtwVTBFD7J9pWaOkx3/ogRI5B5/nSfpX4jRygs6cjIPbfFgQMHpFY5QXmUwId5d3HevHkJnmPOAZKbKVMm/Pnnn80ZbvIYOUJhSYmiRYvKFlJt8iJlHCA8ljb1GEAoKxAQCAgEBAK2gAAlsGCFvM32lNjCGhPSUQmPJc1NYXesvAJPrJKQLlL1UwgbheDt27cP2H4pqcTq5IwdOxbYDTncu3cPWGkLXb+Ub+T2WLJ7VR4uTGHKLLutlKqbLStnzpw8bHrw4MFmyaAkUeRJ/v33380an9QguTyWNK/cHnBDa6tWrRoPP2a1TQ0dNquPkmYxUgZnz56FIkWKmCXDlEFyeCxpfrrGKTSZlZ5ThUffFExMOldG0ipECwQEAgIBgYBAwCEREHUs5aljqf9l0haDf/PmjX63bO8zZ86MkyZNklw+eWQYAcKBAwdKLltfoNweS5qLktyQZ0Ytja7Dvn37mqUOlYdwc3OTtSakXB5LWrCcpWsSApRlo5Wkdqi+fEoKRLVr6TpRosnlsSRPPiNo3LOvxDqsNYfwWJpEw8XJAgGBgEBAICAQSBoBUW5EvnIjWvTfvXvH970tWbIEWrVqpe2W7ZXKdLCbW1i/fr2kc7AssLw0DZWzYFk1JZWtL0xujyXNFRQUBOS1usP222XJkkV/equ8J5tR+RP2EMLk+bX7K2mfolz7eOX0WJKHr1ixYoqUydGCu3LlSujUqRNP4OPq6qrtNvuVkSPuAW3cuLGkJVkSU0gujyWthTzoFGlBiXzstQliaa+WFesSCAgEBAICAashIIil/MSSjEtZSJMnTw5r166V3daUEGXWrFlw//59SeeiG1mqzUkhf3I2JYglKwXDSRgl8mGeQjmXY5TsPn368PqTFMJsahsyZAgPs5YzYZOcxJKIDCWM6dixI4wePdrU5Zt1vrbmK2FGobiWNnrYQuGvbP8uFC9e3FJxRo2Xi1jS5IMGDQJKPMb2oRuli02eZC1XqZhXICAQEAgIBAQC9oqACIWVPxSWvjtUW5IRS6Q6d3I3SoTCbvTw4cOHkk0VERGBKVOmREZaJZOZkCAlQmFpbkZkeN2+hPRQsn/ChAmYK1cus6Zk3j7s37+/WWONHSRnKCzpwIg1Fi5c2Fh1LD6Pasx6enri0qVLLZZFAih5EiPHioXB0pxyhcKSbKrzSr8h169fp4922cAuVyUWJRAQCAgEBAICASsiQDd0SmUsteIyDU6tRFZY7cQsqQ4vBv/3339ru2R7/fDhA7KwSty0aZNkc2zevJlnm2VlUySTmZAgpYildk2sREdCqijWz5JoISs5YvJ8z58/598r5l0yeawpA+QmlsxTy4nM7du3TVHLonOZF5YTWouEsMHavccs8ZKlokwaLyexjI6OxoCAAFn2apu0SBlPFqGwNulnFkoLBAQCAgGBgEBAnQgolRVWu3rmHYY8efLAn3/+qe2S7ZXC8ij8dvz48ZLM0bRpU74f7d9//5VEXmJClAiFpfmZ9xhSp04Nv/76K99vl5hOch8jXL/55hsICQkB5kkzejoKrW7bti28fv0aWMkSo8eZeqKcobCkCyMyPDR52LBhwLyvpqpn1vksgRMPP2YefrPGawdpw2DlqIupncPQq5yhsDRft27deD3co0ePGpre5vsEsbR5E4oFCAQEAgIBgYBAQD0IKE0sp02bBixbKyhRDL5r165w69Yt2Lt3r8WAE2mhpDCLFi2CNm3aWCwvKQFKEUvSo0mTJvDx40fYtm1bUmrJepz2+rFQULh58yZkz57d6LnIzsHBwby8jNGDzDhRbmJJKnXu3Jmv5eDBg2ZoaPoQKrXUu3dvXgrIktI5tE+XkgHR9abRaExXxMwRchPLnTt3Qu3atYGF1EP69OnN1FLFw2T0hgrRAgGBgEBAICAQEAg4GAJKhsIStOzGk4f77d+/X3akmVcUvb29kULaLG0UKs28YUghtko0pUJhaS3Lly9Hmo9l7lViaQnOQeG47BYcWXKkBM+Je4BCMFlGW2SZO+Mekvyz3KGwpPDWrVt5WC+FjSvRWBIqjjkj5mZPRzagvbFKh8GSwnKGwpJ82ldN4dmsNip9tLsmPJYqJv1CNYGAQEAgIBCwTQT27NnDwwGVKOitNoSU9ljS+skrVb16dZg+fbqscFy8eJGXBKGsjvny5bNoLvJWUfkBlujEIjnGDlbSY0ne2DRp0vAyHxTua61G5WEYwTVJD/KQ5ciRA44dOwalS5eWVXUlPJbh4eH8t2jmzJnQpUsXWddDwiMjI3mm5mXLlkGLFi3Mmo8yJLN6qKB0GCwpK7fHkuZo3bo1vHz5EpQIgaf5lGyCWCqJtphLICAQEAgIBBwCAVFuRJlyI9ov06hRo4BuZFmSElnD5mjPGsviykNvu3fvrp3e5NdLly7xcgzMywqVKlUyebw5A5QklqTf119/zcnlihUrzFFXsjEZM2YEKh1Ce/+MafPmzePn040/1cCUsylBLEn/Zs2aQWhoKGzfvl3O5ehkEyFn3lggMmtOGzhwILCEXHD16lVZr2dDuilBLGkPL4W/syRR4Ovra0gNm+0TxNJmTScUFwgIBAQCAgG1IiCIpbLEUuvhoKLwcnuJ6SadvECW7B+k+orkrVDyxllpYslC/WD48OHAwlHBzc3NapdqyZIlOck1NuFS48aNua4bN26UXWeliCWR+06dOnEiw8IwZV8XJQui64MeoJja6OFNpkyZoEePHkD7LJVuShDL9+/fg7+/PyxcuFCR/dWKYmh3wb1iQQIBgYBAQCAgELAyAqKOpTJ1LLVm1u6L++mnn7Rdsr1SCQsPDw9kHiCz5qBxfn5+itSu1FdQyT2WNO+DBw/4XjuWrERfDcXf169fH9u3b2/UvLT/jfbQUn1UJZoSeyxpHSw0GV1cXHD16tVKLAtZcitue3PK6OzatYuPVbJEij4ocu+x1M5Vp04dZEmutB/t5lV4LBWl8WIygYBAQCAgEHAEBITHUlmPJX2nqJwCZWulMgVytqdPn/JsrqzGIc/uaOpctKfyf//7H88KSV4LpZrSHktaV5kyZfheublz5yq1zHjzDBgwAKi0w5EjR+Idi9sRFBQE1apVg/v37wOF0MrdlPJY0jpq1arFw7hXrVol97K4R589PAFG0KFdu3YmzUchovfu3QOlstjGVU4JjyXNSd5KilygcFj2oCquGrb72W4osliIQEAgIBAQCAgEVIIAC6fDsWPHqkQbZdVQOiusdnWUFZbdjfEssdo+uV5ZeCXPHmmq/KioKMydOzeyJCqmDrX4fKU9lqTwhAkTMF26dJJk0TUXALZnknuIyaudVBs0aBAWLFgwqdMkO66Ux5IUZuSee2NZGLdk+icmqGbNmkZ7irVyyMtNnlUWuqvtUvxVKY8le0CFrBwLz9qr+CJlnBBklC1ECwQEAgIBgYBAQCDgYAiwrLC8jAarHajoyom0MQ+gIiGmo0eP5iUpjCEr+iCsWbMGWUIYVBob0oElHcINGzboqyP7+2vXrnGyz7yFss+V0ATaBw5UeiSpxjL9KlrignlHceTIkUmpJclxVjeR24J52iWRl5SQyZMn84cKplwjbG8mZsiQAVkN1KTEy3a8X79+WLduXdnk6wtmkS343Xff6XfZ/HsRCmu7zmahuUBAICAQEAgIBAQCeghQOQVGZoDVLdTrlf7tqVOngJLCUGmVvHnzGjUBu8HmiYUouRBlsHWURmVZ2I06MKJhlSVrQ5cptJLtfU5QB22ZHAqbpRBee2yUqZV5ZHmIqtzr0ybUMrY0T0hICE/aQxl86c8R2owZM+CXX34BVmMUmKfWLpYsiKVdmFEsQiAgEBAICAQEAgIBKqdQr149ePz4MQQEBMgGCJHE9OnTA5VFoD9j2pYtW6BRo0acjObJk8eYIXZxzogRI4DKKwQHByteOoIAZC4goP1+06ZNg86dOyeIKZWsof2vd+7csYqeCSom4QEi94QDS6ojeykVukbSpk0LZH/aS5hUoyzCLBQZWDgst1dS59vD8bt370LWrFlh3759ULlyZXtYEghiaRdmFIsQCAgEBAICATUhcOPGDfD09AQW1qUmtexeFyoDQklXli9fblZiHVMAIpJC3tHDhw8nOYzIDXk4s2fPDiwcNsnz7ekE8u5STUvyCLL9llZZGtVVpBv3hLymZB8i+w0bNuQ1Sq2ipAKT0u9S8eLFgWySK1cu2Wds1aoVsIy0wDIDJzoXkVDCn+3LhDlz5iR6rr0dJHtQgqO+ffvaxdIEsbQLM4pFCAQEAgIBgYCaEHCErLCfoqMgCjUshMsZnFQEPtufpUjdRPIyVK1aldfqy58/f6II0I117dq1ecbaQoUKJXquFAfVZBsibWz/K7i6ukqxNLNksHIj8PbtWyCvsaFG9U+LFSsGZ86c4VlsDZ1jXt8niGZrR40LuDir4ypR6vogvDZt2gRU95W8kOS9TKhRzcsGDRrA9evXIWfOnAmdZpf9StpDCQAFsVQCZTGHQEAgIBAQCDgUAnZPLKOCYXyF0jDiXGYYffwkjCrs5lD2pcUSYaL9lVTGYdasWQmuPzIyEmhvG3mvEyI2CQ4254CwTTzUxo8fz8NcibgYarSnj0gQHddoNIZOMasv6upUKF94CFwsOAyOHh8LhV2kk22WQgoPItJEXurhw4cDlX0x1MhbSXtf06RJA5s3bzZ0iuizIQQEsbQhYwlVBQICAYGAQMA2EBDE0jbsZKmWM2fOBJYhlu9Zo9BnQ23o0KE8vO/06dPASo0YOkXaPkEs4+HJsuFCy5YtITQ0NJ7nlB4Q0D438mr+/PPP8cZa0uHoxJKwo7qQBw4c4N56Q6SdHsoMHjyYh+dSYiHRbBwBdkGJJhAQCAgEBAICAYGAhAiwJ/DIkrpIKFFloiKv4y+lfRGSFcLR5yJUppxy6rx8+RJZcXNk2R0NTrpjxw5e4oHt+TR4XJZOYZt4sF68eJHbgcqfxG0sCyw/RvVXpW6RV6ZgKVcn9Cg2As9FJl1HU+r51SDv5MmTHF8q+xK3kT3c3d15vdO4x+T9HI1RkREYGRUt7zQOKF14LG38wYBQXyAgEBAICATUh4DwWKrPJnJpNGbMGJg+fTpcuHABvvrqK9009+7d44lS6tevDwsXLtT1y/5GeCzjQUxJnby8vHh22iZNmsQ63qFDB+5No/IYUjfhsYxB9Ntvv4Xnz58DlXLRltWgMNlKlSrx0GMqBaPtl9oGhuQJuxhCRZo+QSylwVFIEQgIBAQCAgGBgA6BsLAwns7fzc1O9x7GIi/HYUDyg7BkwWrYc/oWvEZfyF62AXzfuz2U9HfWYaL4m/D/YO+yxbBm90m49ew9fPJIAzkKl4HqDZpBw3JfgbtEChFpoT2U0dHRvD5l4cKFYdeuXTy0kvaXUdZYIjWKNTXaRiFbJIZx+fLlgZIszZ8/X3fazZs3eTbSlStXQvPmzXX9Ur2JRWCODgOvoGWwYPUuOHPnFaBvVijbqDv0aVcGUls1r0843An8CxYxvU7fegofPnlAQPZCULZGA2jWsBxkcrd8XyiVmqH6rZQllkJf379/z0OTicyfOHFCmRBxPaPGsosq9r7KbwO95cv71gG9tGLJAgGBgEBAICAQEAhYgoA23NI1K9brVBezeTihk1sKDMgQgClcNSz0TYMpivTFwNfWCf8Lvbwc2+X1YzlrWUJOV29MkyEdpvR04Z9BkwJbr31nyerjjb19+zYy7wsP+aPQPnbnhm3btkV2Ax3vXNk7VGYbpW2REL4TJkxARvSRJYvRncK8lZgvXz5kDwV0fVK+0YbCumWvg9/VyYkeGid0SxGAGQJ80FUDCBovLDZwF76WclJTZIVew8XtC2NyrosreqfJgOlSeiHLMcSvYf+WK02Rlui5LDEPpk6dGplnkl8fOXLkwKtXryY6Rq6DWruoIkRZQRvIhae+XMpqJppAQCAgEBAICAQEAgIB4xHQkhdGIJ1S5MZm4zbglVeRfPzHR0E4pHRq1Gg8sNr0axhlvFRJzvz0ai/2zO2NGicfLNl9EZ5+8TFGbsRzvPD3r9i9Sh5ss0JaYkkTEGHZuHEjLlu2DGlfmT6BkWRhxgpRkW2sZQtDUNEeSiL8R44c4YeJ1Dg7OyOrK2rodEn6tAQGGKH0+X97dx4eRX3Hcfy75CIHkBCRhohyCBKsB8VSEFJF8MFIFQhnkSJaA7XYBnkUVI5CRVBQCbXYVuQhgKUitlCpgUqKqA8iRUFMOSqXgpFwCNYkZEN2+XYSzQG5lt3Z2SXz5h92d2Z/x+s7myefzG9nklL1qTU5eqrsA1GiX2ZP025NQrRRTLLO3/fdMWpKr5428rWuf+hGDTfGFtc1TZd9eEK//QQX67GcLM14sI92+ulSTxvzaD9jOawa96lU4/Y7atz+xaP3+GOn8roEPlhaXwN/eFZtk2BZVYPHCCCAAAIImCBgLI9U4ztEJrQUpE2Uh5ewDvrwpuq/IJ5cOkKbOBwan5qpX1s6BZfuntu37MxQy/4v6qGaUq07X7/J988ZKkunWltnQVOb4KtFt27d9LbbblNjCawaV+hVYwmz385WlpanPMBEdBqv7+RXnin9tnSnNXNQK+MPMDE65JWvaqum314v2TNfe0aGaMhld+iigzX9rHJr/jcBOOPutxlXNlxel7JgWVyg+9a/qJPGDNS+t/xY+wy4V6dmbtETFvyIaIg1IFhWHmc8QgABBBBAwBQBu18V1rnpUW0f6tCYW5/Vzyz4Ba2iaO7DmtE73jhbGa+jXw/YAsOK4QTkQXmwrOWKvZbVJghrYdzyRePi4srOXBoXWtK8vDy/lui8AFPtqrDF+nb69Roq4donY79a+TFRo7dDGSkaYZytbDVqpZp//t6vrD43Xl6XwC5Rbpg1IFj6fHjSAAIIIIAAAucL2D5YfjBNk4xgGf3jZ/RgTWcNz+cy71nROzq+bZQ6In6oT++u6SyMeV0FbUv1BUurahOktShdEpuVlWXJ91/LA0zNSy6Ldcvkm4xgGaa9n/vU4iXjTs1+6FoNMfruOSfH4r4D/8kpr0tglyg3zBoQLAN/fDMCBBBAAIEGJkCwnK6dAxIs/6k/T4xUR2SyLjj07TfGGtihVf906g2WFtWmiFqUB5hag+VjgQuW/3igoxEsA3G2tP5D2N97lNclsEuUndoQa0Cw9PfRS/sIIIAAArYTIFhaFF4uPLKcW/WRpBiV8M46dVvxhVvt8TxYgiW1qPiOZfAFy2Ld/GjXsrOlN07Z8t1Fe+zx8SidZXmwrK0u1ixRbpg1IFja53PETBFAAAEELBIgWAYoWBqXClo++ArjgiiNjeWF1l+R1qLDq+5ugiVYUot6A8yWgJ2xVP3qlZEaa1xgq+ktz+h+K5er1330WrK1vmBp1RLlhlgDgqUlhzCdIIAAAgjYSWDv3r165MiRhjtlH8NLwcEP9F87cv1ywZKv/vqAtgpxaNhVw3RFteWwLj22dbmu2lZ0fm0KD+mW7O161NorqJw/BrOeeVkbZ16OZq/K1IXzZuvs5xfpG9vzfD6TdVG1cB7Tndmv65KFz+rs2c/r4r9/pMcv8dXM9QaYGoOlS0/tf1/X/vklnT9nlj7zwnLd+N/qV1729XA599XfdVSrxuoIvcK4/c6Bat+zLDm+TZeu2vpdN9aMydc5efp+7+riaeue73dxNTi/3bO5O3TDW9s0N8g+IwTL8+vEMwQQQAABBBCoT8DL8FJ6NcozR97VGb0T9LKhr2hhff14s931mS4b3tG4Ab1DIxJ76Jhp8/XlzMW6cO5UTet/vcaHReqQKvexdBfl6tsz+2nzuFRdWXjhLSG8GUCA3+NNbQr+psPiGmuzNjfp7YMG64BbkzQu/DLt/dt3fbtiqMe1KNRXh7fW0KZXabfbB+rgAb31mrgIbXnLb3TzN5duTbwJMEUbJmibsCht1bmH9hs4SPt1ba2RkW10xJI91cKfb0eaSw8u+5leGdZIHeEJ2mvMVM14OVMXL5ynT4y9S78fH65xqd/ex9K6Mfk2I0/f7U1dPG374vbzvAZV23Wd2KgP3xCnjaJTdMnp4Pp8ECyrVorHCCCAAAIIIFC/gDfhpeSALkhpo7HNmmpUmMN/wbJ09MWHdPUTA7Rj01B1iJTdXkKM/x0hTbRt8mhdtLP0+5cu/XTBQE2IbaZNo8K0Uewg+wbLs7t1/erterJiSaRTdz51m0Y37aN/POzjKRGPalGiOetX68cnK/sq+mSu9oiO0Tv+cMgvZ7brP8h938ObAFOyf5Ou2ZKrFd8Qdp/QV0derY2T0nVzsdkholgPrJ6ud3aM0xBH5edEHCHatG1Pve+l7WUI1o7Jd/f6WvCmLvW16f12z2pQ0b5zr77Yv522bnelRsYEX7B0lA7U+GHLPwQQQAABBBBAwAKBM7J0YDt5JPw5+fy1eyTKnz2eyZNPtm2XfXn5otEtpeMPbpLrW8VU67Fg2Qi5PP2sZOb+VYZFGVGUf+LcOFE635klwzd9LHO6N/ZdxMNaVHTkfFfGd+4v7w1bJx8+3UvCKzbY7cFZ2fxod7n9H8myYWeG9Az3x/F5Rr785EPZse+oFGi0JHToIl1vSJToWqmtGFOtnfu8wbXnWel5w2TJue5x2bL1SbkhtKrpWfng8Z6S/PROSX5ul2yY2EFCqvXoktwd78iec9fIrV2vkNBq2715wYManDspWRNSJO3j/vLnBw7KoPEnZf6RN2VMbNXxe9O3ie+pSMA8QAABBBBAAAFTBFJTU3XWrFmmtNXwGinUzAEt/XvG8iLR8pcO18iGcsbyIude8+4u3TO3j0Y2S9HFRytOY9a8q59eLdk7X2+ObKJ3v/zFJXvG0ica5yn9fO8OfeuldO2e2FFHL99n8lJYL0YXjGPyYhq+nbF064kNk/X6qEba7Ccv6Wkv+vfuLU7N+d0AvaLDPbrqsEvzXxujsUF4xpKlsN5Vl3chgAACCCBQq0CDvypsrTP3ZAPB0hOlQO5Tsi9T706I0mvGvaGnAjEQY9n0ogFttfHVP9d1p8xe/hmICV18n87NUzWp9PuPoS00eeIK3ZMfeIdgHNPFy9Z/u5G6rtbr3LVI70y8UttdGamxlgVLtx5dm67XJvTSOdu+KZtysAZLlsKaePaXphBAAAEEECgVSE5Olu7du8u8efMAqSZg4VLYan3X/AJLYStd3HlvycMpI2VF5DhZkzVLelm9zO7cccl6+G4ZsVxl4hvrZEav5pWDs9sj9xk59t+NkjFurCyJmizvZKXLNdXXZVqrEoxjskjAfXyDTOh7n+QMXS737x4t6QXT5dDaNIn1c//u3BUytPtMicvIlkWDW0sjo7+CVfdJ6/uPBd1SWIKlnw8GmkcAAQQQsJ8AwbKumhMs69IJ5DZ3XrZMuuseWRZ2r/xl9Rzp29LiFGOEyvWTUuWnS0rklyvXyJN9E8p+iQ6kSTD0nb9qjFw1ep9M/c8mmdg+LBiGJME4Jr/COPfIC4P6y8LLZ0v2krvl/VGdZFz+NEuCZcnOp+RH3WfLwciIys+Dq1D+VyASFdtMrvv1Gnl/xs1+nb6njRMsPZViPwQQQAABBDwUIFjWBUWwrEsnUNuK978u4wf9Qv6ZMEFWrnxcbo6zOFSePSivjh8qD2bFyuRVr8mkm+Mrf4kOFEqQ9Htq+UhpO+6IzNy1USa0DY5gGYxj8lu5jD94rH0oRR7cPVDWvDlVboouktdGWhcsxZkne3Z9IYVVLrd6dtMsSZl+Sh5Z/7wMbt9JOidWvyiZ3zzqaJhgWQcOmxBAAAEEEPBGIDs7W+Lj46VLly7evL2Bvsct+ce+lNPFRbJmbE+ZGTFDtr5wl0RExktii+iAhAh3/nH58rRTCtf8SrpMc0vGRwslJSJK4hNbSHTpejOb/HPtWybD+jwkH133mGQuuEfaV1x51CEhMS0ksbkJV4Wty9J1QBYPv0PS/91epi99QUZcHVGxtyMkRlokNhc/j6Civ8A+cEnO0tmyPrqfjOjXVVo3CZXCA2vlsWFjZEXTybI5e5J0sjjviwTjmKys0jn5Yuko6TEnVBb8a4mkJpYW4Iy1wbKG6bIUtgYUXkIAAQQQQAABmwi4PpXZvX4kU7Z+fd6Em9yxUA68+UtpYXmQc8vuOX3lxic2SUmVETkib5c/fbZO0i63/Df4KqOw9mHRul9Jh7t+L7nuC/ttJN8b9aocXT70wg3mPndukLSrB8jLuUXV2g1pMUJeP7xCBjYOolsqVBulWS8Yx+SLo2TglL/J/vxG0iw2Qs587ZSWPcfKgiXPyaB2gThbGYxjMsvbk3Zc8vGMW6XH3P9IZOPKH1Kuwv9JgXGzpNjYTpK+9j35TTdr//RBsPSkduyDAAIIIIAAAggggICdBdyFcuzzz+TwsXwJT+go17ZpbtK9En1ADcYx+TCdi3mr8+he2ZVbIJUrUUtk0/RUmVk0Vt58dpi079RZEqPt8IeP+tVYClu/EXsggAACCCCAAAIIIIAAAoZA4JfCBmsZCJbBWhnGhQACCCBwyQpMnDhRkpKSJC0t7ZKdAwNHAAEEEKhJgGBZk0rpawTL2mR4HQEEEEAAAS8FuCqsl3C8DQEEEEDgkhUgWF6ypWPgCCCAAALBKjBkyJCyK8JOmTIlWIfIuBBAAAEEEDBVgGBpKieNIYAAAggggAACCCCAAAL2EyBY2q/mzBgBBBBAAAEEEEAAAQQQMFWAYGkqJ40hgAACCCCAAAIIIIAAAvYTIFjar+bMGAEEEEAAAQQQQAABBBAwVYBgaSonjSGAAAIIIIAAAggggAAC9hMgWNqv5swYAQQQQAABBBBAAAEEEDBVgGBpKieNIYAAAggggAACCCCAAAL2EyBY2q/mzBgBBBBAAAEEEEAAAQQQMFWAYGkqJ40hgAACCCCAAAIIIIAAAvYTIFjar+bMGAEEEEAAAQQQQAABBBAwVYBgaSonjSGAAAIIIIAAAggggAAC9hMgWNqv5swYAQQQQAABBBBAAAEEEDBVgGBpKieNIYAAAggggAACCCCAAAL2EyBY2q/mzBgBBBBAAAEEEEAAAQQQMFWAYGkqJ40hgAACCCCAAAIIIIAAAvYTIFjar+bMGAEEEEAAAQQQQAABBBAwVYBgaSonjSGAAAIIIIAAAggggAAC9hMgWNqv5swYAQQQQAABBBBAAAEEEDBVgGBpKieNIYAAAggggAACCCCAAAL2EyBY2q/mzBgBBBBAAAEEEEAAAQQQMFWAYGkqJ40hgAACCCCAAAIIIIAAAvYTIFjar+bMGAEEEEAAAQQQQAABBBAwVYBgaSonjSGAAAIIIIAAAggggAAC9hMgWNqv5swYAQQQQAABBBBAAAEEEDBVgGBpKieNIYAAAggggAACCCCAAAL2EyBY2q/mzBgBBBBAAAEEEEAAAQQQMFWAYGkqJ40hgAACCCCAAAIIIIAAAvYTIFjar+bMGAEEEEAAAQQQQAABBBAwVYBgaSonjSGAAAIIIIAAAggggAAC9hMgWNqv5swYAQQQQAABBBBAAAEEEDBVgGBpKieNIYAAAggggAACCCCAAAL2EyBY2q/mzBgBBBBAAAEEEEAAAQQQMFWAYGkqJ40hgAACCCCAAAIIIIAAAvYTIFjar+bMGAEEEEAAAQQQQAABBBAwVYBgaSonjSGAAAIIIIAAAggggAAC9hMgWNqv5swYAQQQQAABBBBAAAEEEDBVgGBpKieNIYAAAggggAACCCCAAAL2EyBY2q/mzBgBBBBAAAEEEEAAAQQQMFWAYGkqJ40hgAACCCCAAAIIIIAAAvYTIFjar+bMGAEEEEAAAQQQQAABBBAwVYBgaSonjSGAAAIIIIAAAggggAAC9hMgWNqv5swYAQQQQAABBBBAAAEEEDBVgGBpKieNIYAAAggggAACCCCAAAL2EyBY2q/mzBgBBBBAAAEEEEAAAQQQMFWAYGkqJ40hgAACCCCAAAIIIIAAAvYT+D+7El20roE72gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aims to understand Spoken language understanding paper by Bing Liu\n",
    "# https://arxiv.org/abs/1609.01454\n",
    "# Title : Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling\n",
    "# I picked (c) Encoder-Decoder Model with Aligned Inputs\n",
    "# Further works to implement 3.2 Attention-Based RNN Model\n",
    "from IPython.display import Image\n",
    "Image(\"picture.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Most of data preprocessing steps & basic seq2seq architecture (indexing, instantiating to class) I followed below pytorch tutorial and official chatbot tutorial\n",
    "https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb\n",
    "https://pytorch.org/tutorials/beginner/chatbot_tutorial.html#sphx-glr-download-beginner-chatbot-tutorial-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines : utters - 4978, intent - 4978, slots - 4978\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "slots_name = \"data/train/train.seq.out\"\n",
    "intent_name = \"data/train/train.labels\"\n",
    "utter_name = \"data/train/train.in\"\n",
    "\n",
    "_DIGIT_RE = re.compile(r\"\\d\")\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalize_string(s):\n",
    "    # digit regular expression compiler\n",
    "    _DIGIT = \"DIG\"\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(_DIGIT_RE, _DIGIT, s)\n",
    "    # below two are not necessary\n",
    "#     s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "    \n",
    "def read_langs(utters, intents, slots):\n",
    "    utters_ = open(utters)\n",
    "    intents_ = open(intents)\n",
    "    slots_ = open(slots)\n",
    "    \n",
    "    utters_ = [normalize_string(line).split() for line in utters_]\n",
    "    intents_ = [normalize_string(line) for line in intents_]\n",
    "    slots_ = [normalize_string(line).split() for line in slots_]\n",
    "    print(\"Number of lines : utters - {}, intent - {}, slots - {}\".format(len(utters_), len(intents_), len(slots_)))\n",
    "    return utters_, intents_, slots_\n",
    "    \n",
    "    \n",
    "def loading_data(utters, intents, slots):\n",
    "    input_utter, intent_labels, slot_labels = read_langs(utters, intents, slots)\n",
    "    \n",
    "    return input_utter, slot_labels, intent_labels\n",
    "\n",
    "input_utter, slot_labels, intent_labels = loading_data(utter_name, intent_name, slots_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default word tokens \n",
    "# PAD token is used to put different length of sequence into mini batch\n",
    "# SOS token is to mark as start of sentence\n",
    "# EOS token is to mark end of sentence\n",
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_token = 3\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2count = collections.Counter()\n",
    "        self.word2index = { \"PAD\" : PAD_token, \"SOS\":SOS_token, \"EOS\":EOS_token, \"UNK\":UNK_token}\n",
    "        self.index2word = { PAD_token : \"PAD\", SOS_token:\"SOS\", EOS_token: \"EOS\" }\n",
    "        \n",
    "        self.slot2index = { \"PAD\" : PAD_token, \"SOS\":SOS_token, \"EOS\":EOS_token, \"UNK\":UNK_token}\n",
    "        self.index2slot = { PAD_token : \"PAD\", SOS_token:\"SOS\", EOS_token: \"EOS\", UNK_token:\"UNK\"}\n",
    "        \n",
    "        self.intent2index = { \"UNK\" : PAD_token }\n",
    "        self.index2intent = { }\n",
    "        self.num_words = len(self.index2word)\n",
    "    \n",
    "    def addCorpus(self, sentence, slots, intents):\n",
    "        \n",
    "        for words, slots, intent in zip(sentence, slots, intents):\n",
    "            self.addWord(words)\n",
    "            self.addSlots(slots)\n",
    "            if intent not in self.intent2index:\n",
    "                self.intent2index[intent]= len(self.intent2index)\n",
    "        for key, val in self.intent2index.items():\n",
    "            self.index2intent[val] = key\n",
    "                \n",
    "        \n",
    "    def addWord(self, words):\n",
    "        for word in words:\n",
    "            if word not in self.word2index:\n",
    "                self.word2index[word] = self.num_words\n",
    "                self.index2word[self.num_words] = word\n",
    "                self.num_words += 1\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def addSlots(self, slots):\n",
    "        for slot in slots:\n",
    "            if slot not in self.slot2index:\n",
    "                self.slot2index[slot] = len(self.slot2index)\n",
    "                self.index2slot[len(self.index2slot)] = slot\n",
    "                \n",
    "                \n",
    "    def trim(self):\n",
    "        MINCOUNT = 1\n",
    "        self.word2index = { \"PAD\" : PAD_token, \"SOS\" : SOS_token, \"EOS\" : EOS_token, \"UNK\" : UNK_token}\n",
    "        self.index2word = { PAD_token : \"PAD\", SOS_token:\"SOS\", EOS_token: \"EOS\",  UNK_token : \"UNK\"}\n",
    "        self.num_words = 3\n",
    "        for word, count in self.word2count.items():\n",
    "            if count > MINCOUNT:\n",
    "                self.word2index[word] = self.num_words\n",
    "                self.index2word[self.num_words] = word\n",
    "                self.num_words += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = Voc(\"corpus\")\n",
    "voc.addCorpus(input_utter, slot_labels, intent_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'UNK', 1: 'flight', 2: 'flight_time', 3: 'airfare', 4: 'aircraft', 5: 'ground_service', 6: 'airport', 7: 'airline', 8: 'distance', 9: 'abbreviation', 10: 'ground_fare', 11: 'quantity', 12: 'city', 13: 'flight_no', 14: 'capacity', 15: 'meal', 16: 'restriction', 17: 'cheapest'} 18\n",
      "{'UNK': 0, 'flight': 1, 'flight_time': 2, 'airfare': 3, 'aircraft': 4, 'ground_service': 5, 'airport': 6, 'airline': 7, 'distance': 8, 'abbreviation': 9, 'ground_fare': 10, 'quantity': 11, 'city': 12, 'flight_no': 13, 'capacity': 14, 'meal': 15, 'restriction': 16, 'cheapest': 17} 18\n"
     ]
    }
   ],
   "source": [
    "#### Before trim words by minimum word count ####\n",
    "len(voc.word2index), len(voc.slot2index), len(voc.intent2index)\n",
    "voc.intent2index\n",
    "print(voc.index2intent, len(voc.index2intent))\n",
    "print(voc.intent2index, len(voc.intent2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc.trim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(578, 125, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### After trim words by minimum word count ####\n",
    "len(voc.word2index), len(voc.slot2index), len(voc.intent2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for models\n",
    "Current variable and class information\n",
    "#### input_utter : list that stores all utterance corpus\n",
    "#### slot_labels : list that stores all slot corpus\n",
    "#### intent_labels : lis that stores all intent informaiton for each utterance\n",
    "#### voc : holds index information for token, slot and intent\n",
    "\n",
    "## Below texts are quoted from below tutorial, but I'm writing to help myself understand better\n",
    "https://pytorch.org/tutorials/beginner/chatbot_tutorial.html#sphx-glr-download-beginner-chatbot-tutorial-py\n",
    "\n",
    "\n",
    "In order for our data to feed them into Tensor, we need to convert them into numerical torch tensors as inputs\n",
    "\n",
    "In order for us to accomodate mini-batch, we will keep [max_length, batch_size] as a shape\n",
    "\n",
    "Hence, any sentence that is shorter than max_length will have \"PAD_TOKEN\" after an \"EOS_token\"\n",
    "\n",
    "For example : [\"How\", \"are\", \"you\", \"EOS\", \"PAD\", \"PAD\", \"PAD\"] max_length : 7\n",
    "In the below ATIS data, maximum length is 46. Hence, we will setup maximum length as 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'want', 'to', 'travel', 'from', 'kansas', 'city', 'to', 'chicago', 'round', 'trip', 'leaving', 'wednesday', 'june', 'sixteenth', 'arriving', 'in', 'chicago', 'at', 'around', 'DIG', \"o'clock\", 'in', 'the', 'evening', 'and', 'returning', 'the', 'next', 'day', 'arriving', 'in', 'kansas', 'city', 'at', 'around', 'DIG', \"o'clock\", 'in', 'the', 'evening', 'which', 'airlines', 'fly', 'that', 'route']\n"
     ]
    }
   ],
   "source": [
    "maxlen = 0\n",
    "for utter in input_utter:\n",
    "    maxlen = max(maxlen, len(utter))\n",
    "    if len(utter) == 46:\n",
    "        print(utter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[ 19,  57, 187],\n",
      "        [ 27,  58,  14],\n",
      "        [ 17,  61, 109],\n",
      "        [383,  20, 110],\n",
      "        [158,   7,   2],\n",
      "        [108,  30,   0],\n",
      "        [147,  31,   0],\n",
      "        [116,   5,   0],\n",
      "        [136, 109,   0],\n",
      "        [125, 110,   0],\n",
      "        [  8, 217,   0],\n",
      "        [ 12,   2,   0],\n",
      "        [ 30,   0,   0],\n",
      "        [ 31,   0,   0],\n",
      "        [  2,   0,   0]])\n",
      "lengths: tensor([15, 12,  5])\n",
      "target_variable: tensor([[ 4,  4,  4],\n",
      "        [ 4,  4,  4],\n",
      "        [ 4,  4, 23],\n",
      "        [16,  4, 59],\n",
      "        [47,  4,  2],\n",
      "        [ 4,  5,  0],\n",
      "        [ 4, 15,  0],\n",
      "        [30,  4,  0],\n",
      "        [ 4,  8,  0],\n",
      "        [ 4, 22,  0],\n",
      "        [ 5, 58,  0],\n",
      "        [ 4,  2,  0],\n",
      "        [ 8,  0,  0],\n",
      "        [22,  0,  0],\n",
      "        [ 2,  0,  0]])\n",
      "mask: tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len: 15\n",
      "intent variable: tensor([3, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "maxlen = 50\n",
    "#### paring all training data and labels in pairs ####\n",
    "pairs = list(zip(input_utter, slot_labels, intent_labels))\n",
    "# Note : Python random.choice assumes uniform distribution by default\n",
    "random.choice(pairs)\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index.get(word, voc.word2index[\"UNK\"]) for word in sentence] + [EOS_token]\n",
    "\n",
    "def indexesFromSlots(voc, slots):\n",
    "    return [voc.slot2index.get(slot, voc.slot2index[\"UNK\"]) for slot in slots]+ [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue = fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value = PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    ### Convert to variable\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "    \n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSlots(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    ### Convert to variable\n",
    "    padVar= torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "def intentVar(l, voc):\n",
    "    indexes_batch = [voc.intent2index.get(intent, voc.intent2index[\"UNK\"]) for intent in l]\n",
    "    intentVar = torch.LongTensor(indexes_batch)\n",
    "    return intentVar\n",
    "    \n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key = lambda x : len(x[0]), reverse = True)\n",
    "    input_batch, output_batch, intent_batch = [], [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "        intent_batch.append(pair[2])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    intent = intentVar(intent_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len, intent\n",
    "\n",
    "small_batch_size = 3\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len, intent_variable = batches\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)\n",
    "print(\"intent variable:\", intent_variable)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines : utters - 893, intent - 893, slots - 893\n"
     ]
    }
   ],
   "source": [
    "test_slots_name = \"data/test/test.seq.out\"\n",
    "test_intent_name = \"data/test/test.labels\"\n",
    "test_utter_name = \"data/test/test.in\"\n",
    "\n",
    "test_input_utter, test_slot_labels, test_intent_labels = loading_data(test_utter_name, test_intent_name, test_slots_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "Unlike original paper ( Takes only last state of backward LSTM for intent classification), I took __mean pooling over LSTM output__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of above description is as below\n",
    "# Picture from : http://deeplearning.net/tutorial/lstm.html\n",
    "Image(\"lstm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding, output_size, n_layers, dropout):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "#         # @parameter information\n",
    "#         # input_size : word_embedding dimension\n",
    "#         # hidden_size : hidden state feature size\n",
    "#         # embedding : word embedding\n",
    "#         # n_layers : number of layers\n",
    "#         # dropout : dropout rate\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, n_layers,\n",
    "                    dropout = dropout, bidirectional = True)\n",
    "        self.intent_decoder = nn.Linear(hidden_size*2, output_size, bias=True)\n",
    "        \n",
    "    def forward(self, input_seq, input_lengths, hidden = None):\n",
    "        # Convert word indexes into embeddings\n",
    "        # embedded : [seq_len, batch, embedding_dim]\n",
    "        embedded = self.embedding(input_seq)\n",
    "        \n",
    "        # Pack padded batch of sequence for RNN module\n",
    "        # packed : [batch*seq_len, embedding_dim]\n",
    "        # For more detail\n",
    "        # https://github.com/HarshTrivedi/packing-unpacking-pytorch-minimal-tutorial\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        # outputs : [batch_sum_seq_len, hidden_dim * num_direction (bi or uni)]\n",
    "        # hidden : [num_layer * num_direction(bi), batch, hidden_sizegru]\n",
    "        outputs, (hidden, memory) = self.lstm(packed, hidden)\n",
    "        # Unpack padding -> zero padding packed sequence\n",
    "        # outputs : #[max_seq, batch, hidden_dim * direction]\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # not sum, concatenate\n",
    "        #outputs = outputs[:, :, :self.hidden_size] + outputs[:,:,self.hidden_size:]\n",
    "        mean_pooling = torch.sum(outputs, dim=0) / Variable(input_lengths.type(torch.FloatTensor).view(-1,1))\n",
    "        #outputs = outputs[:, :, :self.hidden_size] + outputs[:,:,self.hidden_size:]\n",
    "        intent_score = self.intent_decoder(mean_pooling)\n",
    "\n",
    "        intent_output = F.softmax(intent_score, dim = 1)\n",
    "        return outputs, (hidden, memory), intent_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder\n",
    "Notation descriptions\n",
    "\n",
    "\n",
    "\n",
    "Note : decoder takes __explicit input alignment__ of encoder's hidden state and context vector as inputs together with previous eimtted decoder output \n",
    "\n",
    "The author does employ teacher forcing, decoder only takes emitted output as a next input\n",
    "\n",
    "\\begin{align}\n",
    "s_0 : tanh(W_s * h_1^) \\\\\n",
    "Eq.(5) :\n",
    "Context vector : c_i & = \\sum_{j=1}^T \\alpha_{i,j}* h_j\\\\\n",
    "Eq. (6) :\n",
    "\\alpha_{i,j} & = \\frac{exp(e_{i,j})}{\\sum_{k=1}^T exp(e_{i,k}) \n",
    "}\\\\\n",
    "e_{i,k} & = g(s_{i-1}, h_k)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputAlignedDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers, dropout):\n",
    "        super(InputAlignedDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.LSTM = nn.LSTM(hidden_size*5, hidden_size, n_layers, dropout = dropout)\n",
    "        self.g = nn.Linear(hidden_size*3, 1)\n",
    "#         self.concat = nn.Linear(hidden_size * 3, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "#         self.attn = Attn(attn_model, hidden_size)\n",
    "        \n",
    "    def masked_softmax(self, vec, mask, dim=1, epsilon=1e-5):\n",
    "        # This implementation trick from \n",
    "        # https://discuss.pytorch.org/t/apply-mask-softmax/14212/14\n",
    "        exps = torch.exp(vec)\n",
    "        masked_exps = exps * mask.float()\n",
    "        masked_sums = masked_exps.sum(dim, keepdim = True) + epsilon\n",
    "#         if torch.sum((masked_exps/masked_sums)[0]).data.numpy() < 0.99:\n",
    "#             print(vec.shape, mask.shape, masked_exps.shape, torch.sum((masked_exps/masked_sums)[0]), (masked_exps/masked_sums)[0])\n",
    "        return (masked_exps/masked_sums)\n",
    "        \n",
    "    def forward(self, input_step, last_hidden, last_memory, encoder_outputs, mask, encoder_alignment):\n",
    "        # Note : we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        \n",
    "        ############## Refer to above mark down equation ##############\n",
    "        last_hidden_expansion = last_hidden.repeat(encoder_outputs.shape[0], 1, 1)\n",
    "        # Eq (6) above\n",
    "        score = torch.cat((last_hidden_expansion, encoder_outputs), 2)\n",
    "        # max_len, batch\n",
    "        e_ik = self.g(score).squeeze(-1).t()\n",
    "        attn_energies = self.masked_softmax(e_ik, mask.t()).unsqueeze(1)\n",
    "        # Eq (5) above\n",
    "        context = attn_energies.bmm(encoder_outputs.transpose(0, 1)).transpose(0,1)\n",
    "        \n",
    "        ###### Input alignment\n",
    "        encoder_alignment = encoder_alignment.unsqueeze(0)\n",
    "        input_alignment = torch.cat((embedded, encoder_alignment, context), 2)\n",
    "        # Forward through undirectional LSTM\n",
    "        rnn_output, (hidden, memory) = self.LSTM(input_alignment, [last_hidden, last_memory])\n",
    "        \n",
    "        ############# This part is Luong Attention mechanism #############\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        # attn_weights = self.attn(rnn_output, encoder_outputs, mask)\n",
    "        \n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        # encoder_outputs [max_len, batch, hidden_dim] -> transpose encoder_outputs [batch, max_len, hidden_dim]\n",
    "        # attn_weights [batch_size, 1, max_len]\n",
    "        # context : [batch_size, 1, hidden_dim] weighted sum over length\n",
    "        # context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        \n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        # ht = tanh(Wc[ct;ht]), self.concat : Wc\n",
    "        # squeeze to remove dimension 1\n",
    "        # rnn_output : [seq_len = 1, batch_size, hidden_dim]rnn_output.squeeze(0) -> [batch_size, hidden_dim]\n",
    "        # context.squeeze(0) -> [batch_size, attn_hidden_dim]\n",
    "        \n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "#         context = context.squeeze(1)\n",
    "#         concat_input = torch.cat((rnn_output, context), 1)\n",
    "#         concat_output = torch.tanh(self.concat(concat_input))\n",
    "        output = self.out(rnn_output)\n",
    "        output = F.softmax(output, dim = 1)\n",
    "        return output, hidden, memory, attn_energies.squeeze(1).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    \n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def classificationLoss(inp, target):\n",
    "    loss = criterion(inp, target.to(device))\n",
    "    return loss.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizer . . .\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 1000; Percent complete: 10.0%; Average loss: 0.2165\n",
      "[[tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0023, 0.0047, 0.0417, 0.0269, 0.1043, 0.0248, 0.1761, 0.0233, 0.0654,\n",
      "        0.0136, 0.0233, 0.0095, 0.0126, 0.0284, 0.0281, 0.0237, 0.1715, 0.0236,\n",
      "        0.0710, 0.0314, 0.0153, 0.0124, 0.0101, 0.0121, 0.0439],\n",
      "       grad_fn=<SelectBackward>)]]\n",
      "Iteration: 2000; Percent complete: 20.0%; Average loss: 0.0035\n",
      "[[tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0014, 0.0013, 0.0047, 0.0092, 0.0027, 0.0054, 0.0215, 0.0292, 0.0185,\n",
      "        0.0232, 0.0088, 0.4108, 0.0467, 0.0728, 0.0820, 0.0125, 0.1153, 0.0050,\n",
      "        0.0275, 0.0384, 0.0313, 0.0087, 0.0117, 0.0115],\n",
      "       grad_fn=<SelectBackward>)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3000; Percent complete: 30.0%; Average loss: 0.0019\n",
      "[[tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0062, 0.0058, 0.0046, 0.0109, 0.0134, 0.1435, 0.0161, 0.1218, 0.1479,\n",
      "        0.0062, 0.0790, 0.0850, 0.0088, 0.0387, 0.1112, 0.0487, 0.0190, 0.0043,\n",
      "        0.0022, 0.0012, 0.0039, 0.0014, 0.0043, 0.0142, 0.0077, 0.0133, 0.0036,\n",
      "        0.0078, 0.0035, 0.0021, 0.0183, 0.0254, 0.0203],\n",
      "       grad_fn=<SelectBackward>)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4000; Percent complete: 40.0%; Average loss: 0.0024\n",
      "[[tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0021, 0.0018, 0.0021, 0.0020, 0.0059, 0.0066, 0.0585, 0.0117, 0.2015,\n",
      "        0.1039, 0.0077, 0.0087, 0.0068, 0.0363, 0.0365, 0.1373, 0.0528, 0.0046,\n",
      "        0.0201, 0.0629, 0.0364, 0.1181, 0.0443, 0.0035, 0.0210, 0.0067],\n",
      "       grad_fn=<SelectBackward>)]]\n",
      "Iteration: 5000; Percent complete: 50.0%; Average loss: 0.0018\n",
      "[[tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0018, 0.0010, 0.0029, 0.0128, 0.0060, 0.0411, 0.2696, 0.0133, 0.0645,\n",
      "        0.0071, 0.0043, 0.0255, 0.0361, 0.0009, 0.0018, 0.0016, 0.0041, 0.0138,\n",
      "        0.0098, 0.0979, 0.0107, 0.0704, 0.2163, 0.0183, 0.0068, 0.0563, 0.0055],\n",
      "       grad_fn=<SelectBackward>)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6000; Percent complete: 60.0%; Average loss: 0.0014\n",
      "[[tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0024, 0.0074, 0.0118, 0.0070, 0.0267, 0.2081, 0.0227, 0.3692, 0.0071,\n",
      "        0.0039, 0.0096, 0.0045, 0.0106, 0.0250, 0.0009, 0.0011, 0.0010, 0.0297,\n",
      "        0.0221, 0.0048, 0.0029, 0.0041, 0.0143, 0.1206, 0.0824],\n",
      "       grad_fn=<SelectBackward>)]]\n",
      "Iteration: 7000; Percent complete: 70.0%; Average loss: 0.0014\n",
      "[[tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0072, 0.0076, 0.0059, 0.0151, 0.0162, 0.1545, 0.0136, 0.2128, 0.0049,\n",
      "        0.0495, 0.0427, 0.0023, 0.0132, 0.0173, 0.1056, 0.1437, 0.0517, 0.0350,\n",
      "        0.0072, 0.0189, 0.0119, 0.0080, 0.0102, 0.0339, 0.0114],\n",
      "       grad_fn=<SelectBackward>)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8000; Percent complete: 80.0%; Average loss: 0.0014\n",
      "[[tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0035, 0.0037, 0.0021, 0.0061, 0.1013, 0.0143, 0.1139, 0.0260, 0.0062,\n",
      "        0.0518, 0.0151, 0.0038, 0.0067, 0.0026, 0.0060, 0.0815, 0.0122, 0.0934,\n",
      "        0.0241, 0.0069, 0.0511, 0.0151, 0.0037, 0.0068, 0.0028, 0.0054, 0.0548,\n",
      "        0.0134, 0.1016, 0.0269, 0.0090, 0.0726, 0.0223, 0.0333],\n",
      "       grad_fn=<SelectBackward>)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9000; Percent complete: 90.0%; Average loss: 0.0013\n",
      "[[tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0013, 0.0009, 0.0006, 0.0003, 0.0035, 0.0018, 0.0004, 0.0004, 0.0036,\n",
      "        0.0004, 0.0003, 0.0047, 0.0005, 0.0008, 0.0005, 0.0009, 0.0106, 0.0174,\n",
      "        0.0195, 0.0057, 0.0009, 0.0042, 0.0534, 0.0693, 0.0254, 0.2141, 0.0462,\n",
      "        0.0875, 0.2481, 0.0975, 0.0447, 0.0189, 0.0158],\n",
      "       grad_fn=<SelectBackward>)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10000; Percent complete: 100.0%; Average loss: 0.0020\n",
      "[[tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1., grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)], [tensor(1.0000, grad_fn=<ThAddBackward>), tensor([0.0086, 0.0059, 0.0064, 0.0137, 0.0522, 0.0062, 0.0927, 0.0449, 0.0087,\n",
      "        0.0858, 0.0218, 0.0540, 0.0090, 0.0107, 0.0068, 0.0181, 0.0395, 0.0036,\n",
      "        0.0474, 0.0466, 0.0076, 0.0825, 0.0243, 0.0557, 0.0094, 0.0109, 0.0060,\n",
      "        0.0137, 0.0175, 0.0033, 0.0422, 0.0421, 0.0055, 0.0692, 0.0193, 0.0083],\n",
      "       grad_fn=<SelectBackward>)]]\n"
     ]
    }
   ],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, intent_variable, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, (encoder_hidden, encoder_memory), intent_output = encoder(input_variable, lengths)\n",
    "    loss = classificationLoss(intent_output, intent_variable)\n",
    "    print_losses.append(loss.item())\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    # We use backward encoder memory as initial hidden state\n",
    "    decoder_hidden = encoder_hidden[1].unsqueeze(0)\n",
    "    decoder_memory = encoder_memory[1].unsqueeze(0)\n",
    "    attns_ = []\n",
    "    for t in range(max_target_len):\n",
    "        decoder_output, decoder_hidden, decoder_memory, att = decoder(\n",
    "                decoder_input, decoder_hidden, decoder_memory, encoder_outputs, mask, encoder_outputs[t]\n",
    "        )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "        _, topi = decoder_output.topk(1)\n",
    "        decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "        decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "        mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "        loss += mask_loss\n",
    "        print_losses.append(mask_loss.item() * nTotal)\n",
    "        n_totals += nTotal\n",
    "        \n",
    "        attns_.append([sum(att[0]), att[0]])\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "#     print(loss)\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return sum(print_losses) / (n_totals + 0.0005), attns_\n",
    "\n",
    "\n",
    "def trainIters(voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, n_iteration, batch_size, print_every, save_every, clip):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len, intent_variable = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss, attns = train(input_variable, lengths, target_variable, mask, max_target_len, intent_variable, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "            print(attns)\n",
    "\n",
    "            \n",
    "attn_model = 'general'\n",
    "embedding_size = 128\n",
    "hidden_size = 128\n",
    "encoder_n_layers = 1\n",
    "decoder_n_layers = 1\n",
    "dropout = 0.5\n",
    "batch_size = 128\n",
    "\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "encoder = EncoderRNN(embedding_size, hidden_size, embedding, len(voc.intent2index), encoder_n_layers, dropout)\n",
    "decoder = InputAlignedDecoderRNN(attn_model, embedding, hidden_size, len(voc.slot2index), decoder_n_layers, dropout)\n",
    "\n",
    "clip = 5.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.001\n",
    "decoder_learning_ratio = 1.0\n",
    "n_iteration = 10000\n",
    "# n_iteration = 1\n",
    "print_every = 1000\n",
    "save_every = 500\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "print('Building optimizer . . .')\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr = learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr = learning_rate * decoder_learning_ratio)\n",
    "\n",
    "trainIters(voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, n_iteration, batch_size,\n",
    "          print_every, save_every, clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, input_seq, input_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, (encoder_hidden, encoder_memory), intent_output = encoder(input_seq, input_length)\n",
    "        mask = torch.ones(input_seq.shape)\n",
    "        # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "        decoder_input = torch.ones(1, 1, device = device, dtype = torch.long) * SOS_token\n",
    "        \n",
    "        decoder_hidden = encoder_hidden[1].unsqueeze(0)\n",
    "        decoder_memory = encoder_memory[1].unsqueeze(0)\n",
    "        # empty Tensor\n",
    "        all_slots = torch.zeros([0], device = device, dtype = torch.long)\n",
    "        attn_scores = []\n",
    "        for t in range(input_seq.shape[0]):\n",
    "            decoder_output, decoder_hidden, decoder_memory, attn_score = self.decoder(\n",
    "                decoder_input, decoder_hidden, decoder_memory, encoder_outputs, mask, encoder_outputs[t]\n",
    "            )\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim = 1)\n",
    "            all_slots = torch.cat((all_slots, decoder_input), dim = 0)\n",
    "            \n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "            attn_scores.append(attn_score)\n",
    "        return all_slots, attn_scores, intent_output\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "def evaluate():\n",
    "    res = []\n",
    "    attn_weights = []\n",
    "    intent_res = []\n",
    "    for sentence in test_input_utter:\n",
    "        test_input_utter_sent = torch.LongTensor(indexesFromSentence(voc, sentence))\n",
    "        test_sent_len = torch.tensor([len(sentence) + 1])\n",
    "        test_input_utter_sent = test_input_utter_sent.to(device).unsqueeze(1)\n",
    "        test_sent_len = test_sent_len.to(device)\n",
    "        slots, attn_scores, intent_output = searcher(test_input_utter_sent, test_sent_len)\n",
    "        res.append(slots)\n",
    "        attn_weights.append(attn_scores)\n",
    "        #print(intent_output, torch.max(intent_output), intent_output.argmax())\n",
    "#         print(torch.max(intent_output, 1)[1])\n",
    "#         print(intent_output.tolist()[0])\n",
    "        intent_res.append(intent_output.tolist()[0])\n",
    "    return res, attn_weights, intent_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res, attn_weights, intent_res = evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'UNK', 1: 'flight', 2: 'flight_time', 3: 'airfare', 4: 'aircraft', 5: 'ground_service', 6: 'airport', 7: 'airline', 8: 'distance', 9: 'abbreviation', 10: 'ground_fare', 11: 'quantity', 12: 'city', 13: 'flight_no', 14: 'capacity', 15: 'meal', 16: 'restriction', 17: 'cheapest'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(voc.index2intent)\n",
    "intent_res_index = [voc.index2intent[np.argmax(intent)] for intent in intent_res]\n",
    "test_slot_labels_indexes = [indexesFromSlots(voc,slots ) for slots in test_slot_labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent accuracy :  0.9518477043673013\n",
      "Paper benchmark result : 95.87\n",
      "Slot filling weighted F1 score : 0.9776072888999784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwanghoonan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/kwanghoonan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "tp = 0.0\n",
    "for re, tr in zip(intent_res_index, test_intent_labels):\n",
    "    if re == tr:\n",
    "        tp += 1.0\n",
    "acc = tp/len(intent_res)\n",
    "print(\"intent accuracy : \",acc)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for re, gold_labels in zip(res, test_slot_labels_indexes):\n",
    "    re_list = re.numpy().tolist()\n",
    "    if re_list[-1] == 2 and gold_labels[-1] == 2:\n",
    "        re_list = re_list[:-1]\n",
    "        gold_labels = gold_labels[:-1]\n",
    "    if len(re_list) != len(gold_labels):\n",
    "        print(\"Diff Len\")\n",
    "        break\n",
    "    y_pred.extend(re_list)\n",
    "    y_true.extend(gold_labels)\n",
    "\n",
    "print(\"Paper benchmark result :\", 95.87)\n",
    "print(\"Slot filling weighted F1 score :\", f1_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I could not observe a huge benefit of using context vector with attention mechanism with above equation.\n",
    "Sometimes sum of context vectors was not equal to 1 ( much smaller than 1 )\n",
    "Possibly my implementation design is poorly defined, but if we use well-known Global mechanism, it will be much better to observe a benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "#     print(attentions[0].numpy()())\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeezingTensor(tensors):\n",
    "    new_tensors = []\n",
    "    for tensor in tensors:\n",
    "        new_tensors.append(tensor.detach().numpy())\n",
    "    return new_tensors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
